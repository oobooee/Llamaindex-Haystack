description,readme
React components for efficiently rendering large lists and tabular data,"b'\n\nReact components for efficiently rendering large lists and tabular data.\nCheck out  for some examples.\n\n### If you like this project, \xf0\x9f\x8e\x89  or \xe2\x98\x95 \n\n### Sponsors\n\nThe following wonderful companies have sponsored react-virtualized:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## A word about \n\nIf youre considering adding  to a project, take a look at  as a possible lighter-weight alternative. \n\n## Getting started\n\nInstall  using npm.\n\n\n\nES6, CommonJS, and UMD builds are available with each distribution.\nFor example:\n\n\n\nNote webpack 4 makes this optimization itself, see the .\n\nIf the above syntax looks too cumbersome, or you import react-virtualized components from a lot of places, you can also configure a Webpack alias. For example:\n\n\n\nThen you can just import like so:\n\n\n\nYou can also use a global-friendly UMD build:\n\n\n\nNow youre ready to start using the components.\nYou can learn more about which components react-virtualized has to offer .\n\n## Dependencies\n\nReact Virtualized has very few dependencies and most are managed by NPM automatically.\nHowever the following peer dependencies must be specified by your project in order to avoid version conflicts:\n,\n.\nNPM will not automatically install these for you but it will show you a warning message with instructions on how to install them.\n\n## Pure Components\n\nBy default all react-virtualized components use  to avoid re-rendering unless props or state has changed.\nThis occasionally confuses users when a collections data changes (eg  => ) but props do not (eg ).\n\nThe solution to this is to let react-virtualized know that something external has changed.\nThis can be done a couple of different ways.\n\n###### Pass-thru props\n\nThe  method will detect changes to any props, even if they arent declared as .\nThis means you can also pass through additional properties that affect cell rendering to ensure changes are detected.\nFor example, if youre using  to render a list of items that may be re-sorted after initial render- react-virtualized would not normally detect the sort operation because none of the properties it deals with change.\nHowever you can pass through the additional sort property to trigger a re-render.\nFor example:\n\n\n\n###### Public methods\n\n and  components can be forcefully re-rendered using .\nFor  and , youll need to call  to ensure that the inner  is also updated. For , youll need to call  to ensure that the inner s are updated.\n\n## Documentation\n\nAPI documentation available .\n\nThere are also a couple of how-to guides:\n\n- \n- \n- \n- \n- \n- \n\n## Examples\n\nExamples for each component can be seen in .\n\nHere are some online demos of each component:\n\n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n\nAnd here are some ""recipe"" type demos:\n\n- \n- \n- \n- \n- \n\n## Supported Browsers\n\nreact-virtualized aims to support all evergreen browsers and recent mobile browsers for iOS and Android. IE 9+ is also supported (although IE 9 will require some user-defined, custom CSS since flexbox layout is not supported).\n\nIf you find a browser-specific problem, please report it along with a repro case. The easiest way to do this is probably by forking .\n\n## Friends\n\nHere are some great components built on top of react-virtualized:\n\n- : Infinite scrolling date-picker with localization, themes, keyboard support, and more\n- : Higher-order components to turn any list into an animated, touch-friendly, sortable list\n- : Drag-and-drop sortable representation of hierarchical data\n- : Checkbox group component with virtualization for large number of options\n- : Drop-down menu for React with windowing to support large numbers of options.\n- : A reactive tree component that aims to render large sets of tree structured data in an elegant and performant way\n- : A calendar timeline component that is capable of displaying and interacting with a large number of items\n\n## Contributions\n\nUse  for requests.\n\nI actively welcome pull requests; learn how to .\n\n## Changelog\n\nChanges are tracked in the .\n\n## License\n\n_react-virtualized_ is available under the MIT License.\n'"
A type-safe typescript SQL query builder,"b'\n\n\n\n\n\n\n\n\n\n\n\n# \n\nKysely (pronounce \xe2\x80\x9cKey-Seh-Lee\xe2\x80\x9d) is a type-safe and autocompletion-friendly typescript SQL query builder.\nInspired by . Mainly developed for  but also \nruns on all other javascript environments like .\n\n\n\nKysely makes sure you only refer to tables and columns that are visible to the part of the query\nyoure writing. The result type only has the selected columns with correct types and aliases. As an\nadded bonus you get autocompletion for all that stuff.\n\nAs shown in the gif above, through the pure magic of modern typescript, Kysely is even able to parse\nthe alias given to  and add the  column to the result row type. Kysely is able to infer\ncolumn names, aliases and types from selected subqueries, joined subqueries,  statements and pretty\nmuch anything you can think of.\n\nOf course there are cases where things cannot be typed at compile time, and Kysely offers escape\nhatches for these situations. See the \nand the  for more info.\n\nAll API documentation is written in the typing files and you can simply hover over the module, class\nor method youre using to see it in your IDE. The same documentation is also hosted .\n\nIf you start using Kysely and cant find something youd want to use, please open an issue or join our\n.\n\n# Getting started\n\nPlease visit our documentation site  to get started. We also have a comprehensive\nAPI documentation hosted  but you can access the same\ndocumentation in your IDE by hovering over a class/method/property/whatever.\n\n# Contributors\n\n\n    \n        \n    \n    \n    Want to contribute? Check out our contribution guidelines.\n\n\n\n    \n        \n    \n\n'"
Curated List: Practical Natural Language Processing done in Ruby,"b'\n\n \n\n[ |\n  |\n ]\n\n\n# Awesome NLP with Ruby [][ruby]\n\n> Useful resources for text processing in Ruby\n\nThis curated list comprises \nresources, libraries, information sources about computational processing of texts\nin human languages with the .\nThat field is often referred to as\n,\n,\n (Human Language Technology)\nand can be brought in conjunction with\n,\n,\n,\n,\n\nand other related disciplines.\n\nThis list comes from our day to day work on Language Models and NLP Tools.\nRead  this list is awesome. Our  describes the\nimportant decisions and useful answers you may be interested in.\n\n:sparkles: Every  is welcome! Add links through pull\nrequests or create an issue to start a discussion.\n\nFollow us on \nand please spread the word using the  hash tag!\n\n<!-- nodoc -->\n## Contents\n\n<!-- toc -->\n\n- \n- \n  * \n  * \n    + \n  * \n  * \n  * \n    + \n    + \n    + \n    + \n  * \n  * \n    + \n  * \n  * \n- \n  * \n  * \n  * \n  * \n  * \n  * \n  * \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n\n<!-- tocstop -->\n\n<!-- doc -->\n\n## :sparkles: Tutorials\n\nPlease help us to fill out this section! :smiley:\n\n## NLP Pipeline Subtasks\n\nAn NLP Pipeline starts with a plain text.\n\n### Pipeline Generation\n\n-  -\n  Definition framework for operation pipelines.\n-  -\n  Spark bindings with an easy to understand DSL.\n-  -\n  Simplified Ruby Client for .\n-  -\n  Supervisor for parallel execution on multiple CPUs or in many threads.\n-  -\n  Rake extensions to run local and remote tasks in parallel.\n\n### Multipurpose Engines\n\n-  -\n  Ruby Bindings for the  Toolkit.\n-  -\n  Ruby Bindings for the Stanford  tools.\n-  -\n  Natural Language Processing framework for Ruby (like  for Python).\n-  -\n  Wrapper over some  classes and\n  the original .\n-  -\n  JRuby Bindings for the  Toolkit.\n-  &mdash;\n  Wrapper module for spaCy NLP library via .\n\n#### On-line APIs\n\n-  -\n  Legacy Ruby SDK for AlchemyAPI/Bluemix.\n-  -\n  Ruby client library for the  Language Understanding Platform.\n-  - Ruby client library for\n   web services.\n-  - Sentiment\n  Analysis, Topic Modelling, Language Detection, Named Entity Recognition via\n  a Ruby based Web API client.\n-  -\n  Googles Natural Language service API for Ruby.\n\n### Language Identification\n\nLanguage Identification is one of the first crucial steps in every NLP Pipeline.\n\n-  -\n  Language Categorization and Identification.\n\n### Segmentation\n\nTools for Tokenization, Word and Sentence Boundary Detection and Disambiguation.\n\n-  -\n  Simple multilingual tokenizer.\n  []\n-  -\n  Multilingual tokenizer to split a string into tokens.\n-  -\n  Natural language processing algorithms implemented in pure Ruby with minimal dependencies.\n-  -\n  Simple and customizable text tokenization library.\n-  -\n  Word Boundary Disambiguation with many cookies.\n-  -\n  Pure Ruby implementation of the Punkt Segmenter.\n-  -\n  RegExp based tokenizer for different languages.\n-  -\n  Sentence Boundary Disambiguation tool.\n\n### Lexical Processing\n\n#### Stemming\n\nStemming is the term used in information retrieval to describe the process for\nreducing wordforms to some base representation. Stemming should be distinguished\nfrom  since  are not necessarily have\nlinguistic motivation.\n\n-  -\n  Ruby-Stemmer exposes the SnowBall API to Ruby.\n-  -\n  Conservative stemmer for search and indexing.\n\n#### Lemmatization\n\nLemmatization is considered a process of finding a base form of a word. Lemmas\nare often collected in dictionaries.\n\n-  -\n  WordNet based Lemmatizer for English texts.\n\n#### Lexical Statistics: Counting Types and Tokens\n\n-  -\n  Facilities to count word occurrences in a text.\n-  -\n  Word counter for  and  objects.\n-  -\n  Pure Ruby library counting word statistics with different custom options.\n\n#### Filtering Stop Words\n\n-  - Filter and\n  Stop Word Lexicon based on the SnowBall lemmatizer.\n\n### Phrasal Level Processing\n\n-  -\n  N-Gram generator.\n-  -\n  Break words and phrases into ngrams.\n-  -\n  Flexible and general-purpose ngrams library written in pure Ruby.\n\n### Syntactic Processing\n\n#### Constituency Parsing\n\n-  -\n  Ruby based wrapper for the Stanford Parser.\n-  -\n  Pure Ruby implementation of the \n  Parsing Algorithm for Context-Free Constituency Grammars.\n-  -\n  Visualization for syntactic trees in Ruby based on .\n  [dep: ]\n\n### Semantic Analysis\n\n-  -\n  Set of five distance types between strings (including Levenshtein, Sellers, Jaro-Winkler, pair distance).\n-  -\n  Calculates edit distance using the Damerau-Levenshtein algorithm.\n-  -\n  Fast Ruby FFI string edit distance algorithms.\n-  -\n  Fast string edit distance computation, using the Damerau-Levenshtein algorithm.\n-  -\n  Term Frequency / Inverse Document Frequency in pure Ruby.\n-  -\n  Calculate the similarity between texts using TF/IDF.\n\n### Pragmatical Analysis\n-  -\n  Simple extensible sentiment analysis gem.\n\n## High Level Tasks\n\n### Spelling and Error Correction\n\n-  -\n  Spelling and Grammar corrections via the  API.\n-  -\n  Ruby bindings to the standard  Spell Checker.\n-  -\n  FFI based Ruby bindings for .\n-  -\n  Ruby bindings to  via Ruby C API.\n\n### Text Alignment\n\n-  -\n  Alignment routines for bilingual texts (Gale-Church implementation).\n\n### Machine Translation\n\n-  -\n  Google API Ruby Client.\n-  -\n  Ruby client for the microsoft translator API.\n-  -\n  Google Translate with speech synthesis in your terminal.\n-  -\n  implementation of BLEU and other base algorithms.\n\n### Sentiment Analysis\n\n-  -\n  Semantic Polarity based on the\n   lexicon.\n\n### Numbers, Dates, and Time Parsing\n\n-  -\n  Pure Ruby natural language date parser.\n-  -\n  Simple Ruby natural language parser for date and time ranges.\n-  -\n  Pure Ruby parser for elapsed time.\n-  -\n  Methods for parsing and formatting human readable dates.\n-  -\n  Extracts date, time, and message information from naturally worded text.\n-  -\n  Parser for recurring and repeating events.\n-  -\n  Ruby parser for English number expressions.\n\n### Named Entity Recognition\n\n-  -\n  Named Entity Recognition with Stanford NER and Ruby.\n-  -\n  Ruby Binding for Stanford Pos-Tagger and Name Entity Recognizer.\n\n### Text-to-Speech-to-Text\n\n-  -\n  Small Ruby API for utilizing espeak and lame to create text-to-speech mp3 files.\n-  -\n  Text-to-Speech conversion using the Google translate service.\n-  -\n  Ruby wrapper over the AT&T Speech API for speech to text.\n-  -\n  Pocketsphinx bindings.\n\n## Dialog Agents, Assistants, and Chatbots\n\n-  -\n  Straightforward ruby-based Twitter Bot Framework, using OAuth to authenticate.\n-  -\n  Highly extensible chat operation bot framework written with persistent storage on .\n\n## Linguistic Resources\n\n-  -\n  Pure Ruby self contained API library for the .\n-  -\n  Performance tuned bindings for the .\n\n## Machine Learning Libraries\n\n Algorithms\nin pure Ruby or written in other programming languages with appropriate bindings\nfor Ruby.\n\nFor more up-to-date list please look at the [Awesome ML with Ruby][ml-with-ruby] list.\n\n-  -\n  Support Vector Machines with Ruby.\n-  -\n  JRuby bindings for Weka, different ML algorithms implemented through Weka.\n-  -\n  Decision Tree ID3 Algorithm in pure Ruby\n  [].\n-  -\n  Memory based learners from the Timbl framework.\n-  -\n  General classifier module to allow Bayesian and other types of classifications.\n-  -\n  Ruby implementation of the \n  (Latent Dirichlet Allocation) for automatic Topic Modelling and Document Clustering.\n-  -\n  Ruby interface to LIBLINEAR (much more efficient than LIBSVM for text classification).\n-  -\n  Redis-backed Bayesian classifier.\n-  -\n  JRuby maximum entropy classifier for string data, based on the OpenNLP Maxent framework.\n-  -\n  Simple Naive Bayes classifier.\n-  -\n  Full-featured, Ruby implementation of Naive Bayes.\n-  -\n  Generalized rack framework for text classifications.\n-  -\n  Naive Bayes text classification implementation as an OmniCat classifier strategy.\n-  -\n  Ruby bindings to the .\n-  - Feature Extraction and Crossvalidation library.\n\n## Data Visualization\n\nPlease refer to the \nsection on the [Data Science with Ruby][ds-with-ruby] list.\n\n## Optical Character Recognition\n\n*  -\n  FFI based wrapper over the .\n\n## Text Extraction\n\n-  -\n  library for extracting text and metadata from files and documents\n  using the  content analysis toolkit.\n\n## Full Text Search, Information Retrieval, Indexing\n\n-  -\n  Ruby and Rails client library for .\n-  -\n  Rails centric client for .\n-  -\n  \n  plugin for using  in (not only) Rails based projects.\n-  -\n  Ruby client and API for .\n-  -\n  Ruby and Rails integrations for .\n-  -\n  Ruby API library for  services.\n\n## Language Aware String Manipulation\n\nLibraries for language aware string manipulation, i.e. search, pattern matching,\ncase conversion, transcoding, regular expressions which need information about\nthe underlying language.\n\n-  -\n  Fuzzy string comparison with Distance measures and Regular Expression.\n-  -\n  Fuzzy string matching library for Ruby.\n-  -\n  RoR  gem has various string extensions that can handle case.\n-  -\n  Toolset for fuzzy searches in Ruby tuned for accuracy.\n-  -\n  U extends Ruby\xe2\x80\x99s Unicode support.\n-  -\n  Unicode normalization library.\n-  -\n  Find a lot of kinds of common information in a string.\n-  -\n  Generate strings that match a given regular expression.\n-  -\n  Make difficult regular expressions easy.\n-  -\n  Transliterate Hebrew & Yiddish text into Latin characters.\n-  -\n  hight-speed Regular Expression library for Text Mining and Text Extraction.\n-  -\n  sample string generation from a given Regular Expression.\n-  &mdash;\n  transliteration Cyrillic to Latin in many possible ways (defined by the ).\n\n## Articles, Posts, Talks, and Presentations\n\n- 2019\n  - Extracting Text From Images Using Ruby by \n    [ |\n    ]\n- 2018\n  - Natural Language Processing and Tweet Sentiment Analysis by \n    []\n- 2017\n  - The Google NLP API Meets Ruby by \n    []\n  - Syntax Isn by \n    []\n  - Scientific Computing on JRuby by \n    [ |\n     |\n     |\n    ]\n  - Unicode Normalization in Ruby by \n    []\n- 2016\n  - Quickly Create a Telegram Bot in Ruby by \n    []\n  - Deep Learning: An Introduction for Ruby Developers by \n    []\n  - How I made a pure-Ruby word2vec program more than 3x faster by \n    []\n  - D\xc5\x8dmo arigat\xc5\x8d, Mr. Roboto: Machine Learning with Ruby by \n    [ | ]\n- 2015\n  - N-gram Analysis for Fun and Profit by \n    []\n  - Machine Learning made simple with Ruby by \n    []\n  - Using Ruby Machine Learning to Find Paris Hilton Quotes by \n    []\n  - Exploring Natural Language Processing in Ruby by \n    []\n  - Machine Learning made simple with Ruby by \n    []\n  - Practical Data Science in Ruby by Bobby Grayson\n    []\n- 2014\n  - Natural Language Parsing with Ruby by \n    []\n  - Demystifying Data Science: Analyzing Conference Talks with Rails and Ngrams by\n    \n    [ | ]\n  - Natural Language Processing with Ruby by \n    [ |  |\n     |\n    ]\n- 2013\n  - How to parse  by\n    \n    [ |\n    ]\n  - Natural Language Processing in Ruby by \n    [ |\n    ]\n  - Natural Language Processing with Ruby: n-grams by \n    [ |\n    ]\n  - Seeking Lovecraft, Part 1: An introduction to NLP and the Treat Gem by\n    \n    []\n- 2012\n  - Machine Learning with Ruby, Part One by \n    []\n- 2011\n  - Ruby one-liners by \n    []\n  - Clustering in Ruby by \n    [/)]\n- 2010\n  - bayes_motel \xe2\x80\x93 Bayesian classification for Ruby by \n    []\n- 2009\n  - Porting the UEA-Lite Stemmer to Ruby by \n    []\n  - NLP Resources for Ruby by \n    []\n- 2008\n  - Support Vector Machines (SVM) in Ruby by \n    []\n  - Practical text classification with Ruby by \n    [ |\n    ]\n- 2007\n  - Decision Tree Learning in Ruby by \n    []\n- 2006\n  - Speak My Language: Natural Language Processing With Ruby by \n    [ |\n           |\n          ]\n\n## Projects and Code Examples\n\n-  -\n  Implementations of various distance algorithms with example calculations.\n-  -\n  NER Examples in Ruby and Java with some .\n-  -\n  examples of customizable word statistics powered by\n  .\n-  -\n  Web based demonstration of the syntactic tree visualization.\n\n## Books\n\n-  .\n   Text Processing with Ruby: Extract Value from the Data That Surrounds You.\n   Pragmatic Programmers, 2015.\n   []\n-  .\n   Scripting Intelligence: Web 3.0 Information Gathering and Processing.\n   APRESS, 2010.\n   []\n-  .\n   Practical Semantic Web and Linked Data Applications. Lulu, 2010.\n   []\n\n## Community\n\n- \n- \n- \n\n## Needs your Help!\n\nAll projects in this section are really important for the community but need\nmore attention. Please if you have spare time and dedication spend some hours\non the code here.\n\n-  -\n  Information Retrieval in C and Ruby.\n-  -\n  Ruby native wrapper for .\n\n## Related Resources\n\n- \n-  -\n  Among other awesome items a short list of NLP related projects.\n-  -\n  State-of-Art collection of Ruby libraries for NLP.\n-  -\n  General List of NLP related resources (mostly not for Ruby programmers).\n-  -\n  Linear Algebra, Visualization and Scientific Computing for Ruby.\n-  - IRuby kernel for Jupyter (formelly IPython).\n-  -\n  Multitude of OCR (Optical Character Recognition) resources.\n-  -\n  Machine Learning with TensorFlow libraries.\n- \n  \n\n## License\n\n  by  and\n.\n\nTo the extent possible under law, the person who associated CC0 with\n has waived all copyright and related or neighboring rights\nto .\n\nYou should have received a copy of the CC0 legalcode along with this\nwork. If not, see .\n\n<!--- Links --->\n[ruby]: https://www.ruby-lang.org/en/\n[motivation]: https://github.com/arbox/nlp-with-ruby/blob/master/motivation.md\n[faq]: https://github.com/arbox/nlp-with-ruby/blob/master/FAQ.md\n[ds-with-ruby]: https://github.com/arbox/data-science-with-ruby\n[ml-with-ruby]: https://github.com/arbox/machine-learning-with-ruby\n[change-pr]: https://github.com/RichardLitt/knowledge/blob/master/github/amending-a-commit-guide.md\n'"
"Google's common Java, C++ and JavaScript library for parsing, formatting, and validating international phone numbers.","b'\n\n\n\n# What is it?\n\nGoogles common Java, C++ and JavaScript library for parsing, formatting, and\nvalidating international phone numbers. The Java version is optimized for\nrunning on smartphones, and is used by the Android framework since 4.0 (Ice\nCream Sandwich).\n\n# Quick links\n\n*   Reporting an issue? Want to send a pull request? See the \n*   Check the \n*   Fun! \n*   Look for\n     in\n    directories relevant to the code youre interested in.\n*   For contributors and porters: \n*   For porters: \n\n# Highlights of functionality\n\n*   Parsing, formatting, and validating phone numbers for all countries/regions\n    of the world.\n*    - gets the type of the number based on the number itself;\n    able to distinguish Fixed-line, Mobile, Toll-free, Premium Rate, Shared\n    Cost, VoIP, Personal Numbers, UAN, Pager, and Voicemail (whenever feasible).\n*    - gets a confidence level on whether two numbers could be\n    the same.\n*    and  - provide valid example\n    numbers for all countries/regions, with the option of specifying which type\n    of example phone number is needed.\n*    - quickly guesses whether a number is a possible\n    phone number by using only the length information, much faster than a full\n    validation.\n*    - full validation of a phone number for a region using\n    length and prefix information.\n*    - formats phone numbers on-the-fly when users enter\n    each digit.\n*    - finds numbers in text.\n*    - provides geographical information related to\n    a phone number.\n*    - provides carrier information related to a\n    phone number.\n*    - provides timezone information related to a\n    phone number.\n\n# Demo\n\n## Java\n\nThe  is updated with a slight\ndelay after the GitHub release.\n\nLast demo update: v8.13.26.\n\nNote: Even though the library (main branch/)\nis at v8.12.57, because of some deployment issues, we were unable to update the\nJava demo with the new binary version. We will soon fix this. Meantime, please\nuse JS demo.\n\nIf this number is lower than the , we are between\nreleases and the demo may be at either version.\n\n### Demo App\n\nThere is a demo Android App called  in this\nrepository. The purpose of this App is to show an example of how the library can\nbe used in a real-life situation, in this case specifically in an Android App\nusing Java.\n\n## JavaScript\n\nThe \nmay be run at various tags; this link will take you to .\n\n# Java code\n\nTo include the Java code in your application, either integrate with Maven (see\n) or download the latest\njars from the .\n\n# Javadoc\n\nJavadoc is automatically updated to reflect the latest release at\nhttps://javadoc.io/doc/com.googlecode.libphonenumber/libphonenumber/.\n\n# Versioning and Announcements\n\nWe generally choose the release number following these guidelines.\n\nIf any of the changes pushed to master since the last release are incompatible\nwith the intent / specification of an existing libphonenumber API or may cause\nlibphonenumber (Java, C++, or JS) clients to have to change their code to keep\nbuilding, we publish a major release. For example, if the last release were\n7.7.3, the new one would be 8.0.0.\n\nIf any of those changes enable clients to update their code to take advantage\nof new functionality, and if clients would have to roll-back these changes in\nthe event that the release was marked as ""bad"", we publish a minor release. For\nexample, wed go from 7.7.3 to 7.8.0.\n\nOtherwise, including when a release contains only\n changes, we publish a sub-minor release,\ne.g. 7.7.3 to 7.7.4.\n\nSometimes we make internal changes to the code or metadata that, while not\naffecting compatibility for clients, could affect compatibility for porters\nof the library. For such changes we make announcements to\n. Such changes\nare not reflected in the version number, and we would publish a sub-minor\nrelease if there were no other changes.\n\nWant to get notified of new releases? During most of the year, excepting\nholidays and extenuating circumstances, we release fortnightly. We update\n and\ndocument detailed .\nWe also send an announcement to  for every\nrelease.\n\n# Quick Examples\n\nLets say you have a string representing a phone number from Switzerland. This\nis how you parse/normalize it into a  object:\n\n\n\nAt this point,  contains:\n\n\n\n is a class that was originally auto-generated from\n with necessary modifications for efficiency. For details on\nthe meaning of each field, refer to .\n\nNow let us validate whether the number is valid:\n\n\n\nThere are a few formats supported by the formatting method, as illustrated\nbelow:\n\n\n\nYou could also choose to format the number in the way it is dialed from another\ncountry:\n\n\n\n## Formatting Phone Numbers as you type\n\n\n\n## Geocoding Phone Numbers\n\n\n\n## Mapping Phone Numbers to original carriers\n\nCaveat: We do not provide data about the current carrier of a phone number, only\nthe original carrier who is assigned the corresponding range. Read about .\n\n\n\nMore examples on how to use the library can be found in the .\n\n# Third-party Ports\n\nSeveral third-party ports of the phone number library are known to us. We share\nthem here in case theyre useful for developers.\n\nHowever, we emphasize that these ports are by developers outside the\nlibphonenumber project. We do not evaluate their quality or influence their\nmaintenance processes.\n\n*   C#: https://github.com/twcclegg/libphonenumber-csharp\n*   Gleam: https://github.com/massivefermion/phony\n*   Go: https://github.com/nyaruka/phonenumbers\n*   Objective-c: https://github.com/iziz/libPhoneNumber-iOS\n*   Swift: https://github.com/marmelroy/PhoneNumberKit\n*   PHP: https://github.com/giggsey/libphonenumber-for-php\n*   PostgreSQL in-database types: https://github.com/blm768/pg-libphonenumber\n*   Python: https://github.com/daviddrysdale/python-phonenumbers\n*   Ruby: https://github.com/ianks/mini_phone\n*   Ruby: https://github.com/daddyz/phonelib\n*   Ruby: https://github.com/mobi/telephone_number\n*   Rust: https://github.com/1aim/rust-phonenumber\n*   Erlang: https://github.com/marinakr/libphonenumber_erlang\n*   Clojure: https://github.com/randomseed-io/phone-number\n*   R: https://github.com/socialresearchcentre/dialr/\n*   Elixir: https://github.com/socialpaymentsbv/ex_phone_number\n*   Salesforce: https://appexchange.salesforce.com/appxListingDetail?listingId=a0N3A00000G12oJUAR\n\nAlternatives to our own versions:\n\n*   Android-optimized: Our Java version loads the metadata from\n     and asks that Android apps follow the Android\n    loading best practices of repackaging the metadata and loading from\n     themselves\n    ().\n    If you dont want to do this, check out the port at\n    https://github.com/MichaelRocks/libphonenumber-android, which does repackage\n    the metadata and use , and may be depended on without\n    needing those specific loading optimizations from clients. You should also check\n    out the port at https://github.com/lionscribe/libphonenumber-android which also\n    supports geocoding, and only requires a one line code change.\n*   Javascript: If you dont want to use our version, which depends on Closure,\n    there are several other options, including\n    https://github.com/catamphetamine/libphonenumber-js - a stripped-down\n    rewrite, about 110 KB in size - and\n    https://github.com/seegno/google-libphonenumber - a browserify-compatible\n    wrapper around the original unmodified library installable via npm, which\n    packs the Google Closure library, about 420 KB in size.\n\nTools based on libphonenumber metadata:\n\n*   Scala: https://github.com/mr-tolmach/raf - library for generating valid phone numbers in the E.164 format\n'"
A collection of tutorials and examples for solving and understanding machine learning and pattern classification tasks,"b'\n\n\n\n\n\n\n\nTutorials, examples, collections, and everything else that falls into the categories: pattern classification, machine learning, and data mining.\n\n\n\n\n\n\n\n# Sections\n\n\n- \n- \n- \n- \n- \n\t- \n\t- \n\t- \n\t- \n- \n- \n- \n- \n- \n- \n- \n- \n\n\n\n\n\n\n\n\n\n[] of this flowchart.\n\n\n\n\n\n\n\n### Introduction to Machine Learning and Pattern Classification\n[]\n\n- Predictive modeling, supervised machine learning, and pattern classification - the big picture []\n\n- Entry Point: Data - Using Pythons sci-packages to prepare data for Machine Learning tasks and other data analyses []\n\n- An Introduction to simple linear supervised classification using  []\n\n\n\n\n\n\n\n\n\n### Pre-processing\n\n[]\n\n- Feature Extraction\n\t- Tips and Tricks for Encoding Categorical Features in Classification Tasks []\n- Scaling and Normalization\n\t- About Feature Scaling: Standardization and Min-Max-Scaling (Normalization) []\n\n\n- Feature Selection\n\t- Sequential Feature Selection Algorithms []\n\n- Dimensionality Reduction\n\t- Principal Component Analysis (PCA) []\n\t- The effect of scaling and mean centering of variables prior to a PCA [] []\n\t- PCA based on the covariance vs. correlation matrix  []\n  - Linear Discriminant Analysis (LDA) []\n\t- Kernel tricks and nonlinear dimensionality reduction via PCA []\n\n- Representing Text\n\t- Tf-idf Walkthrough for scikit-learn []\n\n\n\n\n\n### Model Evaluation\n[]\n\n- An Overview of General Performance Metrics of Binary Classifier Systems []\n- Cross-validation\n\t- Streamline your cross-validation workflow - scikit-learns Pipeline in action []\n- Model evaluation, model selection, and algorithm selection in machine learning - Part I []\n- Model evaluation, model selection, and algorithm selection in machine learning - Part II []\n\n\n\n\n\n### Parameter Estimation\n[]\n\n- Parametric Techniques\n    - Introduction to the Maximum Likelihood Estimate (MLE) []\n    - How to calculate Maximum Likelihood Estimates (MLE) for different distributions []\n\n- Non-Parametric Techniques\n\t- Kernel density estimation via the Parzen-window technique []\n\t- The K-Nearest Neighbor (KNN) technique\n\n\n- Regression Analysis\n\t- Linear Regression\n\t\t- Least-Squares fit []\n\n   - Non-Linear Regression\n\n\n\n\n\n\n\n\n### Machine Learning Algorithms\n[]\n\n\n#### Bayes Classification\n\n- Naive Bayes and Text Classification I - Introduction and Theory []\n#### Logistic Regression\n\n- Out-of-core Learning and Model Persistence using scikit-learn\n[]\n\n#### Neural Networks\n\n- Artificial Neurons and Single-Layer Neural Networks - How Machine Learning Algorithms Work Part 1 []\n\n- Activation Function Cheatsheet []\n\n#### Ensemble Methods\n\n- Implementing a Weighted Majority Rule Ensemble Classifier in scikit-learn  []\n\n#### Decision Trees\n\n- Cheatsheet for Decision Tree Classification []\n\n\n\n\n\n### Clustering\n[]\n\n- Protoype-based clustering\n- Hierarchical clustering\n\t- Complete-Linkage Clustering and Heatmaps in Python []\n- Density-based clustering\n- Graph-based clustering\n- Probabilistic-based clustering\n\n\n\n\n\n\n\n## Collecting Data\n[]\n\n- Collecting Fantasy Soccer Data with Python and Beautiful Soup []\n\n- Download Your Twitter Timeline and Turn into a Word Cloud Using Python []\n\n- Reading MNIST into NumPy arrays []\n\n\n\n\n\n## Data Visualization\n[]\n\n- Exploratory Analysis of the Star Wars API  []\n\n\n\n- Matplotlib examples -Exploratory data analysis of the Iris dataset []\n\n\n\n- Artificial Intelligence publications per country\n\n[] []\n\n\n\n\n\n\n\n### Statistical Pattern Classification Examples\n[]\n\n- Supervised Learning\n\n    - Parametric Techniques\n    \t- Univariate Normal Density\n    \t\t- Ex1: 2-classes, equal variances, equal priors []\n\t\t\t- Ex2: 2-classes, different variances, equal priors []\n\t\t\t- Ex3: 2-classes, equal variances, different priors []\n\t\t\t- Ex4: 2-classes, different variances, different priors, loss function []\n\t\t\t- Ex5: 2-classes, different variances, equal priors, loss function, cauchy distr. []\n\n\n\n    \t- Multivariate Normal Density\n\t\t\t- Ex5: 2-classes, different variances, equal priors, loss function []\n\t\t\t- Ex7: 2-classes, equal variances, equal priors []\n\n    - Non-Parametric Techniques\n\n\n\n\n\n\n## Books\n[]\n\n#### Python Machine Learning\n\n<a href=http://sebastianraschka.com/publications.html>\n\n- \n- \n- \n\n\n\n\n\n\n\n## Talks\n[]\n\n#### An Introduction to Supervised Machine Learning and Pattern Classification: The Big Picture\n\n\n<a href=http://www.slideshare.net/SebastianRaschka/nextgen-talk-022015>\n\n[]\n\n[]\n\n\n\n\n\n\n\n\n\n#### MusicMood - Machine Learning in Automatic Music Mood Prediction Based on Song Lyrics\n\n<a href=http://www.slideshare.net/SebastianRaschka/musicmood-20140912> \n\n[]\n\n\n[]\n\n\n\n\n\n\n## Applications\n[]\n\n#### MusicMood - Machine Learning in Automatic Music Mood Prediction Based on Song Lyrics\n\nThis project is about building a music recommendation system for users who want to listen to happy songs. Such a system can not only be used to brighten up ones mood on a rainy weekend; especially in hospitals, other medical clinics, or public locations such as restaurants, the MusicMood classifier could be used to spread positive mood among people.\n\n\n\n[]\n\n\n\n#### mlxtend - A library of extension and helper modules for Pythons data analysis and machine learning libraries.\n\n\n\n[]\n\n\n\n\n\n\n## Resources\n[]\n\n\n\n- Copy-and-paste ready LaTex equations []\n\n- Open-source datasets []\n\n- Free Machine Learning eBooks []\n\n- Terms in data science defined in less than 50 words []\n\n- Useful libraries for data science in Python []\n\n- General Tips and Advices []\n\n- A matrix cheatsheat for Python, R, Julia, and MATLAB  []\n'"
"A static code analyzer for C++, C#, Lua","b'# TscanCode \r\n\r\n\r\n\r\n## A fast and accurate static analysis solution for C/C++, C#, Lua codes\r\n\r\nTencent is pleased to support the open source community by making TscanCode available.\r\n\r\nCopyright (C) 2017-2022 Tencent company and TscanCode Team. All rights reserved.\r\n\r\n## Introduction\r\n\r\nTscanCode is devoted to help programmers to find out code defects at the very beginning.  \r\n* TscanCode supports multi-language: ,  and  codes;\r\n* TscanCode is  and , The performance can be 200K lines per minute and  the accuracy rate is about 90%;   \r\n* TscanCode is , It doesnt require strict compiling enviroment and one single command can make it work; \r\n* TscanCode is , you can implement your own checks with TscanCode.\r\n\r\n## Highlights in v2.15.02 (2022-04-28)\r\n* lua crash fix and more useful checkers\r\n\r\n## Highlights in v2.15.01 (2022-01-19)\r\n* lua5.4 support\r\n* a lot of bugfixes and new features\r\n\r\n## Highlights in v2.14.24 (2018-02-24)\r\n*  was released on GUI, easier for rule customization;\r\n* GUI supports  now.\r\n\r\nFor other changes please refer to .\r\n\r\nQQ group:  \r\n\r\n\r\n\r\n## Compiling\r\n\r\nAny C++11 compiler should work. For compilers with partial C++11 support it may work. If your compiler has the C++11 features that are available in Visual Studio 2015 then it will work. If nullptr is not supported by your compiler then this can be emulated using the header lib/cxx11emu.h.\r\n\r\nThere are multiple compilation choices:\r\n* Windows: Visual Studio (Visual Studio 2015 and above)\r\n* Linux: g++ 4.6 (or later)\r\n* Mac: clang++\r\n\r\n### Visual Studio\r\n\r\nUse the tsancode.sln file. The file is configured for Visual Studio 2015, but the platform toolset can be changed easily to older or newer versions. The solution contains platform targets for both x86 and x64.\r\n\r\nSelect option  to build release version.\r\n\r\n### g++ or clang++\r\n\r\nSimple build (no dependencies):\r\n\r\n\r\n\r\n## Usage at a glance\r\n\r\nThis simple example contains a potential null pointer defect. Checking if p is null indicates that p might be null, so dereferencing p  is not safe outside the .\r\n\r\n~~~~~~~~~~cpp\r\n// func.cpp\r\nvoid func(int* p) {\r\n    if(p == NULL) {\r\n        printf(""p is null!"");\r\n    }\r\n\r\n    printf(""p is %d"", p);\r\n}\r\n~~~~~~~~~~\r\n\r\nRun TscanCode:\r\n ;\r\n* ;\r\n* ;\r\n\r\nFor now, codes under  are only for TscanCode  version,  and  version are in the internal review process. Sorry for the inconvenience.\r\n\r\n'"
"A stack for data mining using Spark2, H2O, R and Zeppelin running on Cloudera Hadoop Distribution","b'# Spark2-H2O-R-Zeppelin\nA stack for data mining using Spark2, H2O, R and Zeppelin running on Cloudera Hadoop Distribution\n\n# Spark2 Setup\n\n## Hadoop Version (tested with CDH5.8)\n$hadoop version\n  Hadoop 2.6.0-cdh5.11.0\n\n## Download Spark \nhttp://spark.apache.org/downloads.html\nDownload Spark: spark-2.2.0-bin-hadoop2.6.tgz\nwget http://apache.mirrors.ionfish.org/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.6.tgz\n\n## Extract Spark2 downloaded file\n- sudo mkdir /opt/spark\n- sudo chown -R cloudera:cloudera /opt/spark\n- cp /mnt/working/spark-2.2.0-bin-hadoop2.6.tgz /opt/spark\n- tar xvzf /opt/spark/spark-2.2.0-bin-hadoop2.6.tgz\n-  ln -s /opt/spark/spark-2.2.0-bin-hadoop2.6.tgz /opt/spark/current\n\n## Update conf/spark-env.sh\n- SPARK_HOME=/opt/spark/current\n- HADOOP_CONF_DIR=/etc/hive/conf\n\n## Update conf/spark-defaults.conf\n- spark.master                       yarn\n- spark.yarn.jars                    hdfs://localhost:8020/user/cloudera/spark-2.2.0-bin-hadoop2.6/\n\n## Create HDFS folder /user/cloudera (if not present)\n- sudo -u hdfs hdfs dfs -mkdir /user/cloudera\n- sudo -u hdfs hdfs dfs -chown -R cloudera /user/cloudera\n- hdfs dfs -mkdir spark-2.2.0-bin-hadoop2.6\n- hdfs dfs -copyFromLocal jars/  spark-2.2.0-bin-hadoop2.6\n\n## Test Spark2 Installation\n- $ ./bin/run-example SparkPi 10 --master yarn\n- $ ./bin/spark-shell --master yarn\n- $ ./bin/pyspark\nYarn cluster mode\n- $ ./bin/spark-submit --class org.apache.spark.examples.SparkPi     --master yarn     --deploy-mode cluster     --driver-memory 4g     --executor-memory 2g     --executor-cores 1     --queue thequeue     examples/jars/spark-examples*.jar     10\nYarn client mode\n- ./bin/spark-submit --class org.apache.spark.examples.SparkPi     --master yarn     --deploy-mode client     --driver-memory 4g     --executor-memory 2g     --executor-cores 1     --queue thequeue     examples/jars/spark-examples*.jar     10\n\n# H2O Sparkling-Water Setup\n\n## Download Sparkling-Water\nhttp://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.0/0/sparkling-water-2.0.0.zip\n\n## Update sparkling-env.sh\n- SPARK_HOME=/opt/spark/current\n- MASTER=yarn\n\n## Copy Sparkling-Water Fat jar\n- cp /opt/sparkling-water/current/assembly/build/libs/sparkling-water-assembly_2.11-2.0.0-all.jar  /opt/spark/current/jars\n\n## Test Sparkling-Water Installation\n- /opt/spark/current/bin/spark-submit --master=yarn --class water.SparklingWaterDriver --conf ""spark.yarn.am.extraJavaOptions=-XX:MaxPermSize=384m -Dhdp.version=current""  --driver-memory=8G --num-executors=3 --executor-memory=3G --conf ""spark.executor.extraClassPath=-XX:MaxPermSize=384m -Dhdp.version=current""  /opt/spark/current/jars/sparkling-water-assembly_2.11-2.2.2-all.jar\n\n# Install R\n\n$ sudo yum install R\n$ sudo yum install libxml2-devel\n$ sudo yum install libcurl-devel\n\n- install.packages(knitr, repos=""http://cran.rstudio.com/"",dependencies = TRUE)\n- install.packages(data.table, repos=""http://cran.rstudio.com/"",dependencies = TRUE)\n- install.packages(curl, repos=""http://cran.rstudio.com/"",dependencies=TRUE)\n- install.packages(""httr"", repos=""http://cran.rstudio.com/"", dependencies=TRUE)\n- install.packages(""plotly"", repos=""http://cran.rstudio.com/"", dependencies=TRUE)\n- install.packages(""devtools"", repos=""http://cran.rstudio.com/"", dependencies=TRUE)\n- devtools::install_github(""ropensci/plotly"")\n- devtools::install_github(ramnathv/rCharts)\n\n# Apache Zeppelin\n\n## Download Zeppelin \nhttps://zeppelin.apache.org/download.html\nzeppelin-0.7.3-bin-all.tgz\nwget http://mirror.reverse.net/pub/apache/zeppelin/zeppelin-0.7.3/zeppelin-0.7.3-bin-all.tgz\n\n## Update /opt/zeppelin/current/conf/zeppelin-env.sh\n- export MASTER=yarn\n- export SPARK_HOME=/opt/spark/current\n- export SPARK_APP_NAME=zeppelin-cdh\n- export HADOOP_CONF_DIR=/etc/hive/conf\n- export SPARK_SUBMIT_OPTIONS=""--jars /opt/spark/current/jars/sparkling-water-assembly_2.11-2.2.2-all.jar""\n\n## Run Zeppelin with Spark2, Sparkling-water, and R\n- /opt/zeppelin/current/bin/zeppelin.sh -Pspark-2.2\n\n## Test Zeppelin Installation\nhttp://localhost:8080/#/\n\n- %spark\n- import org.apache.spark.sql.\n- val sqlContext = new SQLContext(sc)\n- import sqlContext.implicits.\n- import org.apache.spark.h2o.\n- val h2oContext = H2OContext.getOrCreate(sc) \n- import h2oContext. \n\n- val df: DataFrame = sc.parallelize(1 to 1000, 100).map(v => IntHolder(Some(v))).toDF\n- val hf = h2oContext.asH2OFrame(df)\n- val newRdd = h2oContext.asDataFrame(hf)(sqlContext)\n\n# Oracle Access\n\n## Use the ojdbc7.jar in the lib folder as it has the file defaultConnectionProperties.properties file updated with oracle.jdbc.timezoneAsRegion=false\n\n## Use the Postgres Interpreter\n- postgresql.driver.name\toracle.jdbc.driver.OracleDriver\n- postgresql.max.result\t1000\n- postgresql.password\t    [PASSWORD]\n- postgresql.url\t        jdbc:oracle:thin:@[HOST_IP]:[HOST_PORT]:[SID]\n- postgresql.user\t        [USERNAME]\n\nDependencies\n/opt/zeppelin/current/lib/ojdbc7.jar\n\n## Add Oracle jdbc driver to Spark Interpreter\n\nDependencies\n/opt/zeppelin/current/lib/ojdbc7.jar\n\n## Test Zeppelin to access Oracle using %psql\n- %psql\n- SELECT * FROM DUAL\n\n## Test Zeppelin to access Oracle using %spark\n- %spark\n- sc.version\n-- val pdf = sqlContext.load(""jdbc"", Map(""url"" -> ""jdbc:oracle:thin:[USERNAME]/[PASSWORD]@[HOST_IP]:[HOST_PORT]:[SID]"", ""driver"" -> ""oracle.jdbc.driver.OracleDriver"", ""dbtable"" -> ""dual"") )\n- pdf.printSchema()\n- pdf.registerTempTable(""pdf"")\n\n- %sql SELECT count() FROM pdf\n\n# Vertica\n\n# Use the vertica-jdbc-8.0.0-1.jar in the lib folder\n\n## Use JDBC Interpreter\n- default.driver\tcom.vertica.jdbc.Driver\n- default.password\t[PASSWD]\n- default.url\tjdbc:vertica://[HOST]:[HOST_PORT]/[DB]?user=[USERNAME]&password=[PASSWD]\n- default.user\t[USERNAME]\n\nDependencies\n/opt/zeppelin/current/lib/vertica-jdbc-8.0.0-1.jar\n\n## Test Zeppelin to access Vertica using %jdbc\n- %jdbc\n- SELECT count() FROM [SCHEMA].[TABLE]\n\n## Test Zeppelin to access Vertica using %spark\n- %spark\n- sc.version \n- val pdfv = sqlContext.load(""jdbc"", Map(""url"" -> ""jdbc:vertica://[HOST]:[PORT]/[DB]?user=[USERNAME]&password=[PASSWD]"", ""driver"" -> ""com.vertica.jdbc.Driver"", ""dbtable"" -> ""[SCHEMA].[TABLE]"", ""fetchsize"" -> ""100"") )\n- pdfv.printSchema()\n- pdfv.registerTempTable(""pdfv"")\n\n- %sql SELECT * FROM pdfv\n\n## Impala\n/opt/zeppelin/current/lib/ojdbc7.jar\t\n/tmp/toSratch/2.5.36.1056/ImpalaJDBC41.jar\t\n/opt/zeppelin/current/lib/vertica-jdbc-8.0.0-1.jar\t\n/tmp/toSratch/2.5.36.1056/commons-logging-1.1.1.jar\t\n/tmp/toSratch/2.5.36.1056/hive_metastore.jar\t\n/tmp/toSratch/2.5.36.1056/hive_service.jar\t\n/tmp/toSratch/2.5.36.1056/httpclient-4.1.3.jar\t\n/tmp/toSratch/2.5.36.1056/httpcore-4.1.3.jar\t\n/tmp/toSratch/2.5.36.1056/libfb303-0.9.0.jar\t\n/tmp/toSratch/2.5.36.1056/libthrift-0.9.0.jar\t\n/tmp/toSratch/2.5.36.1056/log4j-1.2.14.jar\t\n/tmp/toSratch/2.5.36.1056/ql.jar\t\n/tmp/toSratch/2.5.36.1056/slf4j-api-1.5.11.jar\t\n/tmp/toSratch/2.5.36.1056/slf4j-log4j12-1.5.11.jar\t\n/tmp/toSratch/2.5.36.1056/TCLIServiceClient.jar\t\n/tmp/toSratch/2.5.36.1056/zookeeper-3.4.6.jar\n\n# References\nhttps://www.linkedin.com/pulse/running-spark-2xx-cloudera-hadoop-distro-cdh-deenar-toraskar-cfa\nhttps://github.com/h2oai/sparkling-water/blob/master/DEVEL.md#SparklingWaterZeppelin\nhttp://www.cloudera.com/documentation/enterprise/5-8-x/topics/cdh_ig_running_spark_on_yarn.html\n- find IPAddress: docker inspect [container_id] | grep IPAddress\n- sudo iptables -t nat -A DOCKER -p tcp --dport 8080 -j DNAT --to-destination [container_ip]:8080\n- sudo iptables -t nat -A POSTROUTING -s [container_ip] -j MASQUERADE -p tcp --dport 8080 -d [container_ip]\nRedhat 6.5 if yum install R fails\n""wget http://mirror.centos.org/centos/6/os/x86_64/Packages/lapack-devel-3.2.1-4.el6.x86_64.rpm\nwget http://mirror.centos.org/centos/6/os/x86_64/Packages/blas-devel-3.2.1-4.el6.x86_64.rpm\nwget http://mirror.centos.org/centos/6/os/x86_64/Packages/texinfo-tex-4.13a-8.el6.x86_64.rpm\nwget http://vault.centos.org/6.2/updates/x86_64/Packages/libicu-devel-4.2.1-9.1.el6_2.x86_64.rpm\nsudo yum localinstall *.rpm\n\n\n'"
Repository for my scientific initiation project on audio thumbnailing.,"b'# audio-thumbnailing\nRepository for my scientific initiation project on audio thumbnailing. \n\n## Usage Requirements\n        * python 3\n        * jupyter-notebook\n        * numpy\n        * librosa\n\n## References\n* Cooper, Matthew L., and Jonathan Foote. ""Automatic Music Summarization via Similarity Analysis."" ISMIR. 2002.\n* M\xc3\xbcller, Meinard, Peter Grosche, and Nanzhu Jiang. ""A Segment-Based Fitness Measure for Capturing Repetitive Structures of Music Recordings."" ISMIR. 2011.\n* Bartsch, Mark A., and Gregory H. Wakefield. ""Audio thumbnailing of popular music using chroma-based representations."" IEEE Transactions on multimedia 7.1 (2005): 96-104.\n'"
Curated list of Python resources for data science.,"b'# Awesome Data Science with Python\n\n> A curated list of awesome resources for practicing data science using Python, including not only libraries, but also links to tutorials, code snippets, blog posts and talks.  \n\n#### Core\n - Data structures built on top of .  \n - Core ML library, .  \n - Plotting library.  \n - Data visualization library based on matplotlib.  \n - Descriptive statistics using .  \n - Helpful  class.  \n - Missing data visualization.  \n - VSCode plugin to display .csv files with nice colors.  \n\n#### General Python Programming\n  \n - Manage multiple Python versions on your system.  \n - Dependency management.  \n - Python project template generator.  \n - Configuration management.  \n - Python project management.  \n - Extension of itertools.  \n - Progress bars for for-loops. Also supports .  \n - Python logging.  \n\n\n#### Pandas Tricks, Alternatives and Additions\n - Large collection of pandas tricks.  \n - Multi-threaded alternative to pandas.  \n - Extends pandas to n-dimensional arrays.  \n - Write custom accessors like  and .   \n - Efficiently run SQL queries on pandas DataFrame.  \n\n#### Pandas Parallelization\n - Parallelization library for faster pandas .  \n - Out-of-Core DataFrames.  \n - Parallelize pandas operations.  \n - Apply any function to a pandas DataFrame faster.   \n\n#### Environment and Jupyter\n  \n - IPython kernel for Jupyter with additional features.  \n - Open Jupyter Notebooks with doubleclick.  \n - Parameterize and execute Jupyter notebooks, .  \n - Diff two notebook files, Alternative GitHub App: .  \n - Turn Jupyter notebooks into presentations.  \n - Pandas  sorting.  \n - DataFrame visualization within Jupyter.  \n - GUI for viewing, plotting and analyzing Pandas DataFrames.  \n - View and analyze Pandas data structures, integrating with Jupyter.  \n - Interactive tables in Jupyter.  \n - More convenient way of writing mathematical equations in Jupyter.  \n - Productionize and schedule Jupyter Notebooks.  \n - Intuitive GUI for tables.  \n - Turn Jupyter notebooks into standalone web applications.  \n - Voila grid layout.  \n\n#### Extraction\n - Extract text from any document.  \n\n#### Big Data\n -  for big data, , .  \n,  - Pandas  for big data and machine learning library, , , , , .  \n - Helpful  class for out-of-memory dataframes.  \n - Data Table for big data support.  \n - GPU DataFrame Library, .  \n - NumPy-like API accelerated with CUDA.  \n - Flexible, high-performance distributed execution framework.  \n - Fast NumPy array functions written in C.   \n - Data access library for parquet files by Uber.  \n - Distributed NumPy arrays.  \n - Feature engineering and preprocessing library for tabular data by Nvidia.  \n - Reading and writing large multi-dimensional arrays (Google).  \n\n#### Command line tools, CSV\n - Command line tool for CSV files.  \n - Sort large csv files.  \n\n#### Classical Statistics\n\n##### Correlation\n - Correlation between categorical, ordinal and interval variables.  \n\n##### Packages\n - Statistical tests.  \n - Instrumental variable and panel data models.  \n - Statistical tests.    \n - Statistical tests.  \n - Statistical post-hoc tests for pairwise multiple comparisons.   \nBland-Altman Plot ,  - Plot for agreement between two methods of measurement.  \n  \n\n##### Statistical Tests\n - Proportion test.  \n - Alternative to chi-square test, .  \n\n##### Comparing Two Populations\n - Friedman-Rafsky Test: Compare two population based on a multivariate generalization of the Runstest. ,   \n\n##### Interim Analyses / Sequential Analysis / Stopping\n - Wikipedia.  \n - Exact Sequential Analysis for Poisson and Binomial Data (R package).  \n - Uniform boundaries, confidence sequences, and always-valid p-values.  \n\n##### Visualizations\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n##### Talks\n  \n  \n\n##### Texts\n   \n   \n  \n  \n  \n  \n  \n    \n  \n   \n  \n  \n  \n,   \n  \n  \n  \n\n#### Epidemiology\n - Large tool suite for working with epidemiological data (R packages).    \n - Computation, handling, visualisation and simple modelling of incidence (R package).  \n - Estimate time varying instantaneous reproduction number R during epidemics (R package) .  \n - Helpful  function for summary statistics (Table 1).  \n - Epidemiology analysis package, .  \n - Sensitivity analyses for unmeasured confounders (R package).  \n - Anscombe\xe2\x80\x99s Quartet, Causal Quartet,  and others (R package).    \n\n#### Exploration and Cleaning\n.  \n - Clean messy column names.  \n - Data / Schema validation.  \n - Imputations.  \n - Matrix completion and imputation algorithms.  \n - Resampling for imbalanced datasets.  \n - Time series preprocessing: Denoising, Compression, Resampling.  \n - Utility functions ()  \n\n#### Noisy Labels\n - Machine learning with noisy labels, finding mislabelled data, and uncertainty quantification. Also see awesome list below.  \n - Find bad or noisy labels.\n\n#### Train / Test Split\n - Stratification of multilabel data.  \n\n#### Feature Engineering\n - Using df.pipe()  \n  \n - Pipeline, .  \n - Pipelines for DataFrames.  \n - Custom transformers for pipelines.  \n - Categorical encoding of variables, .  \n - Encoding dirty categorical variables.  \n - R-like syntax for statistical models.  \n - LDA.  \n - Automated feature engineering, .  \n - Time series feature engineering.  \n - Time series feature engineering by Google.  \n - Concurrent data pipelines.  \n - Encoders, transformers, etc.  \n\n#### Computer Vision\n  \n\n#### Feature Selection\n, ,     \nBlog post series - , , ,   \nTutorials - ,   \n - Feature selection.  \n - Feature selection using permutation importance.  \n - Feature selection algorithms.  \n - Stability selection.  \n - Relief-based feature selection algorithms.  \n - Genetic feature selection.  \n - Feature selection, , .  \n - Boruta feature selection algorithm + shapley values.  \n - Feature selection package.  \n - Exhaustive feature selection.     \n - Xgboost feature selection algorithm.  \n - Instance-wise Variable Selection using Neural Networks.  \n - Subsetting Features of Tabular Data for Self-Supervised Representation Learning, AstraZeneca.  \n - Maximum Relevance and Minimum Redundancy Feature Selection, .  \n - All Relevant Feature Selection.  \n - Variable Selection Using Random Forests (R package) .  \n - Feature Selection using Genetic Algorithm.  \n\n#### Subset Selection\n - Selecting subsets of data sets to train machine learning models quickly.  \n - Index data for fast lookup by any combination of fields.  \n\n#### Dimensionality Reduction / Representation Learning\n\n##### Selection\nCheck also the Clustering section and self-supervised learning section for ideas!  \n  \n  \nPCA -     \nAutoencoder -   \nIsomaps -     \nLLE -   \nForce-directed graph drawing -     \nMDS -   \nDiffusion Maps -   \nt-SNE -     \nNeRV - ,   \nMDR -   \nUMAP -   \nRandom Projection -   \nIvis -    \nSimCLR -   \n\n##### Neural-network based\n - Vision Transformers for Representation Learning (Microsoft).  \n - Semi-supervised dimensionality reduction of Multi-Class, Multi-Label data (sequencing data) .  \n\n##### Packages\n.  \n, . \n and  - PCA, t-SNE, MDS, Isomaps and others.  \nAdditional plots for PCA - Factor Loadings, Cumulative Variance Explained, ,   \n - Johnson-Lindenstrauss lemma, Gaussian random projection, Sparse random projection.  \n - Partial least squares, supervised estimators for dimensionality reduction and regression.  \n - Dimensionality reduction, factor analysis (PCA, MCA, CA, FAMD).  \nFaster t-SNE implementations: , , \n - Uniform Manifold Approximation and Projection, , , , .  \n - Hierarchical UMAP.  \n - Explore embeddings, interactive visualization (R package).  \n - Self-organizing map.  \n - Topological Data Analysis, , , , .  \n - Topological Data Analysis.  \n - Dimensionality reduction using Siamese Networks.  \n - Dimensionality reduction using triplets.  \n - , .  \n - Projection pursuit, Sufficient dimension reduction, Robust M-estimators.  \n - DatabionicSwarm (R package).  \n - Contrastive PCA.  \n - Sparse contrastive PCA (R package).  \n - Visualization library for large, high-dimensional data sets.  \n - Linear Optimal Low Rank Projection.  \n - Linear Sufficient Dimension Reduction (R package).  \n - Tool for visualizing high dimensional data.  \n\n#### Visualization\n, .  \n.  \n(Plotly,Seaborn, Holoviz, Altair)  \n - Dynamic visualization library, wrapper for , , .  \n - Better histograms, , .  \n - Fast histograms.  \n - Venn diagrams, .  \n - Draw stacked density plots (=ridge plots), .  \n - Categorical variable visualization, .  \n - ROC curves and other visualizations for ML models.  \n - Visualizations for ML models (similar to scikit-plot).  \n - Interactive visualization library, , .  \n - Plotting library.  \n - Animate plots build on matplotlib.  \n - ggplot for Python.  \n - Declarative statistical visualization library.  \n - Plotting library for IPython/Jupyter Notebooks.  \n - High-level plotting library built on top of .  \n - Decision tree visualization and model interpretation.  \n - Generate charts.  \n - Graph visualization (JS package).  \n - Navigatable 3D graph visualization (JS package).  \n - Triangle plots.  \n - Interactive visualizations for big data.  \n - High dimensional Interactive Plotting.  \n - Live Visualizations.  \n - Scatter density plots. Alternative to 2d-histograms.   \n - Complex heatmaps for multidimensional genomic data (R package).  \n - Visualize embeddings (t-SNE etc.) (R package).  \n - Matplotlib wrapper.  \n - Broad Institute tool matrix visualization and analysis software. , Tutorial: , , .  \n - Interactive 2D scatter plot widget for Jupyter.  \n\n#### Colors\n - Color palettes from .  \n - Collection of perceptually uniform colormaps.  \n - Color wheel for all named HTML colors.  \n\n#### Dashboards\n - Shiny for Python, .  \n - Dashboarding solution by Apache.  \n - Dashboarding solution. ,  , .  \n - Convert Python notebook to web app, .  \n - Dashboarding solution by plot.ly. .  \n - Dashboarding library by Facebook.  \n - Dashboarding solution.  \n - .  \n - Turn Jupyter notebooks into standalone web applications.  \n - Voila grid layout.  \n\n#### UI\n - Create UIs for your machine learning model.  \n\n#### Survey Tools\n - Sampling techniques for complex survey designs.  \n\n#### Geographical Tools\n - Plot geographical maps using the Leaflet.js library, .  \n - Google Maps for Jupyter notebooks.  \n - Plot geographical maps.  \n - Draw millions of points on a map.  \n - BallTree.  \n - Nearest neighbor descent for approximate nearest neighbors.  \n - Geocoding of addresses, IP addresses.  \nConversion of different geo formats: ,   \n - Tools for geographic data  \nLow Level Geospatial Tools (GEOS, GDAL/OGR, PROJ.4)  \nVector Data (Shapely, Fiona, Pyproj)  \nRaster Data (Rasterio)  \nPlotting (Descartes, Catropy)  \n.   \n - Python Spatial Analysis Library.  \n - Extract countries, regions and cities from a URL or text.  \n - Distorted maps based on population.  \n\n#### Recommender Systems\nExamples: , , , .  \n - Recommender, .  \n - Fast Collaborative Filtering for Implicit Feedback Datasets.  \n - Deep recommender models using PyTorch.  \n - Recommendation algorithms for both implicit and explicit feedback.  \n - Fast SVD.  \n\n#### Decision Tree Models\n, Intro to Gradient Boosting , ,     \n - Gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms, .  \n - Gradient boosting (GBDT, GBRT or GBM) library, , Methods for CIs: , .  \n - Gradient boosting.  \n -  Gradient boosting and general machine learning framework.  \n - Wrapper for xgboost, lightgbm, catboost etc.  \n - Confidence intervals for random forests.  \n - Generalized random forest.  \n - Decision tree visualization and model interpretation.  \n - Decision tree visualization.  \n - Feature Importance for RandomForests using Permuation Importance.  \nWhy the default feature importance for random forests is wrong:   \n - Bayesian Additive Regression Trees.  \n - Mixed Effects Random Forest for Clustering,   \n - Robust decision trees.  \n - Trees with linear models at the leaves.  \n\n#### Natural Language Processing (NLP) / Text Processing\n-, , .  \n, .  \n - NLP, doc2vec, word2vec, text processing, topic modelling (LSA, LDA), ,  for evaluation.  \nEmbeddings -  ([], []), , , .  \n - Vector embedding utility package.  \n - Visualization for topic modelling.  \n - NLP.  \n - NLP, helpful  with .  \n - NLP from Facebook.  \n - Efficient text classification and representation learning.  \n - Approximate nearest neighbor search.  \n - Approximate nearest neighbor search.  \n - Approximate nearest neighbor search.  \n - Cluster (word-)vectors to find topics.  \n - Probabilistic data structures for large data (MinHash, HyperLogLog).  \n - NLP Framework by Zalando.  \n - NLP Library.  \n - Turn Messenger, Hangouts, WhatsApp and Telegram chat logs into DataFrames.  \n - Collection for comparing distances between two or more sequences.  \n\n#### Bio Image Analysis\n  \n\n##### Tutorials\n - A biologists guide to planning and performing quantitative bioimaging experiments.  \n - Large collection of image processing workflows, including  and , ,  using  and others.  \n - Notebooks and associated  for a variety of image processing tasks.  \n\n##### Datasets\n - Cellpainting dataset.  \n - Datasets for 2D and 3D Biomedical Image Classification.  \n - Huge diverse dataset like ImageNet but for cell images.  \n - Gene Expression and Morphology Profiles.  \n - Cellpainting vs. L1000 assay.  \n\n#### Biostatistics / Robust statistics\n - Robust estimator of covariance, RMPV, , , .  \n - Weighted average of z-scores based on Spearman correlation.  \n - Simple adjustment of outliers.  \n\n#### High-Content Screening Assay Design\n  \n\n - Measure of statistical effect size.  \n - Measure of statistical effect size.  \n - Coefficient of variation.  \n - Strictly standardized mean difference.  \n - Assay quality measurement.  \n\n#### Microscopy + Assay\n - Calculate spectral overlap, bleed through for fluorescence microscopy dyes.  \n - Visualize the spectral compatibility of fluorophores (PerkinElmer).  \n - Thermofisher Spectrum Viewer.  \n - Calculate resolution of images (Nikon).  \n - Drug Layout for plates, , , .  \n\n##### Image Formats and Converters\nOME-Zarr - ,   \n - Various formats to zarr.  \n - Zarr to tiff.  \n - Wrapper for bioformats2raw to parallelize conversions with nextflow, .  \nREMBI model - Recommended Metadata for Biological Images, BioImage Archive: , , , ,   \n\n##### Matrix Formats\n - annotated data matrices in memory and on disk, .  \n - Multimodal omics framework.  \n - Multimodal Data (.h5mu) implementation.  \n - Zarr-based format for storing quantitative biological dynamics data.  \n\n#### Image Viewers\n - Image viewer and image processing tool.    \n - General purpose tool. Image viewer and image processing tool.  \n - Browser-based image viewer for zarr format.  \n - Browser-based image viewer for tiff files.  \n - Image viewer for high-content screening.  uses OMERO.    \n - Viewer and tool for building high-quality datasets and computer vision models.  \nImage Data Explorer - Microscopy Image Viewer, , .  \n - Microscopy Image Viewer, , .  \n - Web-based image annotation and classification tool, .  \n - Data labeling tool to segment images, .  \n\n#### Napari Plugins\n - Segment Anything Plugin.  \n - ChatGPT Plugin.  \n\n##### Image Restoration and Denoising\n - Image denoising.  \n - Unsupervised denoising method.  \n - Content-aware image restoration, .  \n\n##### Illumination correction\n - Illumination correction (CLAHE).  \n - Illumination correction method for optical microscopy.  \n - Background and Shading Correction of Optical Microscopy Images, .  \n\n##### Bleedthrough correction / Spectral Unmixing\n - Blind unmixing without reference spectra measurement,   \n - Flow cytometry. Includes Bleedthrough correction methods.  \nLinear unmixing in Fiji for Bleedthrough Correction - .  \nBleedthrough Correction using Lumos and Fiji - .  \nAutoUnmix - .  \n\n##### Platforms and Pipelines\n,  - Create image analysis pipelines.  \n - Framework to process high-content imaging data from UZH, .  \n - Deep and Machine Learning for Microscopy.  \n - Tools for 3D microscopy analysis,  and lots of other tutorials, interacts with napari.  \n - Image analysis.  \n\n##### Microscopy Pipelines\nLabsyspharm Stack see below.  \n - Bioimage analysis pipelines.  \n - Image processing pipeline on top of Dask.  \n - Image analysis platform.  \n - Image analysis pipeline using , , , .  \n\n##### Labsyspharm\n - Multiple-choice microscopy pipeline, , .  \n - Quantification of cell features.  \n - Quality assurance for microscopy images, .  \n - Whole-slide microscopy image stitching and registration.  \n - Spatial Single-Cell Analysis Toolkit.  \n\n##### Cell Segmentation\n - Review of cell segmentation algorithms, .  \nReview of organoid pipelines - .  \n - BioImage Model Zoo.  \n - Cell segmentation.  \n - Cell segmentation. , .  \n - Cell segmentation with Star-convex Shapes.  \n - Identifying Cells and Segmenting Tissue.  \n - Segment, classify, track and count cells. .   \n - 3D biomedical image segmentation.  \n - Tools for 3D segmentation, classical and deep learning methods.  \n - Python GUI for cell segmentation and tracking.  \n - Deep-Learning in Microscopy.  \n - Bringing the ZeroCostDL4Mic experience using Docker.  \n - Embedding-based Instance Segmentation.  \n - Segment Anything (SAM) from Facebook.  \n - Segment Anything for Microscopy.  \n - Segment Everything Everywhere All at Once from Microsoft.  \n - Cell segmentation, .  \n - Fiji plugin for image segmentation.  \n\n##### Cell Segmentation Datasets\n - Cell images.  \n - Cell images.  \n - Cell images.  \n - Neurons.  \n - 2D + 3D images.  \n - Annotation of the EPFL Hippocampus dataset.  \n - Stardist example training and test dataset.  \n\n##### Evaluation\n - Cell segmentation performance evaluation without Ground Truth labels, .  \n\n##### Feature Engineering Images\n  \n - Biological image analysis.   \n - Image processing.  \n - Regionprops: area, eccentricity, extent.  \n - Zernike, Haralick, LBP, and TAS features, .   \n - Radiomics features from medical imaging.  \n - Elliptical feature descriptor, approximating a contour with a Fourier series.  \n - Faster image processing operations.  \n\n#### Domain Adaptation / Batch-Effect Correction \n, .  \n.  \n - Fuzzy k-means and locally linear adjustments.  \n - Batch-effect correction, .  \n - Nonnegative matrix factorization.  \n - Batch removal. .  \n - Correcting for Batch Effects Using Wasserstein Distance, , .   \n - Awesome Domain Adaptation Python Toolbox.  \n - Various neural network models for domain adaptation.  \n\n##### Sequencing\n.  \n - Analyzing RNA-seq data.  \n - Interactive explorer for single-cell transcriptomics data.  \n - Analyze single-cell gene expression data, .  \n - Beyond single-cell analysis.  \n - Deep Learning for Genomics.  \n - Drug responses in the context of the Genomics of Drug Sensitivity in Cancer project, ANOVA, IC50, MoBEM, .  \n - Analysis of single-cell spatial transcriptomics data.  \n\n##### Drug discovery\n - Drug Discovery and Development.  \n - Deep Learning Based Molecular Modelling and Prediction Toolkit.  \n\n#### Neural Networks\n - Stanford CS class.  \n - Computational Systems Biology: Deep Learning in the Life Sciences.  \n - Calculate output dimensions of Conv2D layer.  \n.  \n.  \n\n##### Tutorials & Viewer\n - Practical Deep Learning for Coders.  \n - Neural Network course by Google.  \nFeature Visualization: ,   \n  \n,     \n - Image Viewer.  \n\n##### Image Related\n - More sophisticated image preprocessing.  \n - Image augmentation library.  \n - Preprocess images.  \n - Wrapper around imgaug and other libraries.  \n - Image augmentation from Google.  \n - Image augmentation, feature extraction and loss functions.  \n - Image, audio, text, video augmentation from Facebook.  \n - Faster image processing operations.  \n\n##### Lossfunction Related\n - List of loss functions for medical image segmentation.  \n\n##### Activation Functions\n - Rational activation functions.  \n\n##### Text Related\n - Utilities for pre-processing text for deep learning in Keras.   \n - Ready-to-use LSTM for text generation.  \n - Text generation.  \n\n##### Neural network and deep learning frameworks\n - Framework for segmentation, classification and lots of other computer vision tasks.  \n - Deep learning framework, .  \n - Deep learning framework, .  \n\n##### Libs General\n - Neural Networks on top of , .  \n - Keras community contributions.  \n - Hyperparameter tuning for Keras.  \n - Keras + Hyperopt: Convenient hyperparameter optimization wrapper.  \n - Distributed Deep learning with Keras & Spark.  \n - Neural Networks on top of TensorFlow.  \n - Neural Networks on top of TensorFlow, .  \n - TensorFlow for applied reinforcement learning.  \n - AutoML for deep learning.  \n - Plot neural networks.  \n - Neural network interpretability, .  \n - Interpretability method.  \n - Optimizer that trains as fast as Adam and as good as SGD, .  \n - Adversarial examples that fool neural networks.  \n - Training metrics.  \n - Pretrained models.  \n - Visualizer for deep learning and machine learning models.  \n - Fast dataloader.  \n\n##### Libs PyTorch\n    \n - Scikit-learn compatible neural network library that wraps PyTorch, , .  \n - Neural Networks in PyTorch.  \n - PyTorch image models.  \n - Highlevel library for PyTorch.  \n - Deep Learning in Computer Vision.  \n - Collection of optimizers for PyTorch.  \n - Wrapper around PyTorch.  \n - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.  \n - Deep learning in healthcare imaging.  \n - Image transformations, epipolar geometry, depth estimation.  \n - Nice model summary.  \n - Inspect tensors, mean, std, inf values.  \n\n##### Distributed Libs\n - Distributed TensorFlow Keras and PyTorch.  \n - Distributed training framework for TensorFlow, Keras, PyTorch, and Apache MXNet.  \n\n##### Architecture Visualization\n.  \n - Viewer for neural networks.  \n - Visualize Keras networks.  \n\n##### Object detection / Instance Segmentation\n - Guide for choosing correct image analysis metrics, ,   \n  \n - Fully convolutional model for real-time instance segmentation.  \n,  - Scalable and Efficient Object Detection.  \n - Object Detection (Mask R-CNN) by Facebook.  \n - Object Detection and Instance Recognition.  \n - Object detection.  \n - Fully Convolutional One-Stage Object Detection.  \n - Real-time 2D object tracking.  \n -  Detector with image classes that can use image-level labels (facebookresearch).  \n - Image segmentation, classification, metric-learning, object detection, pose estimation.  \n\n##### Image Classification\n - Neural network.   \n - Neural network.   \n - PyTorch image classification networks: ResNet, ResNeXt, EfficientNet, and RegNet (by Facebook).  \n\n##### Applications and Snippets\n - Semantic Image Synthesis.  \n, ,   \n - Super-scaling using a Residual Dense Network.  \nCell Segmentation - , Blog Posts: ,   \n - Deep learning models.  \n\n##### Variational Autoencoders (VAEs)\n  \n - BetaVAE, FactorVAE, BetaTCVAE, DIP-VAE.  \n - Ladder Variational Autoencoders (LVAE).  \n - Unifying Generative Autoencoder implementations.  \n\n##### Generative Adversarial Networks (GANs)\n  \n - List of Generative Adversarial Networks.  \n - Various image-to-image tasks.  \n  \n  \n  \n - PyTorch GAN implementations.  \n\n##### Transformers\n - Simple and Efficient Design for Semantic Segmentation with Transformers.  \n - Efficient self-supervised Vision Transformers.  \n - More efficient transformer because of approximate self-attention.  \n\n##### Deep learning on structured data\n  \n\n##### Graph-Based Neural Networks\n  \n  \n  \n - Open Graph Benchmark, Benchmark datasets.  \n - Graph library.  \n - RAPIDS, Graph library on the GPU.  \n - Various methods for deep learning on graphs.  \n - Deep Graph Library.  \n - Build graph networks in TensorFlow, by DeepMind.  \n\n#### Model conversion\n - Compile trained ML models into tensor computations (by Microsoft).  \n\n#### GPU\n - RAPIDS, Run traditional tabular ML tasks on GPUs, .  \n - GBDTs and Random Forest.  \n - Support Vector Machines.  \nLegate Numpy - Distributed Numpy array multiple using GPUs by Nvidia (not released yet) .  \n\n#### Regression\nUnderstanding SVM Regression: , ,   \n\n - Multivariate Adaptive Regression Splines (MARS), .  \n - Generalized Additive Models (GAMs), .  \n - Generalized Low Rank Models.  \n - Specialized distribution for zero inflated targets, .  \n - Estimating prediction intervals.  \n - Regression and Spline models.  \n\n#### Polynomials\n - Orthogonal polynomials in all shapes and sizes.  \n\n#### Classification\n,   \n  \n  \n - Dynamic classifier and ensemble selection.  \n - Create and tune classifier based on your rule set.  \n\n#### Metric Learning\n  \n  \n - Supervised and weakly-supervised metric learning algorithms.  \n - PyTorch metric learning.  \n - Methods for deep metric learning.  \n - Metric learning using siamese neural networks.  \n - Metric learning.  \n\n#### Distance Functions\n - All kinds of distance metrics.  \n - Earth Movers Distance / Wasserstein distance, similarity between histograms. ,    \n  - Distance correlation and related Energy statistics.  \n - Kernel norms, Hausdorff divergences, Debiased Sinkhorn divergences (=approximation of Wasserstein distance).  \n\n#### Self-supervised Learning\n - MoCo, SimCLR, SimSiam, Barlow Twins, BYOL, NNCLR.  \n - Self-Supervised Learning with PyTorch: RotNet, Jigsaw, NPID, ClusterFit, PIRL, SimCLR, MoCo, DeepCluster, SwAV.  \n\n#### Clustering\n.  \n.  \n - Dendrogram, Tanglegram  \n - Clustering algorithm, , .  \n - All sorts of clustering algorithms.  \n -  Fundamental Clustering Problems Suite (R package).  \n - Generalized k-means clustering using a mixture of Gaussian distributions, .  \n - Similarity search library and toolkit for evaluation of k-NN methods.  \n - Mixed Effects Random Forest for Clustering,   \n - Hierarchical clustering algorithm based on t-SNE.  \n - Pure Python implementation of the Self Organizing Maps.  \n, , , .  \n - Clustering by community detection.  \n - Clustering of single cell data (RNA). Improvement of phenograph, .  \n - Hyperbolic Hierarchical Clustering.  \n - Improved k-Medoids Clustering.  \n - Comparing dendrograms (R package).  \n - Deep Clustering With An Unknown Number of Clusters.  \n\n##### Clustering Evalutation\n\n* \n* \n* \n* \n* \n* , \n* \n*  - The similarity of two sets of biclusters.\n\n   \n - Various methods for clustering and cluster validation (R package).  \n* Minimum distance between any two clusters\n* Distance between centroids\n* p-separation index: Like minimum distance. Look at the average distance to nearest point in different cluster for p=10% ""border"" points in any cluster. Measuring density, measuring mountains vs valleys\n* Estimate density by weighted count of close points \n\nOther measures:\n* Within-cluster average distance\n* Mean of within-cluster average distance over nearest-cluster average distance (silhouette score)\n* Within-cluster similarity measure to normal/uniform\n* Within-cluster (squared) distance to centroid (this is the k-Means loss function)\n* Correlation coefficient between distance we originally had to the distance the are induced by the clustering (Huberts Gamma)\n* Entropy of cluster sizes\n* Average largest within-cluster gap\n* Variation of clusterings on bootstrapped data\n\n#### Multi-label classification\n - Multi-label classification, .  \n\n#### Signal Processing and Filtering\n, , .  \n.  \n - Chapter 3 has good introduction to Bessel, Butterworth and Chebyshev filters.  \n.  \n - Focuses on intuition using Jupyter Notebooks. Includes Bayesian and various Kalman filters.  \n for FIR and IIR filters, .  \n - Kalman filtering and optimal estimation library.  \n\n#### Filtering in Python\n\n* \n* ,   \n - Choose appropriate .  \n\n#### Geometry\n - Computations and statistics on manifolds with geometric structures.  \n\n#### Time Series\n - Time series analysis,  , , .  \n - Time series prediction library by Facebook.  \n - Time series prediction library by Facebook.  \n - Time series prediction built on PyTorch.  \n,  - Wrapper for (Auto-) ARIMA.  \n - Time series forecasting framework (R package).  \n - Time series prediction algorithms (ARIMA, GARCH, GAS, Bayesian).  \n - Automated Time Series Models.  \n - Time series prediction and decomposition library.  \n - Hierarchical Time Series Forecasting using Prophet.  \n - Hierarchical Temporal Memory (HTM) for Time Series Prediction and Anomaly Detection.  \n - LSTM and others, examples: , , seq2seq: , , ,   \n - Preprocessing: Denoising, Compression, Resampling.  \n - Time series feature engineering.  \n - Time series feature extraction.  \n - Data structures and algorithms for loading, processing, and analyzing time series data.  \n - General tools for Astronomical Time Series, .  \n - shapelets, .  \n - Time series clustering and classification, , .  \n - Analysis of Groundwater Time Series.  \n - Dynamic Time Warp Distance.  \n - Time Series Forecasting (R package).  \n - Bayesian time series modelling (, )  \n - Automatic Time Series Forecasting.  \n - Anomaly Detection and Correlation library from Linkedin.  \n - Detecting patterns and anomalies, , , .  \n - Another matrix profile library.  \n - Seismology package. Useful  function.  \n - Robust Seasonal-Trend Decomposition.  \n - Time Series library.  \n - Time series transformation and classification, .  \nTurn time series into images and use Neural Nets: , .  \n,  - Toolbox for (deep) learning with time series.   \n - Time Series Anomaly Detection.  \n - Time Series classification using random convolutional kernels.  \n - Anomaly Detection for time series.  \n - Time Series library.  \n - ML powered analytics engine for outlier/anomaly detection and root cause analysis.  \n\n##### Time Series Evaluation\n - Sklearn time series split.  \n - Evaluation with gap.  \n\n#### Financial Data and Trading\nTutorial on using cvxpy: ,   \n - Read stock data.  \n - Read stock data from Yahoo Finance.  \n - Read stock data from various sources.  \n - Technical analysis library.  \n - Backtesting for trading strategies.  \n - Find high moving stocks before they move using anomaly detection and machine learning.  \n - Financial functions.  \n - Backtesting algorithms.  \n - Commission-free trading through API.  \n - Eigen portfolios, minimum variance portfolios and other algorithmic investing strategies.  \n - Quantitative finance tools in TensorFlow, by Google.  \n - Portfolio management.  \n - Portfolio optimization and strategic asset allocation.  \n - Terminal.  \n - Financial markets data visualization.  \n\n##### Quantopian Stack\n - Portfolio and risk analytics.  \n - Algorithmic trading.  \n - Performance analysis of predictive stock factors.  \n - Financial risk metrics.  \n - Calendars for various securities exchanges.  \n\n#### Survival Analysis\n.  \n - Survival analysis, Cox PH Regression, , .  \n - Survival analysis.  \n -    \n - Survival analysis, .  \n - Analyze time lagged conversions.  \nRandomSurvivalForests (R packages: randomForestSRC, ggRandomForests).  \n - Survival analysis.  \n - Fully Parametric Survival Regression.  \n - Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Events.  \n\n#### Outlier Detection & Anomaly Detection\n - Isolation Forest and others.  \n - Outlier Detection / Anomaly Detection.  \n - Extended Isolation Forest.  \n - Anomaly detection (R package).  \n - Anomaly Detection and Correlation library from Linkedin.  \nDistances for comparing histograms and detecting outliers - : , , , .  \n - Anomaly detection library based on singular spectrum transformation.  \n - Detect anomalies in multivariate time series data using LSTMs.  \n - Anomaly Detection for time series.  \n - Robust Random Cut Forest algorithm for anomaly detection on streams.  \n\n#### Concept Drift & Domain Shift\n - Drift Detection for PyTorch Models.  \n - Algorithms for outlier, adversarial and drift detection.  \n - Evaluate and monitor ML models from validation to production.  \n.  \n.  \n\n#### Ranking\n - Large-scale linear classification, regression and ranking.  \n\n#### Causal Inference\n  \n - Video Lecture Series, Bayesian Statistics, Causal Models, , , , , .  \n  \n - Estimate causal effects.  \n - Causal Impact Analysis ().  \n - Modular causal inference analysis and model evaluations by IBM, .  \n - Causal inference by Uber.  \n - Causal inference by Booking.com.  \n - Causal analysis using observational datasets.  \n - Machine Learning + Causal inference, , , .  \n - Heterogeneous Treatment Effects Estimation by Microsoft.  \n\n\n##### Papers\n  \n  \n\n#### Probabilistic Modelling and Bayes\n,   \n - Bayesian modelling.  \n - Probabilistic programming with numpy, built on .  \n - Probabilistic modelling, .  \n - Probabilistic machine learning.  \n - Exploratory analysis of Bayesian models.  \n - Bayesian deep learning, generative models.  \n - Probabilistic modelling, inference, and criticism, , .  \n - Deep Universal Probabilistic Programming.  \n - Deep learning and probabilistic modelling, , , , .  \n - High-level Bayesian model-building interface on top of PyMC3.  \n - Infinite Neural Networks.  \n - Bayesian networks, parameter learning, inference and sampling methods.  \n\n#### Gaussian Processes\n,   \n - Gaussian process optimization.   \n - Gaussian processes (TensorFlow).  \n - Gaussian processes (PyTorch).  \n\n#### Stacking Models and Ensembles\n  \n - , ,  for model stacking.  \n - Stacking ML models.  \n - Stacking ML models.  \n - Ensemble learning.  \n - Combining ML models (stacking, ensembling).  \n\n#### Model Evaluation\n - Evaluate machine learning models (huggingface).  \n - Multi-class confusion matrix.  \n - Confusion matrix.  \nPlotting learning curve: .  \n - Learning curve.  \n - Receiver Operating Characteristic (ROC) curves.  \n\n#### Model Uncertainty\n - Uncertainty quantification.  \n - Predictive uncertainty quantification, calibration, metrics, and visualization.  \n\n#### Model Explanation, Interpretability, Feature Importance\n   \n,   \nscikit-learn -  (can be used on any trained classifier) and   \n - Explain predictions of machine learning models, , .  \n - Interpreting scikit-learns decision tree and random forest predictions.  \n - Explaining the predictions of any machine learning classifier, , .  \n - Create LIMEs for XGBoost.  \n - Inspecting machine learning classifiers and explaining their predictions.  \n - Leave One Feature Out Importance, .  \n - Generate feature contribution plots.  \n - Individual Conditional Expectation Plot Toolbox.  \n - Partial dependence plot toolbox, .  \n - Visualize and cluster partial dependence.  \n - Contrastive explanations.  \n - Collection of tools for explainable AI.  \n - Neural network interpretability.  \n - An eXplainability toolbox for machine learning.  \n - A toolbox to investigate neural network predictions.  \n - Explanations for ML models (R package).  \n - Fit interpretable models, explain models.  \n - Model interpretability.  \n - Interpretable ML package.  \n - Model interpretability and understanding for PyTorch.  \n\n#### Automated Machine Learning\n - Automated machine learning based on TensorFlow.  \n - Automated machine learning tool, optimizes machine learning pipelines.  \n - AutoML for deep learning.  \n - Toolkit for neural architecture search and hyper-parameter tuning by Microsoft.  \n - Automated machine learning.  \n - Automatically discover computer programs that can solve machine learning tasks from Google.  \n - Automated Machine Learning using scikit-learn xgboost, LightGBM and others.  \n\n#### Graph Representation Learning\n - Unsupervised learning on graphs.   \n - Graph representation learning with PyTorch.   \n - Graph representation learning with TensorFlow.   \n\n#### Convex optimization\n - Modelling language for convex optimization problems. Tutorial: ,   \n\n#### Evolutionary Algorithms & Optimization\n - Evolutionary computation framework (Genetic Algorithm, Evolution strategies).  \n - DSL for composable evolutionary algorithms, .  \n - Multiobjective optimization.  \n - Efficiently computes derivatives of numpy code.  \n - Derivation-free optimization.  \n - Sklearn-like interface for genetic programming.  \n - Optimization of expensive black-box functions.  \nOptometrist algorithm - .  \n - Neural architecture search.  \n - Evolutionary computation library built on Pytorch.  \n\n#### Hyperparameter Tuning\n - , .  \n - Hyperparameter search using genetic algorithms.  \n - Hyperparameter optimization.  \n - Hyperopt + sklearn.  \n - Hyperparamter optimization, .  \n -  for Hyperparameter search.  \n - Hyperparameter search with a focus on deep learning and deep reinforcement learning.  \n - Black box hyperparameter optimization.  \n - Scalable Bayesian optimisation.  \n - Bayesian optimization in PyTorch.  \n - Adaptive Experimentation Platform by Facebook.  \n - Hyperparameter optimization based on optuna.  \n\n#### Incremental Learning, Online Learning\nsklearn - , .  \n - Online machine learning.  \n - Online Learning algorithms.  \n\n#### Active Learning\n  \n - Active learning framework.  \n\n#### Reinforcement Learning\n,   \nIntro to Monte Carlo Tree Search (MCTS) - , ,   \nAlphaZero methodology - , , ,   \n - Library for reinforcement learning.  \n - Facebook RL framework.  \n\n#### Deployment and Lifecycle Management\n\n##### Workflow Scheduling and Orchestration\n - Run scripts and workflow graphs in Docker image using Google Life Sciences, AWS Batch, .   \n - Schedule and monitor workflows.  \n - Python specific workflow scheduling.  \n - Development, production and observation of data assets.  \n - Workflow orchestration.  \n - Workflow orchestration.  \n - CI/CD for Machine Learning Projects.  \n - Task scheduling.  \n - Task queue.  \n\n##### Containerization and Docker\n  \n  \n - Facilitates building Docker images.  \n\n##### Data Versioning, Databases, Pipelines and Model Serving\n - Version control for large files.  \n - Build data pipelines.  \n - Feature store. .  \n - Database for vector search applications.  \n - Serve ML models.  \n - Vector database for similarity search.  \n - Version and deploy your ML models following GitOps principles.  \n\n##### Data Science Related\n - Transpile trained ML models into other languages.  \n - Transpile trained scikit-learn estimators to C, Java, JavaScript and others.  \n - Manage the machine learning lifecycle, including experimentation, reproducibility and deployment.  \n - Command-line utilities to make it easier to run machine learning experiments.  \n - Package and deploy machine learning models for serving in production.  \n - Tool with focus on dependency graphs.  \n - Be notified when your training ends.  \n - Lifecycle Management Tool by Netflix.  \n - Deploy machine learning models.  \n - Experiment tracking and model registry.  \n - Experiment Manager, MLOps and Data-Management.  \n - MLOps.  \n - Deploy machine learning models.  \n - MLOPs.  \n\n#### Math and Background\n  \nGilbert Strang -   \nGilbert Strang -   \n\n#### Resources\n - Blog.   \n  \n  \n  \n   \n\n##### Guidelines \n - Guide to data sharing.  \n\n##### Books\n  \n  \n  \n\n##### Other Awesome Lists\n    \n    \n    \n    \n  \n    \n    \n    \n  \n  \n   \n   \n    \n   \n   \n   \n   \n   \n   \n  \n   \n  \n    \n  \n     \n   \n   \n  \n  \n  \n  \n   \n   \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n#### Lectures\n - YouTube Playlist.   \n\n#### Things I google a lot\n  \n  \n  \n\n## Contributing  \nDo you know a package that should be on this list? Did you spot a package that is no longer maintained and should be removed from this list? Then feel free to read the  and submit your pull request or create a new issue.  \n\n## License\n\n'"
The easy-to-use and developer-friendly enterprise CMS powered by Django,"b""##########\ndjango CMS\n##########\n.. image:: https://static.pepy.tech/badge/django-cms\n    :target: https://pepy.tech/project/django-cms\n    :alt: Downloads\n.. image:: https://img.shields.io/pypi/v/django-cms.svg\n    :target: https://pypi.python.org/pypi/django-cms/\n.. image:: https://img.shields.io/badge/wheel-yes-green.svg\n    :target: https://pypi.python.org/pypi/django-cms/\n.. image:: https://img.shields.io/pypi/l/django-cms.svg\n    :target: https://pypi.python.org/pypi/django-cms/\n.. image:: https://codeclimate.com/github/divio/django-cms/badges/gpa.svg\n   :target: https://codeclimate.com/github/divio/django-cms\n   :alt: Code Climate\n\nOpen source enterprise content management system based on the Django framework and backed by the non-profit django CMS Association ().\n\n*******************************************\nContribute to this project and win rewards\n*******************************************\n\nBecause django CMS is a community-driven project, we welcome everyone to  and _ for their contribution. Become part of a fantastic community and help us make django CMS the best open source CMS in the world.\n\n\n.. ATTENTION::\n\n    Please use the  branch as the target for pull requests for on-going development.\n\n    Security fixes will be backported to older branches by the core team as appropriate.\n\n\n********\nFeatures\n********\n\n* hierarchical pages\n* extensive built-in support for multilingual websites\n* multi-site support\n* draft/publish workflows\n* version control\n* a sophisticated publishing architecture, that's also usable in your own applications\n* frontend content editing\n* a hierarchical content structure for nested plugins\n* an extensible navigation system that your own applications can hook into\n* SEO-friendly URLs\n* designed to integrate thoroughly into other applications\n\nDeveloping applications that integrate with and take advantage of django CMS features is easy and well-documented.\n\nMore information on .\n\n************\nRequirements\n************\n\nSee the  in our documentation.\n\nSee the .\n\n\n***************\nGetting started\n***************\n\nThese  take you step-by-step through some key aspects of django CMS.\n\n\n*************\nDocumentation\n*************\n\nOur documentation working group maintains documentation for several versions of the project. Key versions are:\n\n* _ (default), for the current release version\n* , representing the latest build of the .\n\nThe dependencies for the docs are compiled by .\n\n\n***************************\nTest django CMS in our demo\n***************************\n\nThe demo platform is kindly provided by Divio, platinum member of the django CMS Association.\n\n.. image:: https://raw.githubusercontent.com/django-cms/django-cms/develop/docs/images/try-with-divio.png\n   :target: https://www.django-cms.org/en/django-cms-demo/\n   :alt: Try demo with Divio Cloud\n\n************\nGetting Help\n************\n\nPlease head over to our  or our _ for support.\n\n********************\nProfessional support\n********************\n\nChoose from a list of _ of the django CMS Association to get your website project delivered successfully.\n\nChoose a _ for your django CMS project and get your website online today.\n\n\n**************************\nThe django CMS Association\n**************************\n\nThe django CMS Association is a non-profit organization that was founded in 2020 with the goal to drive the success of django CMS, by increasing customer happiness, market share and open-source contributions. We provide infrastructure and guidance for the django CMS project.\n\nThe non-profit django CMS Association is dependent on donations to fulfill its purpose. The best way to donate is to become a member of the association and pay membership fees. The funding will be funneled back into core development and community projects.\n\n_.\n\n\n*******\nCredits\n*******\n\n* Includes icons from _.\n* Python tree engine powered by\n  _.\n* JavaScript tree in admin uses _.\n* Many thanks to\n  _\n  to django CMS!\n"""
" Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow ","b'char-rnn-tensorflow\n===\n\n\n\n\n\nMulti-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow.\n\nInspired from Andrej Karpathys .\n\n## Requirements\n- \n\n## Basic Usage\nTo train with default parameters on the tinyshakespeare corpus, run . To access all the parameters use .\n\nTo sample from a checkpointed model, .\nSampling while the learning is still in progress (to check last checkpoint) works only in CPU or using another GPU.\nTo force CPU mode, use  and  afterward\n(resp.  and  on Windows).\n\nTo continue training after interruption or to run on more epochs, \n\n## Datasets\nYou can use any plain text file as input. For example you could download  as such:\n\n\n\nThen start train from the top level directory using \n\nA quick tip to concatenate many small disparate  files into one large training file: .\n\n## Tuning\n\nTuning your models is kind of a ""dark art"" at this point. In general:\n\n1. Start with as much clean input.txt as possible e.g. 50MiB\n2. Start by establishing a baseline using the default settings.\n3. Use tensorboard to compare all of your runs visually to aid in experimenting.\n4. Tweak --rnn_size up somewhat from 128 if you have a lot of input data.\n5. Tweak --num_layers from 2 to 3 but no higher unless you have experience.\n6. Tweak --seq_length up from 50 based on the length of a valid input string\n   (e.g. names are <= 12 characters, sentences may be up to 64 characters, etc).\n   An lstm cell will ""remember"" for durations longer than this sequence, but the effect falls off for longer character distances.\n7. Finally once youve done all that, only then would I suggest adding some dropout.\n   Start with --output_keep_prob 0.8 and maybe end up with both --input_keep_prob 0.8 --output_keep_prob 0.5 only after exhausting all the above values.\n\n## Tensorboard\nTo visualize training progress, model graphs, and internal state histograms:  fire up Tensorboard and point it at your .  E.g.:\n\n\nThen open a browser to  or the correct IP/Port specified.\n\n\n## Roadmap\n- [ ] Add explanatory comments\n- [ ] Expose more command-line arguments\n- [ ] Compare accuracy and performance with char-rnn\n- [ ] More Tensorboard instrumentation\n\n## Contributing\nPlease feel free to:\n* Leave feedback in the issues\n* Open a Pull Request\n* Join the \n* Share your success stories and data sets!\n'"
The OpenTelemetry PHP Library,"b""# OpenTelemetry for PHP\n\n\n\n\n\nThis is the [<marko.inline.RawText object at 0x000001F254055310>] for the main components of  for PHP.\n\n## Documentation\n\nPlease read the official documentation: https://opentelemetry.io/docs/instrumentation/php/\n\n## Packages and versions\n\n| Package              | Latest                                                                                                                                                                                                                                                                                                                                                  |\n|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| API                  |                                                                                   |\n| SDK                  |                                                                                   |\n| Context              |                                                                   |\n| Semantic Conventions |                                                               |\n| OTLP Exporter        |                                           |\n| gRPC Transport       |                                       |\n| OTLP Protobuf Files  |                           |\n| B3 Propagator        |   |\n\nReleases for both this repository and  are\nbased on read-only  from our monorepo. You should refer to\n for all packages, their versions and details.\n\nYou can also look at the read-only repositories, which live in the\n organization.\n\n## Contributing\n\nWe would love to have you on board, please see our  and .\n\n## Specification conformance\n\nWe attempt to keep the  up to date in order to show which features are available and which have not yet been implemented.\n\nIf you find an inconsistency in the data in the matrix, please let us know in our slack channel and we'll get it rectified.\n\n## Backwards compatibility\n\nSee .\n\n## Versioning\n\nVersioning rationale can be found in the \n"""
XCMetrics is the easiest way to collect Xcode build metrics and improve developer productivity.,"b'\n\n    \n\n\n_XCMetrics is the easiest way to collect Xcode builds metrics and improve your developer productivity._\n\n\n\n\n\n\n## Overview\n\n- \xf0\x9f\x93\x88 Keep your build times under control and monitor which targets are taking the longest to compile.\n- \xe2\x9a\xa0\xef\xb8\x8f Collect warnings to improve your code health.\n- \xe2\x9d\x8c Collect errors to help and diagnose builds problems in real-time.\n- \xf0\x9f\x9b\xa0 Build custom plugins to collect an infinite amount of metadata to be attached to each build, such as version control information and thermal throttling.\n\nXCMetrics is built on top of , which is a tool that can parse Xcode and xcodebuild logs stored in the xcactivitylog format. This allows XCMetrics to collect accurate metrics for you to review and keep track during the lifetime of a codebase.\nXCMetrics has collected almost 1 million builds and over 10 billion steps from all Spotify iOS applications since its introduction. It has allowed us to make important and informed decision in regards to our project structure and architecture.\n\n## Getting Started\n\nHead over to our  to see how to integrate XCMetrics in your project.\n\n## Develop\n\nXCMetrics is built using Swift Package Manager, you just need to open the  file in Xcode: \n\n\n\n## Support\n\nCreate a  with as many details as possible. Its important that you follow the issue template and include all required information in order for us to get back to you as soon as possible.\n\nReach us at the  channel in .\n\n## Contributing\n\nWe feel that a welcoming community is important and we ask that you follow Spotifys \n\nin all interactions with the community.\n\n## Authors\n\nA full list of  can be found on GitHub.\n\nFollow  on Spotify for updates.\n\n## License\n\nCopyright 2020 Spotify, Inc.\n\nLicensed under the Apache License, Version 2.0: https://www.apache.org/licenses/LICENSE-2.0\n\nThis product includes software developed by the ""Marcin Krzyzanowski"" (http://krzyzanowskim.com/).\n\n## Security Issues?\n\nPlease report sensitive security issues via  rather than GitHub.\n'"
Machine Learning Open Source University,"b'\n    \n    \n    \n\n\n\n \n \n  \n\n\n    A Free Machine Learning University \n\n\n\nMachine Learning Open Source University is an IDEA of free-learning of a ML enthusiast for all other ML enthusiast\n\nThis list is continuously updated - And if you are a Ml practitioner and have some good suggestions to improve this or have somegood resources to share, you create pull request and contribute.\n\n\nTable of Contents\n\n1. \n2. \n3. \n4. \n5. \n6. \n7. \n8. \n9. \n10. \n11. \n12. \n13.  \n14. \n15. \n\n\n\n\n\n\n\n\n\n## Getting Started\n\n | Title and Source                                             | Link                               \t\t\t\t          |\n |------------------------------------------------------------  | -------------------------------------------------------------|\n | Elements of AI :  Part-1                                     | \t\t\t\t  |\n | Elements of AI :  Part-2                                     |  \t\t\t  |\n | CS50\xe2\x80\x99s Introduction to AI\tHarvard\t\t\t            | \t\t\t  |\n | Intro to Computational Thinking and Data Science MIT     | \n | Practical Data Ethics\t\t\t\t\t\t\t\t\t\t| \n | Machine learning Mastery Getting Started \t\t\t\t\t| \n | Design and Analysis of Algorithms MIT\t\t\t\t\t| \n | AI: Principles and Techniques Stanford \t\t\t\t\t| |\n | The Private AI Series \t\t\t\t\t\t\t\t\t\t| |\n\n \n\n## Mathematics\n\n\n | Title and Source                                             | Link                               \t\t\t\t          |\n |------------------------------------------------------------  | -------------------------------------------------------------\n | Statistics in Machine Learning (Krish Naik)                  | \n | Computational Linear Algebra for Coders\t\t\t\t\t\t| \n | Linear Algebra  MIT\t\t\t\t\t\t\t\t\t\t| |\n | Statistics by zstatistics\t\t\t\t\t\t\t\t\t| |\n | Essence of linear algebra by 3Blue1Brown\t\t\t\t\t\t| |\n | SEEING THEORY (Visual Probability)\tbrown    \t\t    | |\n | Matrix Methods in Data Analysis,and Machine Learning MIT | \n | Math for Machine Learning \t\t\t\t\t\t\t\t\t|  |\n | Statistics for Applications MIT |  \n\n\n\n## Machine Learning\n\n | Title and Source                                             | Link                               \t\t\t\t           |\n |------------------------------------------------------------  | -------------------------------------------------------------|\n | Introduction to Machine Learning with scikit-learn \t\t\t| |\n | Introduction to Machine Learning\t\t\t\t\t\t\t\t| \n | Open Machine Learning Course \t\t\t\t\t\t\t\t| \t\t\t\t\t\t   |\n | Machine Learning (CS229) Stanford\t\t\t\t\t\t|  |\n | Introduction to Machine Learning MIT \t\t\t\t\t| \t\t\t\t\t   |\n | Machine Learning Systems Design 2021 (CS329S) Stanford   |    |\n | Applied Machine Learning 2020 (CS5787) Cornell Tech      | \n | Machine Learning for Healthcare MIT \t\t\t\t\t\t| \t\t\t\t\t   |\n | Machine Learning for Trading Georgia Tech\t\t\t\t| \t\t\t\t   |\t\n | Introduction to Machine Learning for Coders\t\t\t\t\t| \n | Machine Learning Crash Course\t\t\t\t\t\t\t\t| |\n | Machine Learning with Python \t\t\t\t\t\t\t\t| |\n | Deep Reinforcement Learning:CS285 UC Berkeley\t\t\t| |\n | Probabilistic Machine Learning University of T\xc3\xbcbingen    | |\n | Machine Learning with Graphs(CS224W) Stanford \t\t\t| |\n | Machine Learning in Production CMU\t\t\t\t\t\t| |\n | Machine Learning & Deep Learning Fundamentals                | |\n | Interpretability and Explainability in Machine Learning      | |\n | Practical Machine Learning 2021 Stanford\t\t\t\t\t| |\n | Machine Learning VU University \t\t\t\t\t\t\t| |\n | Machine Learning for Cyber Security Purdue University    | |\n | Audio Signal Processing for Machine Learning \t\t\t\t| |\n | Machine learning & causal inference Stanford\t\t\t\t| |\n | Machine learning cs156 caltech                           |  |\n | Multimodal machine learning (MMML) CMU                   |    | \n | Advanced Topics in Machine Learning Caltech              | \n\n \t\n\n## Deep Learning\n \n \n | Title and Source                                             | Link                               \t\t\t\t           |\n |------------------------------------------------------------  | -------------------------------------------------------------|\n | Introduction to Deep Learning(6.S191) MIT\t\t \t\t| \t\t\t\t\t   |\n | Introduction to Deep Learning\t\t\t\t\t\t\t\t| \n | Deep Learning NYU\t\t\t\t\t \t\t\t\t\t|    |\n | Deep Learning (CS182) UC Berkeley\t\t\t\t\t\t| \n | Deep Learning Lecture Series\tDeepMind x UCL\t\t\t    | |\n | Deep Learning (CS230) Stanford\t\t\t\t\t\t    |                | \n | CNN for Visual Recognition(CS231n) Stanford    \t\t    |   |\n | Full Stack Deep Learning   \t\t\t\t\t\t\t\t\t| |\n | Practical Deep Learning for Coders, v3                       | \t\t\t   |\n | Deep Learning Crash Course 2021 d2l.ai \t\t\t\t\t\t| |\n | Deep Learning for Computer Vision Michigan\t\t\t\t| |\n | Neural Networks from Scratch in Python by Sentdex\t\t\t| |\n | Keras - Python Deep Learning Neural Network API\t\t\t\t| |\n | Reproducible Deep Learning\t\t\t\t\t\t\t\t\t| |\n | PyTorch Fundamentals \t\t\t\t\t\t\t\t\t\t| |\n | Geometric Deep Learing (GDL100)\t\t\t\t\t\t\t\t| |\n | Deep learning Neuromatch Academy \t\t\t\t\t\t\t| \n | Deep Learning for Molecules and Materials\t\t\t\t\t| |\n | Deep Learning course for Vision\t\t\t\t\t\t\t\t| |\n | Deep Multi-Task and Meta Learning (CS330) Stanford  \t\t|  |\n | Deep Learning Interviews book \t\t\t\t\t\t\t\t| |\n | Deep Learning for Computer Vision 2021                       | \n | Deep Learning 2022 CMU                                   |    \n | UvA Deep Learning                                            | \n\n\n## Natural language processing \n\n | Title and Source                                             | Link                               \t\t\t\t  \t\t   |\n | ------------------------------------------------------------ | -----------------------------------------------------------|\n | Natural Language Processing AWS\t\t\t\t\t\t\t\t| \n | NLP - Krish Naik \t\t\t\t                            | \n | NLP with Deep Learning(CS224N) 2019 Stanford     \t\t|  \n | A Code-First Introduction to Natural Language Processing     | |\n | CMU Neural Nets for NLP 2021  Carnegie Mellon University | |\n | Speech and Language Processing Stanford \t\t\t\t\t|  |\n | Natural Language Understanding (CS224U) Stanford\t\t\t|  \n | NLP with Dan Jurafsky and Chris Manning, 2012 Stanford   | |\n | Intro to NLP with spaCy   \t\t\t\t\t\t\t\t\t| |\n | Advanced NLP with spaCy \t\t\t\t\t\t\t\t\t\t|                                              |\n | Applied Language Technology \t\t\t\t\t\t\t\t\t| |\n | Advanced Natural Language Processing Umass\t\t\t\t|  |\n | Huggingface Course\t\t\t\t\t\t\t\t\t\t\t| |\n | NLP Course Michigan\t\t\t\t\t\t\t\t\t\t| |\n | Multilingual NLP 2020 CMU\t\t\t\t\t\t\t\t| |\n | Advanced NLP 2021 CMU\t\t\t\t\t\t\t\t\t| |\n | Transformers United stanford                             |    |  \n | CS324 Large Language Models | |\n\n  \n\n## Reinforcement learning\n\n | Title and Source                                             | Link\t\t\t\t\t\t\t\t\t\t\t\t\t\t                                         |\n |------------------------------------------------------------  | -----------------------------------------------------------|\n | Reinforcement Learning(CS234)  Stanford \t\t\t\t\t| |\n | Introduction to reinforcement learning DeepMind\t\t\t| |\n | Reinforcement Learning Course  DeepMind & UCL\t\t\t| |\n | Advanced Deep Learning & Reinforcement Learning        \t\t| |\n | DeepMind x UCL Reinforcement Learning 2021\t\t\t\t\t| \n \n \n## Books\n\n\n | Title and Source                                             | Link                               \t\t\t\t         |\n |------------------------------------------------------------  | -----------------------------------------------------------|\n | Scientific Python Lectures\t\t \t\t\t\t\t\t\t| |\n | Mathematics for Machine Learning\t\t\t\t\t\t\t    | \t |\n | An Introduction to Statistical Learning                      |               |\n | Think Stats \t\t\t\t\t\t\t\t\t\t\t\t\t| |\n | Python Data Science Handbook                                 | |\n | Natural Language Processing with Python - NLTK               | \t\t\t\t\t\t |\n | Deep Learning by Ian Goodfellow             \t\t\t\t\t| \t\t |\n | Dive into Deep Learning \t\t\t\t\t\t\t\t\t\t| \n | Approaching (Almost) Any Machine Learning Problem    \t\t| |\n | Neural networks and Deep learning\t\t\t\t\t\t\t| |\n | AutoML: Methods, Systems, Challenges (first book on AutoML)  | |\n | Feature Engineering and Selection\t \t\t\t\t\t\t| |\n | Introduction to Machine Learning Interviews Book\t\t\t\t| |\n | Hands-On Machine Learning with R \t\t\t\t\t\t\t| |\n | Zero to Mastery TensorFlow for Deep Learning Book\t\t\t| |\n | Introduction to Probability for Data Science\t\t\t\t\t| |\n | Graph Representation Learning Book\t\t\t\t\t\t\t| |\n | Interpretable Machine Learning\t\t\t\t\t\t\t\t| |\n | Computer Vision: Algorithms and Applications, 2nd ed.\t\t| \n\n \n \n \n## ML in Production\n\n\n | Title and Source                                             | Link                               \t\t\t\t         |\n |------------------------------------------------------------  | -----------------------------------------------------------|\n | \tIntroduction to Docker       \t \t\t\t\t\t\t\t| |\n |  MLOps Basics\t\t\t\t\t\t\t\t\t\t\t\t| | \n |  Effective MLOps: Model Development                           | |\n  \n\n## Quantum ML\n\n | Title and Source                                             | Link                               \t\t\t\t         |\n |------------------------------------------------------------  | -----------------------------------------------------------|\n | \tQuantum machine learning      \t \t\t\t\t\t\t\t| |\n\n\n## DataSets\n\n | Title and Source                                             | Link                               \t\t\t\t         |\n |------------------------------------------------------------  | -----------------------------------------------------------|\n | Yelp Open Dataset\t\t\t\t\t\t\t\t\t\t\t| \t\t\t\t\t\t | \n | Machine Translation \t\t\t\t\t\t\t\t\t\t\t| \t\t\t\t |\n | IndicNLP Corpora (Indian languages)\t\t\t\t\t\t\t| \t\t |\n | Amazon product co-purchasing network metadata\t\t\t\t| |\n | Stanford Question Answering Dataset (SQuAD)\t\t\t\t\t| \n  \n \n## Other Useful Websites\n\n\n1.\t\n2.\t\n3.  \n4.  \n5.  \n6.  \n7.  \n8.  \n10. \n11. \n12. \n13. \n14. \n15. \n16. \n17. \n\n## Other Useful GitRepo\n\n1. \n2. \n3. \n4. \n5. \n6. \n7. \n8. \n9. \n\n## Blogs and Webinar\n1. \n2. \n3. \n\n\n## Must Read Research Paper\n\n NLP [Text] \n\n1. \n2. \n3. \n4. \n4. \n5. \n6. \n8. \n9. \n10.  \n11. \n12. \n\nOCR [Optical Character Recognition] \n\n1. \n\n## Company Tech Blogs \n\n1. \n2. \n3. \n4. \n5. \n6.  | \n\n\n\n'"
Simple library for handling keyboard shortcuts in Javascript,"b'# Mousetrap\n\n\nMousetrap is a simple library for handling keyboard shortcuts in Javascript.\n\nIt is licensed under the Apache 2.0 license.\n\nIt is around 2kb minified and gzipped and 4.5kb minified, has no external dependencies, and has been tested in the following browsers:\n\n- Internet Explorer 6+\n- Safari\n- Firefox\n- Chrome\n\nIt has support for , , and  events on specific keys, keyboard combinations, or key sequences.\n\n## Getting started\n\n1. Include mousetrap on your page before the closing  tag\n\n    \n\n    or install  from  and require it\n\n    \n\n2. Add some keyboard events to listen for\n\n    \n\n## Why Mousetrap?\n\nThere are a number of other similar libraries out there so what makes this one different?\n\n- There are no external dependencies, no framework is required\n- You are not limited to  events (You can specify , , or  or let Mousetrap choose for you).\n- You can bind key events directly to special keys such as  or  without having to specify  or  which are not consistent across all keyboards\n- It works with international keyboard layouts\n- You can bind Gmail like key sequences in addition to regular keys and key combinations\n- You can programatically trigger key events with the  method\n- It works with the numeric keypad on your keyboard\n- The code is well documented/commented\n\n## Tests\n\nUnit tests are run with mocha.\n\n### Running in browser\n\n to check your browser compatibility. You may also download the repo and open  in your browser.\n\n### Running with Node.js\n\n1. Install development dependencies\n\n    \n\n3. Run tests\n\n    \n\n## Documentation\n\nFull documentation can be found at https://craig.is/killing/mice\n'"
"Elegant, flexible data logging in Python for connected sensors and instruments.","b'# Welcome!\n\n\n\nWelcome to Pipecat ... elegant, flexible data logging in Python for\nconnected sensors and instruments.  Use Pipecat to log data from\nbattery chargers, GPS, automobiles, gyros, weather, and more!\n\nHere are some devices supported by Pipecat and examples of how to log their data:\n\n* .\n*  that generate NMEA data.\n* Vehicles that generate OBD-II data.\n* Motion (accelerometer) data from iOS devices.\n* METAR (aviation weather) data from the National Weather Service.\n* Any device that communicate over a serial port.\n* Any device that can handle HTTP GET requests.\n* Any device that can write to a socket using UDP.\n* Any device that can generate XML data.\n\nYou can see the full Pipecat documentation with tutorials at\nhttps://pipecat.readthedocs.io ... for questions, comments, or suggestions, get\nin touch with our team at https://gitter.im/shead-custom-design/pipecat.\n\nLicense\n=======\n\nThis program is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see .\n'"
":leaves: A curated list of awesome MongoDB resources, libraries, tools and applications","b'\n\n# Awesome MongoDB \n\n\n\n> A curated list of awesome MongoDB resources, libraries, tools and applications\n\nInspired by the  list thing. Feel free to improve this list by !\n\n## Table of Contents\n - \n   - \n   - \n   - \n   - \n   - \n   - \n - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n   - \n - \n\n## Resources\n### Documentation\n - \n - \n - \n - \n - \n - \n - \n\n### Articles\n\n - \n - \n -  - Series of articles regarding MongoDB Design Patterns and common use case of each Design Pattern with real world examples.\n -  - Scale 101\n -  - Everything you need/have to know about indexes\n - \n - \n -  - The techniques and MongoDB Cloud features to debug performance issues and expose sub-optimal queries\n\n### Books\n -  - Advanced MongoDB tips and tricks, given by a MongoDB inc. engineer\n -  - Learn how to build a full stack JavaScript web app from scratch\n - \n -  - Free e-book: How to develop effective and optimal data manipulation and analytics pipelines\n -  - Basic introduction\n -  - Learn how to build a production-ready SaaS web app from scratch\n\n### Talks\n -  [47]\n -  [35]\n -  [50]\n\n### Tutorials\n -  - Deployment tutorial of a basic Node.js and MongoDB web stack on Kubernetes\n - \n - \n\n### More\n - \n -  - Certifications and free online courses\n -  - Free and self-paced MongoDB courses for beginners\n\n## Libraries\n### C\n -  - Official C driver\n\n### C++\n -  - Official C++ driver\n\n### C#/.NET ###\n -  - Official C# driver\n -  - C# message queue on top of MongoDB\n -  - Lightweight queue pub/sub processing library\n -  - Repository abstraction layer on top of the C# driver\n\n### D\n -  - D web framework shipping with a MongoDB driver\n\n### Dart\n -  - Community Dart driver\n\n### Delphi\n -  - Library for Delphi that includes a MongoDB client\n -  - Minimal community Delphi driver\n\n### Elixir\n -  - Community Elixir driver\n -  - Community Elixir driver\n -  - Adapter for the Ecto database wrapper\n\n### Erlang\n -  - Community Erlang driver\n\n### Fantom\n -  - Community Fantom driver\n\n### Go\n -  - ODM based on mgo\n -  - Community Go driver\n -  - MongoDB cursor that paginates\n -  - Official Go driver\n\n### Haskell\n -  - Community Haskell driver\n\n### Java\n -  - Query in Java as in Mongo shell\n -  - The power and simplicity of JPA for NoSQL datastores\n -  - Official Java driver\n -  - Java message queue on top of MongoDB\n -  - An enhancement of GridFS to allow for more features and capabilities\n -  - Based on Jackson, allows you to easily handle your mongo objects as POJOs\n -  - Java ODM\n -  - Java ODM and caching layer\n -  - Community driver for languages running on the JVM\n -  - Spring based, object-document support and repositories\n\n### JavaScript\n -  - Class-based ES6 ODM for Mongo-like databases\n -  - Community Deno driver\n -  - Reactive ODM that uses Javascript Proxies to enable transparent DB persistence\n -  - Full stack based on MongoDB, Express, AngularJS, and Node.js\n -  - Full stack based on MongoDB, Express, React and Node.js\n -  - Real-time/reactive client-server framework based on MongoDB, with lots of features\n -  - Node.js asynchronous ODM\n -  - Permissions management library integrated with Mongoose\n -  - Node.js migration framework\n -  - Framework with live querying on top of Mongoose and socket.io\n -  - Universal schema-based ORM with multi-state representation for entities\n -  - Official Node.js driver\n\n### Julia\n -  - C driver bindings\n \n### Kotlin\n-  - Kotlin toolkit based on the Java driver\n\n### Lisp\n -  - Community Common Lisp interface\n -  Community Common Lisp driver\n -  - Community Emacs Lisp driver\n\n### Mathematica\n -  - Community Mathematica driver\n\n### OCaml\n -  - Community OCaml driver\n\n### PHP\n -  - Repository implementation built on top of laravel-mongodb\n -  - Eloquent model and query builder for Laravel\n -  - Repository implementation\n -  - Adapter for applications using \n -  - Official PHP driver\n -  - ODM based on the PHP Mongo PECL extension\n -  - Migration tool based on PHPMongo ODM\n -  - Fast schemaless ODM\n\n### PowerShell\n -  - MongoDB cmdlets for PowerShell\n\n### Python\n -  - MongoDB Atlas Search wrapper with MongoEngine syntax\n -  - Asynchronous ODM based on  and , which supports migrations out of the box\n -  - MongoDB connector for Django compatible with Django ORM\n -  - Flask extension that integrates MongoEngine, WTForms and FlaskDebugToolbar\n -  - Flask extension that adds PyMongo support to Flask\n -  - Powerful schema-less ODM for MongoDB and Python (sync + async)\n -  - ODM on top of PyMongo\n -  - MongoDB logging handler\n -  - Official non-blocking Python driver for Tornado or asyncio\n -  - Official Python driver\n -  - A wrapper for PyMongos Collection object that makes it easy to run  on your queries.\n -  - A lightweight, schemaless, Pythonic Object-Oriented interface\n -  - Asynchronous ODM on top of pydantic\n -  - MongoDB pipeline for Scrapy\n -  - Twisteds MongoDB driver\n -  - Driver-independent (async/sync) ODM based on marshmallow\n\n### R\n -  - Fast and simple client for R\n\n### Ruby\n -  - A simple global method to explain Mongoid queries\n -  - Official Ruby driver\n -  - ODM framework\n\n### Rust\n -  - Official Rust driver\n\n### Scala\n -  - Official Scala driver\n -  - Non-blocking Scala driver\n -  - Read/write data with Spark SQL\n\n### Smalltalk\n -  - Community Smalltalk driver\n\n### Swift\n -  - Community asynchronous Swift driver\n\n## Tools\n### Administration\n -  - Schedule MongoDB backups to S3 with a Kubernetes CronJob.\n -  - Full-featured MongoDB dockerized backup agent\n -  - Manage MongoDB servers and replica sets using JSON configurations\n -  - Generate randomized datasets and benchmark your setup\n -  - Three neat Python scripts to work with collections and indexes\n -  - Collection of scripts to set up test environments and visualize log files\n -  - Nginx module for serving files from GridFS\n -  - REST client written as an Nginx module\n -  - Aggregates queries from query profiler and reports query usage statistics\n -  - MongoDB cluster status overview command line tool\n\nServices:\n -  - IBM DBaaS offer (has other database types too)\n -  - MongoDB Inc. DBaaS offer (works with AWS, Azure, or GCP)\n -  - MongoDB Inc. databases management offer\n -  - Rackspace DBaaS offer (has other database types too)\n -  - Fully managed DBaaS (with option to bring your own Azure/AWS account)\n\n### Data\n -  - Streaming replication to Elasticsearch, Solr, or MongoDB\n -  - PostgreSQL foreign data wrapper\n -  - Hadoop connector\n -  - MongoDB to Elasticsearch (and vice-versa) migration tool\n -  - Multi-master replication\n\nServices:\n -  -  Blockchain based Data integrity solution for MongoDB\n\n### Deployment\n -  - Ansible role\n -  - Chef cookbook\n - \n - \n -  - Puppet module (formerly puppetlabs-mongodb)\n\nServices:\n -  - MongoDB Inc. solution for continuous data sync between separate clusters\n\n### Desktop\n -  - Free Cross-platform GUI from MongoDB\n -  - Connect to MongoDB and prototype queries from VS Code\n -  - Mac native client\n\nServices:\n -  - Cross-platform JetBrains IDE\n -  - MongoDB Admin. Intuitive UI. Fast. Reliable\n -  - Data modeling tool for MongoDB and relational databases\n -  - Feature-rich but easy-to-use cross-platform IDE (formerly MongoBooster)\n -  - Modern and powerful GUI tool, cross-platform and easy-to-use\n -  - Cross-platform GUI, stable and powerful (formerly MongoChef and Robo 3T)\n -  - Native, lightweight GUI on macOS\n\n### Development\n -  - View the MongoDB Query API equivalents of your builder expressions in Visual Studio\n -  - Random data generator\n -  - Database migration tool\n -  - Online query playground\n -  - Node.js library, CLI and Docker image for populating databases using JS and JSON files\n -  - Schema and data analyzer: explore data in your collections\n -  - Schema analyzer: see what fields are in your collection and whats their content\n - \n\nServices:\n -  - MongoDB Inc. solution to run code without the operational overhead\n -  - MongoDB Inc. solution for mobile data sync\n\n### Monitoring\n -  - Nagios plugin (in Bash)\n -  - Simple monitoring CLI\n -  - Collection of Munin plugins\n -  - Long operations monitoring and alerting\n -  - More Munin plugins\n -  - MongoDB top clone\n -  - Another top clone\n -  - Nagios plugin (in Python)\n -  - Free and open-source platform for managing and monitoring databases performances\n -  - Log all MongoDB queries in a ""tail""able way\n\nServices:\n\n -  - SaaS-based monitoring\n -  - SaaS-based query performance analytics and monitoring\n\n### Low-Code\n\n> \xf0\x9f\x92\xa1 These tools are not necessarily made for MongoDB in particular, but support it.\n\n -  - Open-source Retool alternative\n -  - Open-source Firebase alternative\n -  - Open-source Retool alternative\n -  - Open-source Retool alternative\n -  - Open-source Retool alternative\n\nServices:\n-  - Retool alternative\n-  - Drag-and-drop editor with pre-built components to build internal tools\n\n### Shell\n -  - Official Atlas API command-line client\n -  - Official command-line client\n\n### Web\n -  - Web-based user interface to handle connections and databases needs\n -  - Web-based admin interface built with Express\n -  - Admin interface built with Django\n -  - MongoDB client for the web\n -  - Web-based user interface written in JavaScript\n -  - PHPMyAdmin for MongoDB, sort of\n\nServices:\n\n -  - Easy online GUI and data-visualization dashboards\n\n## Applications\n\nThose open-source applications have MongoDB somewhere in their stack:\n\n -  - Web app to publish books or documentation built with React and Express\n -  - Multiplayer programming game for learning how to code\n -  - Mobile & web analytics and marketing platform built with Node.js\n -  - JavaScript CMS built with Mongoose\n -  - Multi-platform e-commerce shopping cart built with ASP.NET\n -  - Evernote clone built with Go\n -  - Node.js based forum software (""built for the modern web"")\n -  - Event-driven, real-time commerce platform built with ES6\n -  - Boilerplate for SaaS products, built with TypeScript, React and Express\n -  - Remote monitoring application built with Node.js and Bootstrap\n -  - Scalable high availability email server that uses MongoDB for email storage\n\n## License\n\n\nTo the extent possible under law,  has waived all copyright and related or neighboring rights to this work.\n'"
R interface for Apache Spark,"b'sparklyr: R interface for Apache Spark\n================\n\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n<!-- badges: start -->\n\n\n\n\n\n\n\n\n\n- Install and connect to  using YARN,\n  Mesos, Livy or Kubernetes.\n- Use  to filter and aggregate Spark datasets and\n   then bring them\n  into R for analysis and visualization.\n- Use , ,\n   and\n  \n  to train models at scale in Spark.\n- Create interoperable machine learning\n   and\n  productionize them with\n  .\n- Create  that call the full Spark API or run\n   code to support new functionality.\n\n## Table of Contents\n\n- \n- \n- \n  - \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n\n## Installation\n\nYou can install the sparklyr package from\n as follows:\n\n\n\nYou should also install a local version of Spark for development\npurposes:\n\n\n\nTo upgrade to the latest version of sparklyr, run the following command\nand restart your r session:\n\n\n\n## Connecting to Spark\n\nYou can connect to both local instances of Spark as well as remote Spark\nclusters. Here we\xe2\x80\x99ll connect to a local instance of Spark via the\n\nfunction:\n\n\n\nThe returned Spark connection () provides a remote dplyr data source\nto the Spark cluster.\n\nFor more information on connecting to remote Spark clusters see the\n section of the\nsparklyr website.\n\n## Using dplyr\n\nWe can now use all of the available dplyr verbs against the tables\nwithin the cluster.\n\nWe\xe2\x80\x99ll start by copying some datasets from R into the Spark cluster (note\nthat you may need to install the nycflights13 and Lahman packages in\norder to execute this code):\n\n\n\n\n\nTo start with here\xe2\x80\x99s a simple filtering example:\n\n\n\n\nprovides additional  examples you can try. For example, consider\nthe last example from the tutorial which plots data on flight delays:\n\n\n\n<img src=""tools/readme/dplyr-ggplot2-1.png"" width=""100%"" />\n\n### Window Functions\n\ndplyr  are\nalso supported, for example:\n\n\n\nFor additional documentation on using dplyr with Spark see the\n section of the sparklyr\nwebsite.\n\n## Using SQL\n\nIt\xe2\x80\x99s also possible to execute SQL queries directly against tables within\na Spark cluster. The  object implements a\n interface for Spark, so you can use\n to execute SQL and return the result as an R data frame:\n\n\n\n## Machine Learning\n\nYou can orchestrate machine learning algorithms in a Spark cluster via\nthe \nfunctions within sparklyr. These functions connect to a set of\nhigh-level APIs built on top of DataFrames that help you create and tune\nmachine learning workflows.\n\nHere\xe2\x80\x99s an example where we use\n\nto fit a linear regression model. We\xe2\x80\x99ll use the built-in \ndataset, and see if we can predict a car\xe2\x80\x99s fuel consumption ()\nbased on its weight (), and the number of cylinders the engine\ncontains (). We\xe2\x80\x99ll assume in each case that the relationship\nbetween  and each of our features is linear.\n\n\n\nFor linear regression models produced by Spark, we can use \nto learn a bit more about the quality of our fit, and the statistical\nsignificance of each of our predictors.\n\n\n\nSpark machine learning supports a wide array of algorithms and feature\ntransformations and as illustrated above it\xe2\x80\x99s easy to chain these\nfunctions together with dplyr pipelines. To learn more see the  section.\n\n## Reading and Writing Data\n\nYou can read and write data in CSV, JSON, and Parquet formats. Data can\nbe stored in HDFS, S3, or on the local filesystem of cluster nodes.\n\n\n\n## Distributed R\n\nYou can execute arbitrary r code across your cluster using\n. For example, we can apply  over  as\nfollows:\n\n\n\nYou can also group by columns to perform an operation over each group of\nrows and make use of any package within the closure:\n\n\n\n## Extensions\n\nThe facilities used internally by sparklyr for its  and machine\nlearning interfaces are available to extension packages. Since Spark is\na general purpose cluster computing system there are many potential\napplications for extensions (e.g.\xc2\xa0interfaces to custom machine learning\npipelines, interfaces to 3rd party Spark packages, etc.).\n\nHere\xe2\x80\x99s a simple example that wraps a Spark text file line counting\nfunction with an R function:\n\n\n\nTo learn more about creating extensions see the\n section\nof the sparklyr website.\n\n## Table Utilities\n\nYou can cache a table into memory with:\n\n\n\nand unload from memory using:\n\n\n\n## Connection Utilities\n\nYou can view the Spark web console using the  function:\n\n\n\nYou can show the log using the  function:\n\n\n\nFinally, we disconnect from Spark:\n\n\n\n## RStudio IDE\n\nThe RStudio IDE includes integrated support for Spark and the sparklyr\npackage, including tools for:\n\n- Creating and managing Spark connections\n- Browsing the tables and columns of Spark DataFrames\n- Previewing the first 1,000 rows of Spark DataFrames\n\nOnce you\xe2\x80\x99ve installed the sparklyr package, you should find a new\nSpark pane within the IDE. This pane includes a New Connection\ndialog which can be used to make connections to local or remote Spark\ninstances:\n\n\n\nOnce you\xe2\x80\x99ve connected to Spark you\xe2\x80\x99ll be able to browse the tables\ncontained within the Spark cluster and preview Spark DataFrames using\nthe standard RStudio data viewer:\n\n\n\nYou can also connect to Spark through \nthrough a new connection dialog:\n\n\n\n\n\n\n\n## Using H2O\n\n is a CRAN\npackage from  that extends\n to provide an interface into\n. For\ninstance, the following example installs, configures and runs\n:\n\n\n\n\n\n    #> Model Details:\n    #> ==============\n    #>\n    #> H2ORegressionModel: glm\n    #> Model ID:  GLM_model_R_1527265202599_1\n    #> GLM Model: summary\n    #>     family     link                              regularization\n    #> 1 gaussian identity Elastic Net (alpha = 0.5, lambda = 0.1013 )\n    #>                                                                lambda_search\n    #> 1 nlambda = 100, lambda.max = 10.132, lambda.min = 0.1013, lambda.1se = -1.0\n    #>   number_of_predictors_total number_of_active_predictors\n    #> 1                          2                           2\n    #>   number_of_iterations                                training_frame\n    #> 1                  100 frame_rdd_31_ad5c4e88ec97eb8ccedae9475ad34e02\n    #>\n    #> Coefficients: glm coefficients\n    #>       names coefficients standardized_coefficients\n    #> 1 Intercept    38.941654                 20.090625\n    #> 2       cyl    -1.468783                 -2.623132\n    #> 3        wt    -3.034558                 -2.969186\n    #>\n    #> H2ORegressionMetrics: glm\n    #> ** Reported on training data. **\n    #>\n    #> MSE:  6.017684\n    #> RMSE:  2.453097\n    #> MAE:  1.940985\n    #> RMSLE:  0.1114801\n    #> Mean Residual Deviance :  6.017684\n    #> R^2 :  0.8289895\n    #> Null Deviance :1126.047\n    #> Null D.o.F. :31\n    #> Residual Deviance :192.5659\n    #> Residual D.o.F. :29\n    #> AIC :156.2425\n\n\n\n## Connecting through Livy\n\n enables remote connections to\nApache Spark clusters. However, please notice that connecting to Spark\nclusters through Livy is much slower than any other connection method.\n\nBefore connecting to Livy, you will need the connection information to\nan existing service running Livy. Otherwise, to test  in your\nlocal environment, you can install it and run it locally as follows:\n\n\n\n\n\nTo connect, use the Livy service address as  and\n in . Once connection completes, use\n as usual, for instance:\n\n\n\nOnce you are done using  locally, you should stop this service\nwith:\n\n\n\nTo connect to remote  clusters that support basic authentication\nconnect as:\n\n\n\n## Connecting through Databricks Connect\n\n\nallows you to connect sparklyr to a remote Databricks Cluster. You can\ninstall  and use it to\nsubmit Spark jobs written in sparklyr APIs and have them execute\nremotely on a Databricks cluster instead of in the local Spark session.\n\nTo use sparklyr with Databricks Connect first launch a Cluster on\nDatabricks. Then follow \nto setup the client:\n\n1.  Make sure pyspark is not installed\n2.  Install the Databricks Connect python package. The latest supported\n    version is 6.4.1.\n3.  Run  and provide the configuration\n    information\n    - Databricks account URL of the form\n      .\n    - \n    - Cluster ID\n    - Port (default port number is )\n\nTo configure  with Databricks Connect, set the following\nenvironment variables:\n\n\n\nNow simply create a spark connection as follows\n\n\n\n\n\n\n'"
CSS3 Animations with special effects,"b':tophat: magic\n---------------\n\nCSS3 Animations with special effects. (\xe2\x86\x92 3.1 kB gzip)\n\n## Demo\n\nCheckout the demo for the animations \n\n## Table of Contents\n\n- \n- \n- \n- \n- \n- \n- \n\n\n## Installation\n\nGitHub Package Registry - \n\n\nNPM - \n\n\nYARN - \n\n\n## Getting Started\n\nInclude the file magic.css or include the minified version magic.min.css\n\n\n\nor\n\n\n\n## Usage with JavaScript\n\nThis is a sample code for on hover effect with JavaScript.\nFirst, Include the class  and then a desired animation class.\n\n\nIf you want to load the animation after certain time, you can use this example:\n\n\nIf you want to load the animation after certain time but with an infinite loop, you can use this example:\n\n\n## Usage with jQuery\n\nThis is a sample code for on hover effect with jQuery.\nFirst, Include the class  and then the desired animation class.\n\n\nIf you want to load the animation after certain time, you can use this example:\n\n\nIf you want to load the animation after certain time but with infinite loop, you can use this example:\n\n## HTML & CSS tips\n\nYou can change the time of the animation by setting the class  for example:\n\n\nDefault CSS timing is:\n\n\nIf you want to assign the timing to a specific animation, you can use the following code (use 2 class):\n\n\n## Animation Classes\n\n| MAGIC EFFECTS | BLING     | STATIC EFFECTS      | STATIC EFFECTS OUT | PERSPECTIVE            | ROTATE      |\n|---------------|-----------|---------------------|--------------------|------------------------|-------------|\n| magic         | puffIn    | openDownLeft        | openDownLeftOut    | perspectiveDown        | rotateDown  |\n| twisterInDown | puffOut   | openDownRight       | openDownRightOut   | perspectiveUp          | rotateUp    |\n| twisterInUp   | vanishIn  | openUpLeft          | openUpLeftOut      | perspectiveLeft        | rotateLeft  |\n| swap          | vanishOut | openUpRight         | openUpRightOut     | perspectiveRight       | rotateRight |\n|               |           | openDownLeftReturn  |                    | perspectiveDownReturn  |             |\n|               |           | openDownRightReturn |                    | perspectiveUpReturn    |             |\n|               |           | openUpLeftReturn    |                    | perspectiveLeftReturn  |             |\n|               |           | openUpRightReturn   |                    | perspectiveRightReturn |             |\n\n\n| SLIDE            | MATH      | TIN         | BOMB         | BOING        | ON THE SPACE  |\n|------------------|-----------|-------------|--------------|--------------|---------------|\n| slideDown        | swashOut  | tinRightOut | bombRightOut | boingInUp    | spaceOutUp    |\n| slideUp          | swashIn   | tinLeftOut  | bombLeftOut  | boingOutDown | spaceOutRight |\n| slideLeft        | foolishIn | tinUpOut    |              |              | spaceOutDown  |\n| slideRight       | holeOut   | tinDownOut  |              |              | spaceOutLeft  |\n| slideDownReturn  |           | tinRightIn  |              |              | spaceInUp     |\n| slideUpReturn    |           | tinLeftIn   |              |              | spaceInRight  |\n| slideLeftReturn  |           | tinUpIn     |              |              | spaceInDown   |\n| slideRightReturn |           | tinDownIn   |              |              | spaceInLeft   |\n\n:tada: Gulp and SCSS (SASS) compiling\n---------------\n\nIf you want to customize the CSS files, now you will have the chance. For example, if you want to include only certain animations, you will have to go to this file:\n\n\n\nComment or uncomment your desired file and run from terminal the following commands:\n\n\n\nand last command:\n\n\n\nAutomatically this generate the new files!\n\n\n:white_check_mark: Browser Support\n---------------\n\nBrowser | Chrome | Firefox | Safari | iOS Safari | Opera | Android | Android Chrome | IE | Opera Mini\n--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---:\nVersion | 31+ | 31+ | 7+ | 7.1+ | 27+ | 4.1+ | 42+ | 10+ | :x:\n'"
"Read flat files (csv, tsv, fwf) into R","b'\n<!-- README.md is generated from README.Rmd. Please edit that file -->\n\n# readr \n\n<!-- badges: start -->\n\n\n\n\n\n\n## Overview\n\nThe goal of readr is to provide a fast and friendly way to read\nrectangular data from delimited files, such as comma-separated values\n(CSV) and tab-separated values (TSV). It is designed to parse many types\nof data found in the wild, while providing an informative problem report\nwhen parsing leads to unexpected results. If you are new to readr, the\nbest place to start is the  in R for Data Science.\n\n## Installation\n\n\n\n\n\n\n\n\n\n## Cheatsheet\n\n<img src=""https://github.com/rstudio/cheatsheets/raw/main/pngs/thumbnails/data-import-cheatsheet-thumbs.png"" height=""252"" alt=""thumbnail of tidyverse data import cheatsheet""//>\n\n## Usage\n\nreadr is part of the core tidyverse, so you can load it with:\n\n\n\nOf course, you can also load readr as an individual package:\n\n\n\nTo read a rectangular dataset with readr, you combine two pieces: a\nfunction that parses the lines of the file into individual fields and a\ncolumn specification.\n\nreadr supports the following file formats with these \nfunctions:\n\n- : comma-separated values (CSV)\n- : tab-separated values (TSV)\n- : semicolon-separated values with  as the decimal mark\n- : delimited files (CSV and TSV are important special\n  cases)\n- : fixed-width files\n- : whitespace-separated files\n- : web log files\n\nA column specification describes how each column should be converted\nfrom a character vector to a specific data type (e.g.\xc2\xa0character,\nnumeric, datetime, etc.). In the absence of a column specification,\nreadr will guess column types from the data. \ngives more detail on how readr guesses the column types. Column type\nguessing is very handy, especially during data exploration, but it\xe2\x80\x99s\nimportant to remember these are just guesses. As any data analysis\nproject matures past the exploratory phase, the best strategy is to\nprovide explicit column types.\n\nThe following example loads a sample file bundled with readr and guesses\nthe column types:\n\n\n\nNote that readr prints the column types \xe2\x80\x93 the guessed column types, in\nthis case. This is useful because it allows you to check that the\ncolumns have been read in as you expect. If they haven\xe2\x80\x99t, that means you\nneed to provide the column specification. This sounds like a lot of\ntrouble, but luckily readr affords a nice workflow for this. Use\n to retrieve the (guessed) column specification from your\ninitial effort.\n\n\n\nNow you can copy, paste, and tweak this, to create a more explicit readr\ncall that expresses the desired column types. Here we express that \nshould be a factor with levels  and , in that order, and\nthat  should be integer.\n\n\n\n gives an expanded introduction to readr.\n\n## Editions\n\nreadr got a new parsing engine in version 2.0.0 (released July 2021). In\nthis so-called second edition, readr calls , by default.\n\nThe parsing engine in readr versions prior to 2.0.0 is now called the\nfirst edition. If you\xe2\x80\x99re using readr >= 2.0.0, you can still access\nfirst edition parsing via the functions  and\n. And, obviously, if you\xe2\x80\x99re using readr < 2.0.0, you\nwill get first edition parsing, by definition, because that\xe2\x80\x99s all there\nis.\n\nWe will continue to support the first edition for a number of releases,\nbut the overall goal is to make the second edition uniformly better than\nthe first. Therefore the plan is to eventually deprecate and then remove\nthe first edition code. New code and actively-maintained code should use\nthe second edition. The workarounds  and\n are offered as a pragmatic way to patch up legacy\ncode or as a temporary solution for infelicities identified as the\nsecond edition matures.\n\n## Alternatives\n\nThere are two main alternatives to readr: base R and data.table\xe2\x80\x99s\n. The most important differences are discussed below.\n\n### Base R\n\nCompared to the corresponding base functions, readr functions:\n\n- Use a consistent naming scheme for the parameters (e.g.\xc2\xa0\n  and  not  and ).\n\n- Are generally much faster (up to 10x-100x) depending on the dataset.\n\n- Leave strings as is by default, and automatically parse common\n  date/time formats.\n\n- Have a helpful progress bar if loading is going to take a while.\n\n- All functions work exactly the same way regardless of the current\n  locale. To override the US-centric defaults, use .\n\n### data.table and \n\n has a function\nsimilar to  called . Compared to , readr\nfunctions:\n\n- Are sometimes slower, particularly on numeric heavy data.\n\n- Can automatically guess some parameters, but basically encourage\n  explicit specification of, e.g., the delimiter, skipped rows, and the\n  header row.\n\n- Follow tidyverse-wide conventions, such as returning a tibble, a\n  standard approach for column name repair, and a common mini-language\n  for column selection.\n\n## Acknowledgements\n\nThanks to:\n\n-  for showing me the beauty of\n  deterministic finite automata for parsing, and for teaching me why I\n  should write a tokenizer.\n\n-  for helping me come up with\n  a design that makes very few copies, and is easy to extend.\n\n-  for coming up with\n  the name!\n'"
Rust port of Lucene,"b""Rucene - Rust implementation of Lucene\n=====================================================================================\n\n## Introduction\n\nRucene is a Rust port of the popular Apache Lucene project. Rucene is not a complete application, but rather a code library and API that can easily be used to add full text search capabilities to applications.\n\n## Status\n\nThe index searcher part of Rucene has been put into production and has served all search traffics at Zhihu since July, 2018. Development of the index writer part was started in late 2018, and has been put into production to serve real-time searching since May, 2019.\n\n## Documentation\n\nWe don't yet have an API documentation for Rucene, but the usage is similar to .\n\n> Note:\n>\n> We are working on this, but could use more help since it is a massive project.\n\n## License\n\nRucene is under the Apache 2.0 license. See the  file for details.\n"""
Break free from CSS prefix hell!,"b'# \n## Break free from CSS prefix hell!\n\n\n\nA script that lets you use only unprefixed CSS properties everywhere. \nIt works behind the scenes, adding the current browser\xe2\x80\x99s prefix to any CSS code, only when it\xe2\x80\x99s needed.\n\n## API Documentation\nNote: To use -prefix-free you dont need to write any JS code, just to include prefixfree.js in your page. The following is meant mostly for plugin authors.\n\n-prefix-free creates 2 global variables:  and . StyleFix is a framework for building various CSS fixers and -prefix-free depends on it. Currently, StyleFix is bundled with -prefix-free and only available this way, but it might eventually get split to a separate project, with separate documentation.\n\n## StyleFix API Documentation\n\n### Properties\n\tStyleFix.fixers\nAn array of the current callbacks.\n\n### Functions\n\tStyleFix.register(callback)\nAdds  to the queue of functions that will be called when fixing CSS code.  will be called with the following parameters:\n\n* css (String): The CSS code that is being processed,\n* raw (Boolean): Whether the CSS code can contain rules etc or its just a bunch of declarations (such as the ones found in the  attribute),\n* element (HTMLElement): The node that the CSS code came from (such as a  element, a  element or any element with a  attribute)\n\nand it should return the fixed CSS code.\n\n\tStyleFix.link(linkElement)\n\nProcesses a  element and converts it to a  element with fixed code. Relative URLs will be converted.\n\n\tStyleFix.styleElement(styleElement)\n\t\nFixes code inside a  element.\n\n\tStyleFix.styleAttribute(element)\n\t\nFixes code inside the  attribute of an element. Will not work in IE and Firefox &lt; 3.6 due to a bug those have with : In IE invalid values of valid properties will be dropped, and in Firefox &lt; 3.6 anything invalid will be dropped.\n\n\tStyleFix.camelCase(str)\n\tStyleFix.deCamelCase(str)\nUtility methods that convert a string to camelCase and back.\n\n## -prefix-free API Documentation\n\n### Properties\n\tPrefixFree.prefix\nThe detected prefix of the current browser (like  or )\n\n\tPrefixFree.Prefix\nThe detected prefix of the current browser in camelCase format (like  or )\n\n\tPrefixFree.properties\n\tPrefixFree.functions\n\tPrefixFree.keywords\n\tPrefixFree.selectors\n\tPrefixFree.atrules\nProperties/functions/keywords/etc that are only available with a prefix in the current browser.\n\n### Functions\n\tPrefixFree.prefixCSS(code [, raw])\nPrefixes the properties and values in the code passed with the prefix of the current browser, only when needed. If the second parameter is truthy, it also prefixes selectors and @-rules. This is the most useful method in -prefix-free.\n\n\tPrefixFree.prefixSelector(selector)\n\tPrefixFree.prefixProperty(property)\nPrefixes the passed selector or property. The property is prefixed even when it. These are more internal methods and I assume they wont be too useful in general.\n'"
iPython Notebook for Challenge 1 of ODSC Hackathon,b'# odsc_hackathon\niPython Notebook for Challenge 1 of ODSC Hackathon\n'
A speech recognition library for the web,"b'JuliusJS\r\n====\r\n\r\n> A speech recognition library for the web\r\n\r\nTry the \r\n\r\nJuliusJS is an opinionated port of Julius to JavaScript. \r\nIt actively listens to the user to transcribe what they are saying through a callback.\r\n\r\n\r\n\r\n###### Features:\r\n\r\n- Real-time transcription\r\n - Use the provided grammar, or write your own\r\n- 100% JavaScript implementation\r\n - All recognition is done in-browser through a \r\n - Familiar event-inspired API\r\n - No external server calls\r\n\r\n## Quickstart\r\n\r\n##### Using Express 4.0\r\n\r\n1. Grab the latest version with bower\r\n - \r\n1. Include  in your html\r\n - \r\n1. Make the scripts available to the client through your server\r\n  \r\n1. In your main script, bootstrap JuliusJS and register an event listener for recognition events\r\n  \r\n\r\n- Your site now has real-time speech recognition baked in!\r\n\r\n### Configure your own recognition grammar\r\n\r\nIn order for JuliusJS to use it, your grammar must follow the . The site includes a tutorial on writing grammars.\r\nBy default, phonemes are defined in , though you might find  more useful as reference.\r\n\r\n- Building your own grammar requires the  script and associated binaries, distributed with Julius.\r\n - On Mac OS X\r\n   - Use , included with this repo\r\n - On other OS\r\n   - Run  to populate  with the necessary files\r\n\r\n1. Write a  file with words to be recognized\r\n - The  file defines ""word candidates"" and their pronunciations.\r\n1. Write a  file with phrases composed of those words\r\n - The  file defines ""category-level syntax, i.e. allowed connection of words by their category name.""\r\n1. Compile the grammar using \r\n - The  and  must be prefixed with the same name\r\n - This will generate  and \r\n1. Give the new  and  files to the  constructor\r\n  \r\n  \r\n\r\n## Advanced Use\r\n\r\n### Configuring the engine\r\n\r\nThe  constructor takes three arguments which can be used to tune the engine:\r\n\r\n\r\n\r\n_Both path/to/dfa and path/to/dict must be set to use a custom grammar_\r\n\r\n##### path/to/dfa\r\n- path to a valid  file, generated as described \r\n- if left , the default grammar will be used\r\n\r\n##### path/to/dict\r\n- path to a valid  file, generated as described \r\n- if left , the default grammar will be used\r\n\r\n##### options\r\n-  - if \r\n-  - if \r\n -  by default\r\n-  - if \r\n - this is mostly useful for debugging\r\n- \r\n - Julius supports a wide range of options. Most of these are made available here, by specifying the flag name as a key. For example:  will lower the zero-crossing threshold to 30. Some of these options will break JuliusJS, so use with caution.\r\n - A reference to available options can be found in the .\r\n - Currently, the only supported hidden markov model is from voxforge. The  and  options are unsupported.\r\n\r\n## Examples\r\n\r\n### Voice Command\r\n\r\n_Coming soon...\r\n\r\n### Keyword Spotting (e.g., API integration)\r\n\r\n_Coming soon...\r\n\r\n### In the wild\r\n\r\n_If you use  let me know, and Ill add your project to this list (or issue a pull request yourself).\r\n\r\n1. \r\n\r\n### Build from source\r\n\r\n__You Once you have that, run . If you are missing other tools, the script will let you know.\r\n\r\nAs emscript.sh reloads and recompiles static libraries,  is available once youve already run emscript.sh. reemscript.sh will only recompile to JavaScript based on your latest changes. This can also be run with .\r\n\r\nAdditionally, tests are set will be made to run using . In the meantime,  a blank page with the JuliusJS library can be served using .\r\n\r\n### Codemap\r\n\r\n##### emscript.sh / reemscript.sh\r\n\r\nThese scripts will compile/recompile Julius C source to JavaScript, as well as copy all other necessary files, to the js folder.\r\n\r\nemscript.sh will also compile binaries, which you can use to create recognition grammars or compile grammars to smaller binary files. These are copied to the bin folder.\r\n\r\n##### src\r\n\r\nThis is where the source for Julius will go once emscript.sh is run. emscript.sh will replace certain files in src/julius4 with those in src/include in order to make src/emscripted, the files eventually compiled to JavaScript.\r\n\r\n- src/include/julius/app.h - the main application header\r\n- src/include/julius/main.c - the main application\r\n- src/include/julius/recogloop.c - a wrapper around the recognition loop\r\n- src/include/libjulius/src/adin_cut.c - interactions with a microphone\r\n- src/include/libjulius/src/m_adin.c - initialization to Web Audio\r\n- src/include/libjulius/src/recogmain.c - the main recognition loop\r\n- src/include/libsent/configure[.in] - configuration to add Web Audio\r\n- src/include/libsent/src/adin/adin_mic_webaudio.c - input on Web Audio\r\n\r\n_Files in bold were changed to replace a loop with eventing, to simulate multithreading in a Worker._\r\n\r\n##### js\r\n\r\nThe home to the testing server run with . Files are copied to this folder from dist with emscript.sh and reemscript.sh. If they are modified, they should be commited back to the dist folder.\r\n\r\n##### dist\r\n\r\nThe home for committed copies of the compiled library, as well as the wrappers that make them work: julius.js and worker.js. dist/listener/converter.js is the file that actually pipes Web Audio to Julius (the compiled C program).\r\n\r\n---\r\n\r\nJuliusJS is a port of the ""Large Vocabulary Continuous Speech Recognition Engine Julius"" to JavaScript\r\n'"
HKAiportSchedule,b'# HKAiportSchedule\nHKAiportSchedule\n\nI am trying to write a show scrip to capture the arrival / departure schedule & actually delay for all the flight using HKIA (Hong Kong International Airport).\n\nThis is still in progress and feel free to provide your comment. :)\n\nLibraries used are quite common \n* lxml (for html parsing)\n* requests (for making HTTP calls)\n* pandas (for data manipulation)\n'
[NOT MAINTAINED] Simple global state for React with Hooks API without Context API,"b""This project is no longer maintained.\nPlease directly use .\n\n---\n\n# react-hooks-global-state\n\n\n\n\n\n\nSimple global state for React with Hooks API without Context API\n\n## Introduction\n\nThis is a library to provide a global state with React Hooks.\nIt has following characteristics.\n\n*   Optimization for shallow state getter and setter.\n    *   The library cares the state object only one-level deep.\n*   TypeScript type definitions\n    *   A creator function creates hooks with types inferred.\n*   Redux middleware support to some extent\n    *   Some of libraries in Redux ecosystem can be used.\n\n## Install\n\n\n\n## Usage\n\n### setState style\n\n\n\n### reducer style\n\n\n\n## API\n\n\n\n### createGlobalState\n\nCreate a global state.\n\nIt returns a set of functions\n\n*   : a custom hook works like React.useState\n*   : a function to get a global state by key outside React\n*   : a function to set a global state by key outside React\n*   : a function that subscribes to state changes\n\n#### Parameters\n\n*    State \n\n#### Examples\n\n\n\n### createStore\n\nCreate a global store.\n\nIt returns a set of functions\n\n*   : a custom hook to read store state by key\n*   : a function to get store state by key outside React\n*   : a function to dispatch an action to store\n\nA store works somewhat similarly to Redux, but not the same.\n\n#### Parameters\n\n*    Reducer \n*    State  (optional, default )\n*    any? \n\n#### Examples\n\n\n\nReturns Store \n\n### useGlobalState\n\nuseGlobalState created by createStore is deprecated.\n\nType: function (stateKey: StateKey): any\n\nMeta\n\n*   deprecated: useStoreState instead\n\n## Examples\n\nThe  folder contains working examples.\nYou can run one of them with\n\n\n\nand open  in your web browser.\n\nYou can also try them in codesandbox.io:\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Blogs\n\n*   \n*   \n*   \n*   \n*   \n*   \n\n## Community Wiki\n\n*   \n*   \n"""
A Rust compiler front-end for IDEs,"b'\n  <img\n    src=""https://raw.githubusercontent.com/rust-analyzer/rust-analyzer/master/assets/logo-wide.svg""\n    alt=""rust-analyzer logo"">\n\n\nrust-analyzer is a modular compiler frontend for the Rust language.\nIt is a part of a larger rls-2.0 effort to create excellent IDE support for Rust.\n\n## Quick Start\n\nhttps://rust-analyzer.github.io/manual.html#installation\n\n## Documentation\n\nIf you want to contribute to rust-analyzer or are just curious about how\nthings work under the hood, check the  folder.\n\nIf you want to use rust-analyzers language server with your editor of\nchoice, check  folder.\nIt also contains some tips & tricks to help you be more productive when using rust-analyzer.\n\n## Security and Privacy\n\nSee the corresponding sections of .\n\n## Communication\n\nFor usage and troubleshooting requests, please use ""IDEs and Editors"" category of the Rust forum:\n\nhttps://users.rust-lang.org/c/ide/14\n\nFor questions about development and implementation, join rust-analyzer working group on Zulip:\n\nhttps://rust-lang.zulipchat.com/#narrow/stream/185405-t-compiler.2Frust-analyzer\n\n## Quick Links\n\n* Website: https://rust-analyzer.github.io/\n* Metrics: https://rust-analyzer.github.io/metrics/\n* API docs: https://rust-lang.github.io/rust-analyzer/ide/\n* Changelog: https://rust-analyzer.github.io/thisweek\n\n## License\n\nrust-analyzer is primarily distributed under the terms of both the MIT\nlicense and the Apache License (Version 2.0).\n\nSee LICENSE-APACHE and LICENSE-MIT for details.\n'"
Bitcoin implementation in PHP,"b'  \n## Bitcoin\n\n\n\n\n\n\nThis repository contains an implementation of Bitcoin using mostly pure PHP.\n\nWarning: This library does not support 32-bit installs of PHP. Please also note that composer is the only supported installation method.\n\n## Installation\n\nYou can install this library via Composer: \n\n## Contributing\n\nAll contributions are welcome. Please see [] before you get started\n\n## Documentation\n\n Check out the beginnings of the documentation for the library: []\n\n## Presently supported:\n\n - Blocks, headers, and merkle blocks and bloom filters\n - P2SH & Segregated witness scripts\n - An adaptable elliptic-curve library, using [] by default, or libsecp256k1 if the bindings are found\n - Support for building, parsing, signing/validating transactions\n - Deterministic signatures (RFC6979)\n - BIP32 and electrum (older type I) deterministic key algorithms\n - BIP39, and the older electrum seed format.\n - ScriptFactory for common input/output types, parser, interpreter, and classifiers\n - Supports bindings to libbitcoinconsensus\n - Bindings to Stratum (electrum) servers\n\n# Other projects\n\n -  - Toolkit for working with binary data in PHP\n -  - PHP bindings to libsecp256k1\n -  - PHP bindings to libbitcoinconsensus\n -  - PHP implementation of bitcoin P2P messaging using reactphp\n -  - PHP implementation of the stratum protocol using reactphp\n -  - Electrum server discovery (over IRC) using reactphp\n -  - A toy project (really just for fun) a full node using bitcoin-p2p-php\n -  - A BIP70 (payment requests) implementation for PHP\n\n## Supporters\n\nThis library is a 100% open source project. We do not receive any funding from the industry, nor provide paid support or development of features. That said, we are grateful for our supporters who provide free access for open source projects:\n\n\n\nThanks to  for supporting the project through sponsoring some  within their  program.\n'"
The Go programming language,"b'# The Go Programming Language\n\nGo is an open source programming language that makes it easy to build simple,\nreliable, and efficient software.\n\n\nGopher image by [Renee French][rf], licensed under [Creative Commons 4.0 Attributions license][cc4-by].\n\nOur canonical Git repository is located at https://go.googlesource.com/go.\nThere is a mirror of the repository at https://github.com/golang/go.\n\nUnless otherwise noted, the Go source files are distributed under the\nBSD-style license found in the LICENSE file.\n\n### Download and Install\n\n#### Binary Distributions\n\nOfficial binary distributions are available at https://go.dev/dl/.\n\nAfter downloading a binary release, visit https://go.dev/doc/install\nfor installation instructions.\n\n#### Install From Source\n\nIf a binary distribution is not available for your combination of\noperating system and architecture, visit\nhttps://go.dev/doc/install/source\nfor source installation instructions.\n\n### Contributing\n\nGo is the work of thousands of contributors. We appreciate your help!\n\nTo contribute, please read the contribution guidelines at https://go.dev/doc/contribute.\n\nNote that the Go project uses the issue tracker for bug reports and\nproposals only. See https://go.dev/wiki/Questions for a list of\nplaces to ask questions about the Go language.\n\n[rf]: https://reneefrench.blogspot.com/\n[cc4-by]: https://creativecommons.org/licenses/by/4.0/\n'"
Phoenix Pull-to-Refresh,"b' \n\n# Phoenix Pull-to-Refresh\n\n#### This project aims to provide a simple and customizable pull to refresh implementation. Made in [Yalantis] (https://yalantis.com/?utm_source=github)\n\nCheck this [project on Dribbble] (https://dribbble.com/shots/1650317-Pull-to-Refresh-Rentals)  \nCheck this [project on Behance] (https://www.behance.net/gallery/20411445/Mobile-Animations-Interactions)  \n\n\n\n#Usage\n\nFor a working implementation, Have a look at the Sample Project - sample\n\n1. Include the library as local library project.\n\n    \n\n2. Include the PullToRefreshView widget in your layout.\n\n\t\n\n3. In your  method refer to the View and setup OnRefreshListener.\n\t\n\n#Customization\n\nTo customize drawables you can change:\n   * sun.png - Sun image\n   * sky.png - background image\n   * buildings.png - foreground image\n\n# Misc\nIf you need to change progress state:\n\n#Compatibility\n  \n  * Android GINGERBREAD 2.3+\n  \n# Changelog\n\n### Version: 1.2\n\n  * Sample updated with RecyclerView example\n  * Showing the refresh view just in its bounds. (Issue with transparent / empty ListView)\n  * Possibility to set refresh view padding\n\n### Version: 1.0\n\n  * Initial Build\n\n#### Let us know!\n\nWe\xe2\x80\x99d be really happy if you sent us links to your projects where you use our component. Just send an email to github@yalantis.com And do let us know if you have any questions or suggestion regarding the animation. \n\nP.S. We\xe2\x80\x99re going to publish more awesomeness wrapped in code and a tutorial on how to make UI for Android (iOS) better than better. Stay tuned!\n\n## License\n\n    Copyright 2017, Yalantis\n\n    Licensed under the Apache License, Version 2.0 (the ""License"");\n    you may not use this file except in compliance with the License.\n    You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n    Unless required by applicable law or agreed to in writing, software\n    distributed under the License is distributed on an ""AS IS"" BASIS,\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    See the License for the specific language governing permissions and\n    limitations under the License.\n'"
DEPRECATED: A rich text editor framework for the web platform,"b'THIS PROJECT IS DEPRECATED - You can find more information about this in our blog post, . In summary:\n\n- We have no plans to add features to Scribe but may make critical updates throughout the period that we continue to use instances of Scribe internally\n- We recommend forking the project in order to do any feature work as we will not be moving the Scribe repository out of the Guardian organisation\n- In time we hope to be able to open source the new text editor we are working on\n\n# Scribe\n\nA rich text editor framework for the web platform, with patches for\nbrowser inconsistencies and sensible defaults.\n\n## Status\n\n   \n\n## Description\n\nFor an introduction, you may want to read the blog post .\n\nPlease note: There is a lot of missing documentation for Scribe and many of its plugins. We plan to improve this, however in the meantime we encourage you to look at the code. Scribe is very small in comparison to other libraries of its kind.\n\nYou can join us on IRC at [#scribejs] on freenode, or via the .\n\n[See an example][example].\n\nScribe only actively supports a .\n\n## Core\n\nAt the core of Scribe we have:\n\n* ;\n* .\n\n### Patches\n\nScribe patches [many browser inconsistencies][browser inconsistencies] in the [native command API][Executing Commands].\n\n## Installation\n\n\nAlternatively, you can .\n\n## Usage Example\n\nScribe is an AMD module:\n\n\n\nYou can [see a live example here][example], or .\n\nAlso be sure to check the  directory for an\nAMD syntax example as well as a CommonJS (browserify) example.\n\n## Options\n\n\n  allowBlockElements\n  Enable/disable block element mode (enabled by default)\n  undo: { enabled: false }\n  Enable/disable Scribes custom undo manager\n  defaultCommandPatches\n  Defines which command patches should be loaded by default\n  defaultPlugins\n  Defines which of Scribes built-in plugins should be active\n  defaultFormatters\n  Defines which of Scribes default formatters should be active\n\n\nFor detailed documentation see the .\n\n## Architecture\n\n* .\n* No runtime dependencies.\n\nA plugin is simply a function that receives Scribe as an argument:\n\n\n\nA consumer can then use your plugin with :\n\n\n\nPlugins may package whatever functionality you desire, and you are free to use\nnative APIs to do so. However, you are required to wrap any DOM manipulation in\na transaction, so that we can capture state changes for the history. For\nexample:\n\n\n\n### Browser Support\n\n\n\n## Plugins\n\nScribe has a rich plugin ecosystem that expands and customises what it can do.\n\nSee the wiki for a \n\n## FAQ\n\nSee the wikis \n\n[browser inconsistencies]: https://github.com/guardian/scribe/blob/master/BROWSERINCONSISTENCIES.md\n[Executing Commands]: https://developer.mozilla.org/en-US/docs/Rich-Text_Editing_in_Mozilla#Executing_Commands\n[Range API]: https://developer.mozilla.org/en-US/docs/Web/API/Range\n[Selection API]: https://developer.mozilla.org/en-US/docs/Web/API/Selection\n[example]: http://guardian.github.io/scribe\n'"
A command-line installer for Windows.,"b'\n\n    Scoop\n\n\nFeatures\n|\nInstallation\n|\nDocumentation\n\n\n- - -\n\n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n    \n        \n    \n\n\nScoop is a command-line installer for Windows.\n\n## What does Scoop do?\n\nScoop installs programs from the command line with a minimal amount of friction. It:\n\n- Eliminates permission popup windows\n- Hides GUI wizard-style installers\n- Prevents PATH pollution from installing lots of programs\n- Avoids unexpected side-effects from installing and uninstalling programs\n- Finds and installs dependencies automatically\n- Performs all the extra setup steps itself to get a working program\n\nScoop is very scriptable, so you can run repeatable setups to get your environment just the way you like, e.g.:\n\n\n\nIf youve built software that youd like others to use, Scoop is an alternative to building an installer (e.g. MSI or InnoSetup) \xe2\x80\x94 you just need to zip your program and provide a JSON manifest that describes how to install it.\n\n## Installation\n\nRun the following command from a non-admin PowerShell to install scoop to its default location .\n\n\n\nAdvanced installation instruction and full documentation of the installer are available in . Please create new issues there if you have questions about the installation.\n\n## \n\n## Multi-connection downloads with \n\nScoop can utilize  to use multi-connection downloads. Simply install  through Scoop and it will be used for all downloads afterward.\n\n\n\nBy default,  displays a warning when running  or  while  is enabled. This warning can be suppressed by running .\n\nYou can tweak the following  settings with the  command:\n\n- aria2-enabled (default: true)\n- aria2-warning-enabled (default: true)\n-  (default: 2)\n-  (default: 5)\n-  (default: 5)\n-  (default: 5M)\n-  (default: )\n\n## Inspiration\n\n- \n- \n\n## What sort of apps can Scoop install?\n\nThe apps that install best with Scoop are commonly called ""portable"" apps: i.e. compressed program files that run stand-alone when extracted and dont have side-effects like changing the registry or putting files outside the program directory.\n\nSince installers are common, Scoop supports them too (and their uninstallers).\n\nScoop is also great at handling single-file programs and Powershell scripts. These dont even need to be compressed. See the  package for an example: its really just a GitHub gist.\n\n### Contribute to this project\n\nIf youd like to improve Scoop by adding features or fixing bugs, please read our .\n\n### Support this project\n\nIf you find Scoop useful and would like to support ongoing development and maintenance, heres how:\n\n-  (one-time donation)\n\n## Known application buckets\n\nThe following buckets are known to scoop:\n\n-  - Default bucket for the most common (mostly CLI) apps\n-  - Apps that dont fit the main buckets \n-  - Open source/freeware games and game-related tools\n-  -  Nerd Fonts\n-  - Almost all of the  apps from \n-  - Sysinternals Suite and all individual application from \n-  - A collection of Java development kits (JDKs), Java runtime engines (JREs), Javas virtual machine debugging tools and Java based runtime engines.\n-  - Non-portable apps (may require UAC)\n-  - Installers for most versions of PHP\n-  - Alternative versions of apps found in other buckets\n\nThe main bucket is installed by default. To add any of the other buckets, type:\n\n\n\nFor example, to add the extras bucket, type:\n\n\n\n## Other application buckets\n\nMany other application buckets hosted on Github can be found in the  or via .\n'"
":tropical_drink: A curated list of awesome gulp resources, plugins, and boilerplates for a better development workflow automation - http://alferov.github.io/awesome-gulp","b""# Awesome Gulp \n\n> A curated list of awesome  resources, plugins, and boilerplates for a better development workflow automation.\n\n_Looking for something else? Take a look at other ._\n\n## Contribution\n\n:octocat: All contributions welcome. Feel free to contribute ().\n\n## Contents\n\n- \n- \n  - \n  - \n  - \n  - \n    - \n    - \n    - \n    - \n    - \n    - \n    - \n    - \n  - \n- \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n  - \n- \n  - \n  - \n- \n\n## Legend\n\n[:no_entry:] - A deprecation notice;\n\n## Resources\n\n### General Resources\n\n- \n- \n- \n- \n- \n\n### Official Documentation\n\n- \n- \n- \n- \n- \n\n### Community\n\n- \n- \n\n### Tutorials\n\n#### Gulp Tutorials\n\n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n- \n\n#### Gulp 4 Tutorials\n\n- \n- \n\n#### Gulp with Browserify\n\n- \n- \n- \n\n#### Gulp with Angular\n\n- \n\n#### Gulp with Angular and Browserify\n\n- \n\n#### Gulp with Angular and Webpack\n\n- \n- \n- \n\n#### Gulp with React and Browserify\n\n- \n- \n\n#### Gulp with Ember\n\n- \n\n#### Gulp with WordPress\n\n- \n\n### Miscellaneous Resources\n\n- \n- \n\n## Plugins\n\n### Compilation\n\n-  - Sass \xe2\x86\x92 CSS with .\n-  - Sass \xe2\x86\x92 CSS with Ruby Sass.\n-  - Sass \xe2\x86\x92 CSS with Ruby Sass & Compass.\n-  -  \xe2\x86\x92 CSS.\n-  -  \xe2\x86\x92 CSS.\n-  - Pipe CSS through  processors with a single parse.\n-  -  \xe2\x86\x92 JavaScript.\n-  -  \xe2\x86\x92 JavaScript.\n-  - Facebook  JSX templates \xe2\x86\x92 JavaScript.\n-  - Run  as a stream to conveniently integrate with gulp.\n\n### Transpilation\n\n-  - ES6 \xe2\x86\x92 ES5 with .\n-  - ES6 \xe2\x86\x92 ES5 using .\n-  - ES6 \xe2\x86\x92 ES5 with .\n-  - [:no_entry:] ES6 \xe2\x86\x92 ES5 with .\n-  -  - a polyfill for future versions of the CSS spec.\n-  - [:no_entry:] Use tomorrow's CSS syntax, today, using .\n\n### Concatenation\n\n-  - Concatenate files.\n\n### Minification\n\n-  - Minify CSS with .\n-  - Minify CSS with .\n-  - Minify JavaScript with .\n-  - Minify HTML with .\n-  - Minify PNG, JPEG, GIF and SVG images with .\n-  - Minify SVG files with gulp.\n\n### Optimization\n\n-  - Remove unused CSS selectors with .\n-  - Transform all resources found (those within a url() declaration) in CSS files into base64-encoded data URI strings.\n-  - Convert SVGs to PNGs.\n-  - Generate images at different sizes.\n-  - Combine svg files into one with  elements.\n-  - Create icon fonts from several SVG icons.\n\n### Injecting Assets\n\n-  - Parse build blocks in HTML files to replace references to non-optimized scripts or stylesheets.\n-  - Transform each file to a string and inject each transformed string into placeholders in the target stream files.\n-  - Wire Bower dependencies to your source code.\n\n### Templating\n\n-  - Concatenate and register AngularJS templates in the $templateCache.\n-  -  \xe2\x86\x92 HTML.\n-  -  templates \xe2\x86\x92 JavaScript.\n-  -  templates \xe2\x86\x92 HTML.\n-  -  templates \xe2\x86\x92 JavaScript.\n-  -  templates \xe2\x86\x92 JavaScript.\n-  -  templates \xe2\x86\x92 JavaScript.\n-  - Markdown \xe2\x86\x92 HTML.\n-  -  templates \xe2\x86\x92 JavaScript.\n-  -  templates \xe2\x86\x92 HTML.\n-  - Gulp plugin for  - markdown processor powered by plugins\n\n### Linting\n\n-  - Automated linting of CSS with .\n-  -  wrapper to validate your HTML.\n-  - Detect errors and potential problems in JavaScript with .\n-  - Check JavaScript code style with .\n-  - A style checker that helps keep  code clean.\n-  -  linter plugin for gulp.\n-  - Identify and report on patterns found in ECMAScript/JavaScript code.\n-  - Validate HTML with .\n-  - Lint less files with .\n-  - Check your HTML templates for unused CSS classes.\n\n### Live Reload\n\n-  - Keep multiple browsers & devices in sync when building websites ().\n-  - Gulp plugin for livereload.\n\n### Caching\n\n-  - Only pass through changed files.\n-  - A simple in-memory file cache.\n-  - Remember and recall files passed through it.\n-  - Pass through newer source files only.\n\n### Flow Control\n\n-  - Merge multiple streams into one interleaved stream.\n-  - Pipe queued streams progressively.\n-  - Run a series of dependent gulp tasks in order.\n-  - Conditionally run a task.\n\n### Logging\n\n-  - Notification plugin for gulp.\n-  - Display the size of your project.\n-  - Debug vinyl file streams to see what files are run through your gulp pipeline.\n-  - Better Error Reporting with interactive system notifications and custom server for error displaying.\n\n### Testing\n\n-  - Run  tests.\n-  - Run  tests in Node.js.\n-  - Gulp wrapper for  tests.\n-  - Coverage reporting for Node.js that is independent of the test runner.\n-  - Karma test runner for gulp.\n- - Run  tests with gulp.\n\n### Miscellaneous Plugins\n\n-  - Set of useful utilities.\n-  - Prevent pipe breaking caused by errors.\n-  - Automatically load in gulp plugins.\n-  - Simplify build process setup by dynamically getting the library files.\n-  - Parse CSS and add vendor prefixes to rules by Can I Use.\n-  - Provide source map support.\n-  - A string replace plugin for gulp.\n-  - Rename files easily.\n-  - Static asset revisioning by appending content hash to filenames: unicorn.css \xe2\x86\x92 unicorn-d41d8cd98f.css.\n-  - Delete files/folders using globs.\n-  - Run a shell command.\n-  - Strip console, alert, and debugger statements from JavaScript code.\n-  - Parses a CSS file, finds imports, grabs the content of the linked file and replaces the import statement with it.\n-  - Inline your CSS properties into the style attribute in an HTML file.\n-  - Publish contents to Github pages.\n-  - Add AngularJS dependency injection annotations with .\n-  - Bump any semver JSON version.\n-  - Include files with gulp.\n-  - ZIP compress files.\n-  - Run Git commands with gulp.\n-  - Filter files in a vinyl stream using globbing.\n-  - Preprocess files based on custom context or environment configuration.\n-  - Eval JS-expression or require CommonJS modules and JSON files.\n\n## Scaffolding\n\n### Boilerplates\n\n-  - Google Web Starter Kit.\n-  - Boilerplate to kickstart creating gulp plugins.\n-  - A starting point for Polymer 1.0 apps.\n-  - The most complete React/Flux dev stack and starter kit for isomorphic functional web apps.\n-  - Minimal boilerplate to start a responsive HTML5/Sass project.\n-  - A lightweight, mobile-first boilerplate for front-end web developers.\n-  - Boilerplate using AngularJS, Sass, gulp, and Browserify.\n-  - A Node.js, Hapi, and Swig boilerplate.\n-  - A Laravel 5 boilerplate project.\n-  - React starter kit that contains react-router, Reflux, jest, webpack, gulp and Stylus.\n-  - Frontend boilerplate and modular BEM css framework based on gulp, pug, stylus, postcss, webpack and babel.\n-  - A boilerplate for frontend projects powered by Gulp, HTML5 bolierplate, Sass, PostCss and Webpack(for Babel transpiling).\n\n### Yeoman Generators\n\n-  - A gulp generator for modern webapps.\n-  - Yeoman generator for AngularJS with gulp.\n-  - A Yeoman Generator for React library. It includes gulp, Browserify, Browsersync and Bootstrap.\n-  - A Node.js module generator including gulp and Mocha.\n-  - Yeoman generator for Bootstrap, gulp & libsass.\n-  - Yeoman generator involving AngularJS, gulp and Browserify.\n-  - A Yeoman generator for Ionic Projects with gulp.\n-  - Scaffold out a .\n-  - Jekyll workflow with gulp, Sass, AutoPrefixer, asset optimization and cache busting and much more.\n\n## Miscellaneous\n\n-  - A clean, fluent API for defining basic gulp tasks for your Laravel applications.\n-  - Gulp as an app (OS X).\n-  - Example of gulp tasks unit testing.\n-  - An elegant, intuitive way to reuse gulp tasks.\n\n## License\n\n\n\nTo the extent possible under law,  has waived all copyright and related or neighboring rights to this work.\n"""
Chromium-based cross-platform / cross-language application framework,"b'#### DEPRECATED - This package is no longer supporter or maintained.\n\n\n\n\n\nChromium-based cross-platform / cross-language application framework\n\nThrust is \n\nThrust is based on Chromiums Content Module and is supported on Linux, MacOSX and Windows:\n\n\nScreenshot of Thrust Getting Started example running on each major platform.\n\nTo better understand what Thrust can do, check out [<marko.inline.RawText object at 0x000001F253B86AD0>] by \n@morganrallen, the cross-platform browser that fits in a gist:\n\n\n#### Table of Contents\n- \n  - \n  - \n  - \n  - \n  - \n  - \n- \n- \n- \n  - \n  - \n  - \n  - \n- \n- \n\n***\n## Language bindings\n\nThrusts binary distribution exposes its API on the standard IO and language\n specific library packages automatically download the binary distribution at \ninstallation. Thrust is based on Chromiums content module and uses web-pages \nas its GUI.\n\nAll these Getting Started example work as is on each major platform (MacOSX,\nWindows, Linux)\n\n### NodeJS\n##### Getting Started\n\nFirst install with \n\n\n\n##### Library\n\n- node-thrust \n\n### Go\n\n##### Getting Started\n\nFirst download with \n\n\npackage main\n\nimport (\n\t""github.com/miketheprogrammer/go-thrust/lib/dispatcher""\n\t""github.com/miketheprogrammer/go-thrust/lib/spawn""\n\t""github.com/miketheprogrammer/go-thrust/lib/bindings/window""\n\t""github.com/miketheprogrammer/go-thrust/lib/commands""\n)\n\nfunc main() {\n\tspawn.Run()\n\tsize := commands.SizeHW{}\n\topts := window.Options{\n\t\tRootUrl:  ""http://google.com"",\n\t\tSize:     size,\n\t\tTitle:    ""Demo window"",\n\t\tHasFrame: true,\n\t}\n\tthrustWindow := window.NewWindow(opts)\n\tthrustWindow.Show()\n\tthrustWindow.Maximize()\n\tthrustWindow.Focus()\n\tdispatcher.RunLoop()\n}\n\n##### Library\n\n- go-thrust: \n\n### Python\n\n##### Getting Started\n\nFirst install with  (requires Python3)\n\n\n\n##### Library\n\n- pythrust \n\n### Scala\n\n##### Getting Started\n\nInclude scala-thrust jar on your classpath. (Add to lib in your project.)\n\n\n\n##### Library\n\n- scala-thrust \n\n### Clojure\n\n##### Getting Started\n\n- \n- \n\n\n\n##### Library\n\n- clj-thrust \n\n### Perl\n\n##### Getting Started\n\nInstall with \n\nSimple command line test:\n\n\n\nBasic program\n\n\n\n##### Library\n\n- \n- \n\n\n***\n## API Reference\n\nThe API reference as well as links to specific language bindings documentations \nare availble in the \n directory.\n\n***\n## Architecture\n\n\n\n***\n## Community\n\n##### Request for API\n\n- List of API needed by various projects on Thrust: \n\n\n##### List of Thrust Users \n\n- List of people relying on Thrust: \n\n\n##### Getting Involved\nNo longer maintained actively.\n\n***\n## Features & Roadmap\n\n- [x] window creation create, show, close resize, minimize, maximize, ...\n- [x] node.js, go node.js and go bindings libraries\n- [x] window events close, blur, focus, unresponsive, crashed\n- [x] cross-platform equivalent support on ,  and \n- [x] sessions off the record, custom storage path, custom cookie store\n- [x] kiosk kiosk mode\n- [x] application menu global application menu (MacOSX, X11/Unity)\n- [x] webview webview tag (secure navigation, tabs management)\n- [x] frameless frameless window and draggable regions\n- [x] python python bindings library\n- [x] remote thrust specific IPC mechanism for client/server communication\n- [x] proxy enable traffic proxying (Tor, header injection, ...)\n- [ ] tray icon tray icon native integration\n- [ ] protocol specific protocol registration (, ...)\n\n***\n## Building Thrust from Sources\n\nYou will generally dont need to build thrust yourself. A binary version of \nthrust should be automatically fetched by the library youre reyling on at \ninstallation.\n\nTo build thrust, youll need to have  and  installed. You can \nthen boostrap the project with:\n\n\nBuild both the  and  targets with the following commands:\n\n\nNote that  may take some time as it checks out  and\ndownloads  for your platform.\n\n'"
frontend package manager and build tool for modular web applications,"b'  \n\n\n\n# THIS PROJECT IS DEPRECATED\nComponent is not maintained anymore. See  for more information.\n\nYou can still use the component registry on  to search for components.\n  All the  are not affected, because most of them also provide a  file. \nThe  files in these components are still kept to provide backwards compatibility for component and .\n\n## What now?\nConsider to use another tool, which rely on the  and the  standard:\n\n- \n-  (supports npm and github endpoint)\n- \n\n---\n\n  Component is a vertically integrated frontend solution, handling everything from package management to the build process, handling everything including HTML, JS, CSS, images, and fonts. Think of it as an opinionated  all wrapped into .\n\n  Want to know more about Component? Visit the  or view the .\n\n  If youre confused about component, components, componentjs, please read \n\n> Component 1.0.0: Several\nmajor new features have been added, some have been removed, and the project has been greatly reorganized. You may need to upgrade your\nversion of node and/or npm to avoid breakage. Please see the detailed . Component 0.x will not be maintained anymore.\n\n## Installation\n\n  First, you need  v0.10+ installed. If you do not have it installed, visit .\n\n  With  installed, run the following command:\n\n     $ npm install -g component\n\n## Getting Started\n\nRead this  guide to get a basic static site running very quickly with Component.\n\nNote: the Component repo (this repo) has only documentation for Component 0.19. All of the documentation related to 1.0.0 will be handled in the .\n\n## Team\n\nThe team and organization have undergone massive changes. In summary,  stopped developing Component and started with  and the guys from  switched to using . Component will still be maintained and updated while it is in use. You can read more about Duo.js and Component .\n\nThe long story of Component and the changes that occurred in component can be found in Jonathan Ongs blog post .\n\nDevelopment for component (maintenance and features) will be continued at the latest when latest browsers will support the  and  natively.\n\n## Contributors\n\n- / - maintainer\n- / - maintainer\n- / - maintainer\n-  - maintainer\n- / - maintainer\n- / - original author\n- / - second-gen author\n- / - original sponsor\n'"
":cookie: A full-featured, hackable tiling window manager written and configured in Python (X11 + Wayland)","b""|logo|\n\nA full-featured, hackable tiling window manager written and configured in Python\n\n|website| |pypi| |ci| |rtd| |license| |black| |coverage|\n\nFeatures\n========\n\n* Simple, small and extensible. It's easy to write your own layouts,\n  widgets and commands.\n* Configured in Python.\n* Runs as an X11 WM or a Wayland compositor.\n* Command shell that allows all aspects of Qtile to be managed and\n  inspected.\n* Complete remote scriptability - write scripts to set up workspaces,\n  manipulate windows, update status bar widgets and more.\n* Qtile's remote scriptability makes it one of the most thoroughly\n  unit-tested window managers around.\n\nCommunity\n=========\n\nQtile is supported by a dedicated group of users. If you need any help, please\ndon't hesitate to fire off an email to our mailing list or join us on IRC. You\ncan also ask questions on the discussions board.\n\n:Mailing List: https://groups.google.com/group/qtile-dev\n:Q&A: https://github.com/qtile/qtile/discussions/categories/q-a\n:IRC: irc://irc.oftc.net:6667/qtile\n:Discord: https://discord.gg/ehh233wCrC (Bridged with IRC)\n\nExample code\n============\n\nCheck out the _ repo which contains examples of users' configurations,\nscripts and other useful links.\n\n.. qtile-examples. There are also a few ,\nand  for contributing in the documentation.\n\nPlease also consider submitting useful scripts etc. to the qtile-examples repo\n(see above).\n\n.. issue tracker GPG: \n| _ GPG: \n| _ GPG: \n| _ GPG: \n\n.. _: https://github.com/tych0\n.. _: https://github.com/ramnes\n.. _: https://github.com/m-col\n.. _: https://github.com/flacjacket\n.. _: https://github.com/elparaguayo\n.. _: https://github.com/jwijenbergh\n"""
"APM, (Application Performance Management) tool for large-scale distributed systems. ","b'\n\n\n\n\n\n\n## Latest Release (2023/10/10)\n\nWere happy to announce the release of Pinpoint v2.5.3.\nPlease check the release note at (https://github.com/pinpoint-apm/pinpoint/releases/tag/v2.5.3).\n\nThe current stable version is .\n\n## Live Demo\n\nTake a quick look at Pinpoint with our !\n\n## PHP, PYTHON\n\nPinpoint also supports application written in PHP, Python. .\n\n## About Pinpoint\n\nPinpoint is an APM (Application Performance Management) tool for large-scale distributed systems written in Java / /.\nInspired by ,\nPinpoint provides a solution to help analyze the overall structure of the system and how components within them are interconnected by tracing transactions across distributed applications.\n\nYou should definitely check Pinpoint out If you want to\n\n* understand your [<marko.inline.RawText object at 0x000001F253E7D590>] at a glance\n* monitor your application in Real-Time\n* gain code-level visibility to every transaction\n* install APM Agents without changing a single line of code\n* have minimal impact on the performance (approximately 3% increase in resource usage)\n\n## Getting Started\n *  for simple test run of Pinpoint\n *  for further instructions.\n \n## Overview\nServices nowadays often consist of many different components, communicating amongst themselves as well as making API calls to external services. How each and every transaction gets executed is often left as a blackbox. Pinpoint traces transaction flows between these components and provides a clear view to identify problem areas and potential bottlenecks.\nFor a more intimate guide, please check out our [<marko.inline.RawText object at 0x000001F253E7E710>] video clip.\n\n* ServerMap - Understand the topology of any distributed systems by visualizing how their components are interconnected. Clicking on a node reveals details about the component, such as its current status, and transaction count.\n* Realtime Active Thread Chart - Monitor active threads inside applications in real-time.\n* Request/Response Scatter Chart - Visualize request count and response patterns over time to identify potential problems. Transactions can be selected for additional detail by dragging over the chart.\n\n  \n\n* CallStack - Gain code-level visibility to every transaction in a distributed environment, identifying bottlenecks and points of failure in a single view.\n\n  \n\n* Inspector - View additional details on the application such as CPU usage, Memory/Garbage Collection, TPS, and JVM arguments.\n\n  \n\n* URI-metric\n  \n\n* Infrastructure\n  \n\n## Supported Modules\n* JDK 8+\n* , , , , , , , , \n* ,  (, , , ), \n* Apache HttpClient  /  / , , , , \n* , , , \n* , , , , \n* , , , , , , , , \n* , , Redis(, , ), , , , \n* , \n* , , , \n* , , , \n* , , \n* , \n\n## Compatibility\n\nJava version required to run Pinpoint:\n<!-- <compatibilityJava.md> -->\n| Pinpoint Version | Agent | Collector | Web | Flink |\n|------------------|-------|-----------|-----|-------|\n| 2.0.x            | 6-13  | 8         | 8   | 8     |\n| 2.1.x            | 6-14  | 8         | 8   | 8     |\n| 2.2.x            | 7-14  | 8         | 8   | 8     |\n| 2.3.x            | 7-17  | 8         | 8   | 8     |\n| 2.4.x            | 7-18  | 11        | 11  | 11    |\n| 2.5.x            | 8-19  | 11        | 11  | 11    |\n| 3.0.x            | 8-21  | 17        | 17  | 17    |\n\n<!-- </compatibilityJava.md> -->\nHBase compatibility table:\n<!-- <compatibilityHbase.md> -->\n| Pinpoint Version | HBase 1.x | HBase 2.x                                                                                                             |\n|------------------|-----------|-----------------------------------------------------------------------------------------------------------------------|\n| 2.0.x            | yes       |  |\n| 2.1.x            | yes       |  |\n| 2.2.x            | yes       |  |\n| 2.3.x            | yes       |                                     |\n| 2.4.x            | yes       |                                     |\n| 2.5.x            | yes       |                                     |\n| 3.0.x            | no         | yes                                    |\n\n<!-- </compatibilityHbase.md> -->\nAgent - Collector compatibility table:\n<!-- <compatibilityPinpoint.md> -->\n| Agent Version | Collector 2.0.x | Collector 2.1.x | Collector 2.2.x | Collector 2.3.x | Collector 2.4.x | Collector 2.5.x | Collector 3.0.x |\n|---------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|\n| 2.0.x         | yes             | yes             | yes             | yes             | yes             | yes             | yes             |\n| 2.1.x         | no              | yes             | yes             | yes             | yes             | yes             | yes             |\n| 2.2.x         | no              | no              | yes             | yes             | yes             | yes             | yes             |\n| 2.3.x         | no              | no              | no              | yes             | yes             | yes             | yes             |\n| 2.4.x         | no              | no              | no              | no              | yes             | yes             | yes             |\n| 2.5.x         | no              | no              | no              | no              | no              | yes             | yes             |\n| 3.0.x         | no              | no              | no              | no              | no              | no              | yes             |\n\n<!-- </compatibilityPinpoint.md> -->\nFlink compatibility table:\n<!-- <compatibilityFlink.md> -->\n| Pinpoint Version | Flink 1.3.X | Flink 1.4.X | Flink 1.5.X | Flink 1.6.X | Flink 1.7.X | Flink 1.14.X |\n|------------------|-------------|-------------|-------------|-------------|-------------|--------------|\n| 2.0.x            | yes         | yes         | yes         | yes         | yes         | no           |\n| 2.1.x            | yes         | yes         | yes         | yes         | yes         | no           |\n| 2.2.x            | yes         | yes         | yes         | yes         | yes         | no           |\n| 2.3.x            | yes         | yes         | yes         | yes         | yes         | no           |\n| 2.4.x            | yes         | yes         | yes         | yes         | yes         | yes          |\n| 2.5.x            | yes         | yes         | yes         | yes         | yes         | yes          |\n<!-- </compatibilityFlink.md> -->\nPinot compatibility table:\n<!-- <compatibilityPinot.md> -->\n| Pinpoint Version | Pinot 0.11.0 | Pinot 0.12.0 | Pinot 1.0.0    |\n|------------------|--------------|--------------|----------------|\n| 2.5.x            | yes          | yes          | yes            |\n| 3.0.x            | no           | no           | yes            | \n\n\n## Community\n\n  \n  \n  \n\nWe have Chinese community now, welcome to join!\n\n\n   \xf0\x9f\x91\x86 click me\n\n\nQQ Group1: 897594820 | QQ Group2: 812507584 | QQ Group3: 882020485| DING Group : 21981598\n:----------------: |:----------------: | :-----------: | :-----------: \n | | | \n\n\n\n## License\nPinpoint is licensed under the Apache License, Version 2.0.\nSee  for full license text.\n\n\n\n'"
Distributed reliable key-value store for the most critical data of a distributed system,"b'# etcd\n\n\n\n\n\n\n\n\n\n\n\nNote: The  branch may be in an unstable or even broken state during development. For stable versions, see [releases][github-release].\n\n\n\netcd is a distributed reliable key-value store for the most critical data of a distributed system, with a focus on being:\n\n* Simple: well-defined, user-facing API (gRPC)\n* Secure: automatic TLS with optional client cert authentication\n* Fast: benchmarked 10,000 writes/sec\n* Reliable: properly distributed using Raft\n\netcd is written in Go and uses the [Raft][] consensus algorithm to manage a highly-available replicated log.\n\netcd is used , and the development team stands behind it in critical deployment scenarios, where etcd is frequently teamed with applications such as [Kubernetes][k8s], [locksmith][], [vulcand][], [Doorman][], and many others. Reliability is further ensured by rigorous .\n\nSee [etcdctl][etcdctl] for a simple command line client.\n\n\n\nOriginal image credited to  xkcd.com/2347, alterations by Josh Berkus.\n\n[raft]: https://raft.github.io/\n[k8s]: http://kubernetes.io/\n[doorman]: https://github.com/youtube/doorman\n[locksmith]: https://github.com/coreos/locksmith\n[vulcand]: https://github.com/vulcand/vulcand\n[etcdctl]: https://github.com/etcd-io/etcd/tree/main/etcdctl\n\n## Maintainers\n\n strive to shape an inclusive open source project culture where users are heard and contributors feel respected and empowered. Maintainers aim to build productive relationships across different companies and disciplines. Read more about .\n\n## Getting started\n\n### Getting etcd\n\nThe easiest way to get etcd is to use one of the pre-built release binaries which are available for OSX, Linux, Windows, and Docker on the [release page][github-release].\n\nFor more installation guides, please check out  and .\n\n[github-release]: https://github.com/etcd-io/etcd/releases\n\n### Running etcd\n\nFirst start a single-member cluster of etcd.\n\nIf etcd is installed using the [pre-built release binaries][github-release], run it from the installation location as below:\n\n\n\nThe etcd command can be simply run as such if it is moved to the system path as below:\n\n\n\nThis will bring up etcd listening on port 2379 for client communication and on port 2380 for server-to-server communication.\n\nNext, lets set a single key, and then retrieve it:\n\n\n\netcd is now running and serving client requests. For more, please check out:\n\n* \n* \n\n### etcd TCP ports\n\nThe [official etcd ports][iana-ports] are 2379 for client requests, and 2380 for peer communication.\n\n[iana-ports]: http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt\n\n### Running a local etcd cluster\n\nFirst install , which manages Procfile-based applications.\n\nOur  will set up a local example cluster. Start it with:\n\n\n\nThis will bring up 3 etcd members ,  and  and optionally etcd , which runs locally and composes a cluster.\n\nEvery cluster member and proxy accepts key value reads and key value writes.\n\nFollow the comments in  to add a learner node to the cluster.\n\n### Install etcd client v3\n\n\n\n### Next steps\n\nNow its time to dig into the full etcd API and other guides.\n\n* Read the full [documentation].\n* Review etcd [frequently asked questions].\n* Explore the full gRPC [API].\n* Set up a [multi-machine cluster][clustering].\n* Learn the [config format, env variables and flags][configuration].\n* Find [language bindings and tools][integrations].\n* Use TLS to [secure an etcd cluster][security].\n* [Tune etcd][tuning].\n\n[documentation]: https://etcd.io/docs/latest\n[api]: https://etcd.io/docs/latest/learning/api\n[clustering]: https://etcd.io/docs/latest/op-guide/clustering\n[configuration]: https://etcd.io/docs/latest/op-guide/configuration\n[integrations]: https://etcd.io/docs/latest/integrations\n[security]: https://etcd.io/docs/latest/op-guide/security\n[tuning]: https://etcd.io/docs/latest/tuning\n\n## Contact\n\n* Email: \n* Slack:  channel on Kubernetes ()\n* \n\n### Community meetings\n\netcd contributors and maintainers meet every week at 11:00 AM (USA Pacific) on Thursday and meetings alternate between community meetings and issue triage meetings. An initial agenda will be posted to the [shared Google docs][shared-meeting-notes] a day before each meeting, and everyone is welcome to suggest additional topics or other agendas. \n\nIssue triage meetings are aimed at getting through our backlog of PRs and Issues. Triage meetings are open to any contributor; you dont have to be a reviewer or approver to help out! They can also be a good way to get started contributing.\n\nMeeting recordings are uploaded to official etcd [YouTube channel].\n\nGet calendar invitation by joining  mailing group.\n\nJoin CNCF-funded Zoom channel: \n\n[shared-meeting-notes]: https://docs.google.com/document/d/16XEGyPBisZvmmoIHSZzv__LoyOeluC5a4x353CX0SIM/edit\n[YouTube channel]: https://www.youtube.com/channel/UC7tUWR24I5AR9NMsG-NYBlg\n\n## Contributing\n\nSee  for details on setting up your development environment, submitting patches and the contribution workflow.\n\nPlease refer to  for information on becoming an etcd project member.  We welcome and look forward to your contributions to the project!\n\nPlease also refer to  to get more details on the priorities for the next few major or minor releases.\n\n## Reporting bugs\n\nSee  for details about reporting any issues. Before opening an issue please check it is not covered in our [frequently asked questions].\n\n[frequently asked questions]: https://etcd.io/docs/latest/faq\n\n## Reporting a security vulnerability\n\nSee  for details on how to report a security vulnerability and how the etcd team manages it.\n\n## Issue and PR management\n\nSee  for details on how issues are managed.\n\nSee  for guidelines on how pull requests are managed.\n\n## etcd Emeritus Maintainers\n\nThese emeritus maintainers dedicated a part of their career to etcd and reviewed code, triaged bugs and pushed the project forward over a substantial period of time. Their contribution is greatly appreciated.\n\n* Fanmin Shi\n* Anthony Romano\n* Brandon Philips\n* Joe Betz\n* Gyuho Lee\n* Jingyi Hu\n* Xiang Li\n* Ben Darnell\n* Sam Batschelet\n\n### License\n\netcd is under the Apache 2.0 license. See the  file for details.\n'"
A block-style editor with clean JSON output,"b'\n  \n    \n      \n      \n      \n        \n  \n\n\n\n editorjs.io |\n  documentation |\n  changelog\n  \n\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n## About\n\nEditor.js is an open-source text editor offering a variety of features to help users create and format content efficiently. It has a modern, block-style interface that allows users to easily add and arrange different types of content, such as text, images, lists, quotes, etc. Each Block is provided via a separate plugin making Editor.js extremely flexible.\n\nEditor.js outputs a clean JSON data instead of heavy HTML markup. Use it in Web, iOS, Android, AMP, Instant Articles, speech readers, AI chatbots \xe2\x80\x94 everywhere. Easy to sanitize, extend and integrate with your logic. \n\n- \xf0\x9f\x98\x8d\xc2\xa0\xc2\xa0Modern UI out of the box\n- \xf0\x9f\x92\x8e\xc2\xa0\xc2\xa0Clean JSON output\n- \xe2\x9a\x99\xef\xb8\x8f\xc2\xa0\xc2\xa0Well-designed API\n- \xf0\x9f\x9b\x8d\xc2\xa0\xc2\xa0Various Tools available\n- \xf0\x9f\x92\x8c\xc2\xa0\xc2\xa0Free and open source\n\n\n  \n   \n\n## Installation\n\nIts quite simple:\n\n1. Install Editor.js \n2. Install tools you need\n3. Initialize Editors instance\n\nInstall using NPM, Yarn, or :\n\n\n\nChoose and install tools:\n\n- \n- \n-  \n-  (without backend requirement)\n- \n- \n- \n-  (YouTube, Twitch, Vimeo, Gfycat, Instagram, Twitter, etc)\n- \n- \n- \n- \n- \n- \n- \n- \n\nSee the  list for more tools.\n\nInitialize the Editor:\n\n\n\njavascript\nconst data = await editor.save()\n```\n\n### Example\n\nTake a look at the  to view more detailed examples.\n\n\n## Roadmap\n\n\n\n- Unified Toolbox\n  - [x] Block Tunes moved left\n  - [x] Toolbox becomes vertical\n  - [x] Ability to display several Toolbox buttons by the single Tool\n  - [x] Block Tunes become vertical\n  - [ ] Block Tunes support nested menus\n  - [ ] Conversion Toolbar uses Unified Toolbox\n  - [ ] Conversion Toolbar added to the Block Tunes\n- Collaborative editing\n  - [ ] Implement Inline Tools JSON format\n  - [ ] Operations Observer, Executor, Manager, Transformer\n  - [ ] Implement Undo/Redo Manager\n  - [ ] Implement Tools API changes\n  - [ ] Implement Server and communication\n  - [ ] Update basic tools to fit the new API\n- Other features\n  - [ ] Blocks dragndrop\n  - [ ] New cross-block selection\n  - [ ] New cross-block caret moving\n- Ecosystem improvements\n  - [x] CodeX Icons \xe2\x80\x94 the way to unify all tools and core icons\n  - [x] New Homepage and Docs\n  - [x] @editorjs/create-tool for Tools bootstrapping\n  - [ ] Editor.js DevTools \xe2\x80\x94 stand for core and tools development\n  - [ ] Editor.js Design System\n  - [ ] Editor.js Preset Env\n  - [ ] Editor.js ToolKit\n  - [ ] New core bundle system\n  - [ ] New documentation and guides\n\n\n  \n    \n    \n    \n  \n\n\n\n\n## Like Editor.js?\n\nYou can support project improvement and development of new features with a donation to our team.\n\n\n\n\n\n\n\n### Why donate\n\nDonations to open-source products have several advantages for your business:\n\n- If your business relies on Editor.js, youll probably want it to be maintained\n- It helps Editor.js to evolve and get the new features\n- We can support contributors and the community around the project. Youll receive well organized docs, guides, etc.\n- We need to pay for our infrastructure and maintain public resources (domain names, homepages, docs, etc). Supporting it guarantees you to access any resources at the time you need them.\n- You can advertise by adding your brand assets and mentions on our public resources\n\n\n### Sponsors\n\nSupport us by becoming a sponsor. Your logo will show up here with a link to your website.\n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\n\n### Backers\n Thank you to all our backers\n\n\n\n\n\n### Contributors\n\nThis project exists thanks to all the people who contribute. \n\n\n\n### Need something special?\n\nHire CodeX experts to resolve technical challenges and match your product requirements. \n\n- Resolve a problem that has high value for you\n- Implement a new feature required by your business\n- Help with integration or tool development\n- Provide any consultation\n\nContact us via team@codex.so and share your details\n\n## Community\n\n- \n- \n- \n- \n- \n\n# About CodeX\n\n\n\nCodeX is a team of digital specialists around the world interested in building high-quality open source products on a global market. We are  for young people who want to constantly improve their skills and grow professionally with experiments in cutting-edge technologies.\n\n| \xf0\x9f\x8c\x90 | Join  \xf0\x9f\x91\x8b  | Twitter | Instagram |\n| -- | -- | -- | -- |\n|  |  | |  |\n'"
A command-line tool that reorganizes your Xcode project folder to match your Xcode groups,"b'\n\n\n \n\nA command-line tool that reorganizes your Xcode project folder to match your Xcode groups.\n\n\n\n##### Xcode\n\n\n\n##### Finder\n\n\n\n## Installation\n\n    $ gem install synx\n\n## Usage\n\n### Basic\n:warning: WARNING: Make sure that your project is backed up through source control before doing anything :warning:\n\nExecute the command on your project to have it reorganize the files on the file system:\n\n     $ synx path/to/my/project.xcodeproj\n     \nIt may have confused CocoaPods. If you use them, execute this command:\n\n    $ pod install\n    \nYoure good to go!\n\n### Advanced\n\nSynx supports the following options:\n\n\n\nFor example, OCMock could have been organized using this command:\n\n    $ synx -p -e ""/OCMock/Core Mocks"" -e /OCMockTests Source/OCMock.xcodeproj/\n\nif they had wanted not to sync the  and  groups, and also remove () any image/source files found by synx that werent referenced by any groups in Xcode.\n\n## Contributing\n\nWed love to see your ideas for improving this library! The best way to contribute is by submitting a pull request. Well do our best to respond to your patch as soon as possible. You can also submit a  if you find bugs or have questions. :octocat:\n\nPlease make sure to follow our general coding style and add test coverage for new features!\n\n\n## Contributors\n\n* , awesome logo!\n*  and , feedback.\n'"
Content aware image cropping,"b""# smartcrop.js\n\n\n\nSmartcrop.js implements an algorithm to find good crops for images.\nIt can be used in the browser, in node or via a CLI.\n\n\nImage:  by N. Feans\n\n> Note\n> I'm currently working on a more advanced version of smartcrop.js based on machine learning. As part of that I'm looking for a large dataset of manually cropped images. If you know of such a dataset, please .\n\n## Demos\n\n- , contains over 100 images, heavy.\n- , allows you to test smartcrop with your own images and different face detection libraries.\n- , automatically creates Ken Burns transitions for a slide show.\n\n## Simple Example\n\n\n\nOutput:\n\n\n\n## Download/ Installation\n\n\nor just download  from the git repository.\n\nSmarcrop requires support for ,\nuse a  for unsupported browsers or set  to your favorite promise implementation\n(I recommend ).\n\n\n## Consider avoiding crops using dont-crop\n\nIf you are interested in using smartcrop.js to crop your images you should also consider to avoid cropping them by using .\nDont-crop gives you matching gradients and colors to pad and complement your images.\n\n\n\n## Command Line Interface\n\nThe  offers command line interface to smartcrop.js.\n\n## Node\n\nYou can use smartcrop from nodejs via either  (which is using image magick via gm) or  (which is using libvips via sharp).\nThe  can be used as an example of using smartcrop from node.\n\n## Stability\n\nWhile smartcrop.js is a small personal project it is currently being used on high traffic production sites.\nIt has a basic set of automated tests and a test coverage of close to 100%.\nThe tests run in all modern browsers thanks to .\nIf in any doubt the code is short enough to perform a quick review yourself.\n\n## Algorithm Overview\n\nSmartcrop.js works using fairly dumb image processing. In short:\n\n1. Find edges using laplace\n1. Find regions with a color like skin\n1. Find regions high in saturation\n1. Boost regions as specified by options (for example detected faces)\n1. Generate a set of candidate crops using a sliding window\n1. Rank them using an importance function to focus the detail in the center\n   and avoid it in the edges.\n1. Output the candidate crop with the highest rank\n\n## Face detection\n\nThe smartcrop algorithm itself is designed to be simple, relatively fast, small and generic.\n\nIn many cases it does make sense to add face detection to it to ensure faces get the priority they deserve.\n\nThere are multiple javascript libraries which can be easily integrated into smartcrop.js.\n\n-  / \n- \n- \n- \n\nYou can experiment with all of these in the \n\nOn the client side I would recommend using tracking.js because it's small and simple. Opencv.js is compiled from c++ and very heavy (~7.6MB of javascript + 900kb of data).\njquery.facedetection has dependency on jquery and from my limited experience seems to perform worse than the others.\n\nOn the server side node-opencv can be quicker but comes with some  as well.\n\nIt's also worth noting that all of these libraries are based on the now dated  object detection framework.\nIt would be interesting to see how more  techniques could be implemented in browser friendly javascript.\n\n## Supported Module Formats\n\n- CommonJS\n- AMD\n- global export / window\n\n## Supported Browsers\n\nSee .\nA  for\n is recommended if you need to support old browsers.\n\n## API\n\n### smartcrop.crop(image, options)\n\nFind the best crop for image using options.\n\nimage: anything ctx.drawImage() accepts, usually HTMLImageElement, HTMLCanvasElement or HTMLVideoElement.\n\nKeep in mind that  apply to the image source.\nYou may not use cross-domain images without  clearance.\n\noptions: \n\nreturns: A promise for a .\n\n### cropOptions\n\nminScale: minimal scale of the crop rect, set to 1.0 to prevent smaller than necessary crops (lowers the risk of chopping things off).\n\nwidth: width of the crop you want to use.\n\nheight: height of the crop you want to use.\n\nboost: optional array of regions whose 'interestingness' you want to boost (for example faces). See ;\n\nruleOfThirds: optional boolean if set to false it will turn off the rule of thirds composition weight.\n\ndebug  if true, cropResults will contain a debugCanvas and the complete results array.\n\nThere are many more (for now undocumented) options available.\nCheck the  and be advised that they might change in the future.\n\n### cropResult\n\nResult of the promise returned by smartcrop.crop.\n\n\n\n### crop\n\nAn individual crop.\n\n\n\n### boost\n\nDescribes a region to boost. A usage example of this is to take\ninto account faces in the image. See  for an example on how to integrate face detection.\n\n\n\nNote that the impact the boost has is proportional to it's weight and area.\n\n## Tests\n\nYou can run the tests using . Alternatively you can also just run grunt (the default task) and open \n\n## Benchmark\n\nThere are benchmarks for both the browser (test/benchmark.html) and node (node test/benchmark-node.js [requires node-canvas])\nboth powered by .\n\nIf you just want some rough numbers: It takes < 20 ms to find a square crop of a 640x427px picture on an i7.\nIn other words, it's fine to run it on one image, it's suboptimal to run it on an entire gallery on page load.\n\n## Contributors\n\n- \n\n## Ports, Alternatives\n\n-  Middleware for connect.js that supports smartcrop.js by \n-  by \n-  by \n-  by \n-  by \n-  smartcrop wrapped in a ruby gem by \n-  c# .net port by \n-  a library to avoid cropping by padding images with matching colors or gradients\n\n## Version history\n\n### 2.0.5\nFix .\n\n### 2.0.4\nTypescript type definitions.\n\n### 2.0.2\n\nIn short: It's a lot faster when calculating bigger crops.\nThe quality of the crops should be comparable but the results\nare going to be different so this will be a major release.\n\n### 1.1.1\n\nRemoved useless files from npm package.\n\n### 1.1\n\nCreating github releases. Added options.input which is getting passed along to iop.open.\n\n### 1.0\n\nRefactoring/cleanup to make it easier to use with node.js (dropping the node-canvas dependency) and enable support for boosts which can be used to do face detection.\nThis is a 1.0 in the semantic meaning (denoting backwards incompatible API changes).\nIt does not denote a finished product.\n\n## License\n\nCopyright (c) 2018 Jonas Wagner, licensed under the MIT License (enclosed)\n"""
A RESTful API package for the Laravel and Lumen frameworks.,"b""# Move repositories notice\nUnfortunately this package cannot be maintained at this location anymore due to broken CI integrations, and travis-ci likely can't be used much longer either due to their change to paid plans. This project is still being actively maintained, we ask you to please switch to the following repository: https://github.com/api-ecosystem-for-laravel/dingo-api\n\n---\n\n\n\nThe Dingo API package is meant to provide you, the developer, with a set of tools to help you easily and quickly build your own API. While the goal of this package is to remain as flexible as possible it still won't cover all situations and solve all problems.\n\n\n\n\n\n\n\n## Features\n\nThis package provides tools for the following, and more:\n\n- Content Negotiation\n- Multiple Authentication Adapters\n- API Versioning\n- Rate Limiting\n- Response Transformers and Formatters\n- Error and Exception Handling\n- Internal Requests\n- API Blueprint Documentation\n\n## Documentation\n\nPlease refer to our extensive  for more information.\n\n## API Boilerplate\n\nIf you are looking to start a new project from scratch, consider using the , which builds on top of the dingo-api package, and adds a lot of great features.\n\n## Support\n\nFor answers you may not find in the Wiki, avoid posting issues. Feel free to ask for support on the dedicated  room. Make sure to mention specialtactics so he is notified.\n\n## License\n\nThis package is licensed under the .\n"""
An autocompletion daemon for the Go programming language,"b'## An autocompletion daemon for the Go programming language\n\nIMPORTANT: This project is not maintained anymore, consider using https://pkg.go.dev/golang.org/x/tools/gopls, a tool which provides similar functionality and more, created and maintained by Go team.\n\nGocode is a helper tool which is intended to be integrated with your source code editor, like vim, neovim and emacs. It provides several advanced capabilities, which currently includes:\n\n - Context-sensitive autocompletion\n\nIt is called daemon, because it uses client/server architecture for caching purposes. In particular, it makes autocompletions very fast. Typical autocompletion time with warm cache is 30ms, which is barely noticeable.\n\nAlso watch the .\n\n\n\n\n\n### Setup\n\n 1. You should have a correctly installed Go compiler environment and your personal workspace ($GOPATH). If you have no idea what $GOPATH is, take a look . Please make sure that your $GOPATH/bin is available in your $PATH. This is important, because most editors assume that gocode binary is available in one of the directories, specified by your $PATH environment variable. Otherwise manually copy the gocode binary from $GOPATH/bin to a location which is part of your $PATH after getting it in step 2.\n\n    Do these steps only if you understand why you need to do them:\n\n    \n\n    \n\n 2. Then you need to get the appropriate version of the gocode, for 6g/8g/5g compiler you can do this:\n\n     (-u flag for ""update"")\n\n    Windows users should consider doing this instead:\n\n    \n\n    That way on the Windows OS gocode will be built as a GUI application and doing so solves hanging window issues with some of the editors.\n\n 3. Next steps are editor specific. See below.\n\n### Vim setup\n\n#### Vim manual installation\n\nNote: As of go 1.5 there is no $GOROOT/misc/vim script. Suggested installation is via .\n\nIn order to install vim scripts, you need to fulfill the following steps:\n\n 1. Install official Go vim scripts from $GOROOT/misc/vim. If you did that already, proceed to the step 2.\n\n 2. Install gocode vim scripts. Usually its enough to do the following:\n\n    2.1. \n\n    update.sh script does the following:\n\n\t\t#!/bin/sh\n\t\tmkdir -p ""$HOME/.vim/autoload""\n\t\tmkdir -p ""$HOME/.vim/ftplugin/go""\n\t\tcp ""${0%/}/autoload/gocomplete.vim"" ""$HOME/.vim/autoload""\n\t\tcp ""${0%/}/ftplugin/go/gocomplete.vim"" ""$HOME/.vim/ftplugin/go""\n\n    2.2. Alternatively, you can create symlinks using symlink.sh script in order to avoid running update.sh after every gocode update.\n\n    symlink.sh script does the following:\n\n\t\t#!/bin/sh\n\t\tcd ""${0%/*}""\n\t\tROOTDIR=\n\t\tmkdir -p ""$HOME/.vim/autoload""\n\t\tmkdir -p ""$HOME/.vim/ftplugin/go""\n\t\tln -s ""$ROOTDIR/autoload/gocomplete.vim"" ""$HOME/.vim/autoload/""\n\t\tln -s ""$ROOTDIR/ftplugin/go/gocomplete.vim"" ""$HOME/.vim/ftplugin/go/""\n\n 3. Make sure vim has filetype plugin enabled. Simply add that to your .vimrc:\n\n    \n\n 4. Autocompletion should work now. Use  for autocompletion (omnifunc autocompletion).\n\n#### Using Vundle in Vim\n\nAdd the following line to your .vimrc:\n\n\n\nAnd then update your packages by running .\n\n#### Using vim-plug in Vim\n\nAdd the following line to your .vimrc:\n\n\n\nAnd then update your packages by running .\n\n#### Other\n\nAlternatively take a look at the vundle/pathogen friendly repo: https://github.com/Blackrush/vim-gocode.\n\n### Neovim setup\n#### Neovim manual installation\n\n Neovim users should also follow , except that you should goto  in step 2, and remember that, the Neovim configuration file is .\n\n#### Using Vundle in Neovim\n\nAdd the following line to your init.vim:\n\n\n\nAnd then update your packages by running .\n\n#### Using vim-plug in Neovim\n\nAdd the following line to your init.vim:\n\n\n\nAnd then update your packages by running .\n\n### Emacs setup\n\nIn order to install emacs script, you need to fulfill the following steps:\n\n 1. Install \n\n 2. Copy emacs/go-autocomplete.el file from the gocode source distribution to a directory which is in your load-path in emacs.\n\n 3. Add these lines to your .emacs:\n\n \t\t(require go-autocomplete)\n\t\t(require auto-complete-config)\n\t\t(ac-config-default)\n\nAlso, there is an alternative plugin for emacs using company-mode. See  for installation instructions.\n\nIf youre a MacOSX user, you may find that script useful: https://github.com/purcell/exec-path-from-shell. It helps you with setting up the right environment variables as Go and gocode require it. By default it pulls the PATH, but dont forget to add the GOPATH as well, e.g.:\n\n\n\n### Options\n\nYou can change all available options using  command. The config file uses json format and is usually stored somewhere in ~/.config/gocode directory. On windows its stored in the appropriate AppData folder. Its suggested to avoid modifying config file manually, do that using the  command.\n\n lists all options and their values.\n\n shows the value of that option.\n\n sets the new value for that option.\n\n - propose-builtins\n\n   A boolean option. If true, gocode will add built-in types, functions and constants to autocompletion proposals. Default: false.\n\n - lib-path\n\n   A string option. Allows you to add search paths for packages. By default, gocode only searches **$GOPATH/pkg/$GOOS_$GOARCH** and **$GOROOT/pkg/$GOOS_$GOARCH** in terms of previously existed environment variables. Also you can specify multiple paths using : (colon) as a separator (on Windows use semicolon ;). The paths specified by lib-path are prepended to the default ones.\n\n - autobuild\n\n   A boolean option. If true, gocode will try to automatically build out-of-date packages when their source files are modified, in order to obtain the freshest autocomplete results for them. This feature is experimental. Default: false.\n\n - force-debug-output\n\n   A string option. If is not empty, gocode will forcefully redirect the logging into that file. Also forces enabling of the debug mode on the server side. Default: """" (empty).\n\n - package-lookup-mode\n\n   A string option. If go, use standard Go package lookup rules. If gb, use gb-specific lookup rules. See https://github.com/constabulary/gb for details. Default: go.\n\n - close-timeout\n\n   An integer option. If there have been no completion requests after this number of seconds, the gocode process will terminate. Defaults to 1800 (30 minutes).\n\n - unimported-packages\n\n   A boolean option. If set to true, gocode will try to import certain known packages automatically for identifiers which cannot be resolved otherwise. Currently only a limited set of standard library packages are supported. Default: false.\n\n - partials\n\n   A boolean option. If set to false, gocode will not filter autocompletion results based on entered prefix before the cursor. Instead it will return all available autocompletion results viable for a given context. Whether this option is set to true or false, gocode will return a valid prefix length for output formats which support it. Setting this option to a non-default value may result in editor misbehaviour. Default: true.\n\n - ignore-case\n\n   A boolean option. If set to true, gocode will perform case-insensitive matching when doing prefix-based filtering. Default: false.\n\n - class-filtering\n\n   A boolean option. Enables or disables gocodes feature where it performs class-based filtering if partial input matches corresponding class keyword: const, var, type, func, package. Default: true.\n\n### Debugging\n\nIf something went wrong, the first thing you may want to do is manually start the gocode daemon with a debug mode enabled and in a separate terminal window. It will show you all the stack traces, panics if any and additional info about autocompletion requests. Shutdown the daemon if it was already started and run a new one explicitly with a debug mode enabled:\n\n\n\n\n\nPlease, report bugs, feature suggestions and other rants to the  of this project.\n\n### Developing\n\nThere is .\n\nIf you have troubles, please, contact me and I will try to do my best answering your questions. You can contact me via email. Or for short question find me on IRC: #go-nuts @ freenode.\n\n### Misc\n\n - Its a good idea to use the latest git version always. Im trying to keep it in a working state.\n - Use  (not ) for building a local source tree. The objects in  are needed for Gocode to work.\n'"
"Community list of awesome projects, apps, tools, and services related to IPFS.","b'# Awesome IPFS \n\nThis is a community list of awesome projects, apps, tools, and services related to IPFS.\n\nTo submit your project, read the , and \n\n## Table of Contents\n\n- \n- \n- \n- \n- \n- \n- \n- \n- \n\n## Implementations\nIPFS is an open-source project that encourages the development of multiple implementations of the protocol, each of which seeks to optimize for various use cases.\n\nCheck out the list of  in the IPFS docs.\n\n## Apps\n\n-  - A minimal web browser for the distributed web. Supports downloading/uploading data from IPFS using the browsers  API\n-  - Anytype is a no-code, modular web builder designed to give ownership back to creators. Its built on our private, local-first, p2p-synced and open Anysync protocol.\n-  - A High-Fidelity Web Archiving Extension for Chrome and Chromium based browsers with support for IPFS.\n-  - Autonomica is a Keybase-like Dapp for creating an identity and proving this identity via published social media and web proofs.\n-  - File synchronization with git like interface and FUSE filesystem.\n-  - Play music from your IPFS node, or any other cloud/distributed storage service you use.\n-  - Mobile app for accessing and uploading content on the IPFS network.\n-  - Hardbin is an encrypted pastebin, with the decryption key passed in the URL fragment\n-  - Web Archive (WARC) indexing and replay using IPFS.\n-  - Wiki built on top of IPFS\n-  - A simple way to publish uncensorable essays on IPFS.\n-  - IPFS Desktop gives you all the power of IPFS in a convenient desktop app: a complete IPFS node, plus handy OS menubar/taskbar shortcuts and an all-in-one file manager, peer map, and content explorer.\n-  - Terminal-based, encrypted chatrooms. Allows private messaging & secure in-chat file/directory sharing. Server/broker-less (no signaling/rendezvous server needed). Works over LAN/internet(w/ NAT-traversal).\n-  - A completely decentralized first person shooter. Built with Unity, Fleek, Unstoppable Domans and Pinata.\n-  - A censorship resistant deadmans switch\n-  - Mintter\xc2\xa0Hypermedia\xc2\xa0is an\xc2\xa0open system, built on\xc2\xa0IPFS, that allows communities to collaborate on content that is structured and deeply linked. All content in the system is cryptographically signed, versioned, and made permanent with IPFS.\n-  - Ultra simple chatrooms on the web.\n-  - Peer to Peer Web Site hosting at your fingertips! Send full featured HTML (incl. CSS, JS) sites from your browser and attach files eg. videos, images, etc.\n-  - End-to-end encrypted, peer-to-peer file storage and sharing.\n-  - Push to Talk lets you edit audio essays and publish them with IPFS.\n-  - Privacy focused, end-to-end encrypted chat app that runs a private IPFS network over Tor connections. Desktop and mobile iOS and Android apps available.\n-  - Privacy-first, end-to-end encrypted email, file storage, and collaboration platform using IPFS storage.\n\n## Browsers\nA list of web browsers with IPFS integrations\n-  - A minimal web browser for the distributed web. Supports downloading/uploading data from IPFS using the browsers  API\n-  - A privacy-focused browser with many future forward features.\n-  - A multi-platform Qt5-based browser for the distributed web.\n-  - Opera browser added support for  in 2021\n\n## Tools\n\n-  - [EXPERIMENTAL] A lightweight IPFS Gateway daemon backed by a remote data store.\n-  - Set up a decentralized web3 app by running one command.\n-  - A browser extension that uploads the content to Web3.Storage and generates QR codes for CIDs.\n-  - A decentralized encrypted backup agent for popular databases supported by IPFS and Filecoin.\n-  - Adds support for deploying Gatsby websites to IPFS by ensuring that assets are relative.\n-  - A script to rehost your git repos in ipfs.\n-  - push/pull repositories from/to IPFS.\n-  - set of programs written in Python 3 which allow Git user to clone, push, fetch, self-host or release Git repositories over IPFS decentralized data storage system.\n-  - This is a Golang port of OrbitDB that intends to be fully compatible with the original JavaScript version. OrbitDB is a serverless, distributed, peer-to-peer database.\n-  - IPFS and libp2p on Mobile, with Gomobile.\n-  - This is a simple webtool to add URLs to an IPFS node.\n-  - IPFS-backed Docker Registry.\n-  - A GitHub Action to install and initialize go-ipfs to provision a cross-platform test environment on GitHubs CI platform.\n-  - GitHub Action for delivery of static websites.\n-  - Encrypt a file or directory with AES256 then add to IPFS.\n-  - Browser extension that simplifies access to IPFS resources.\n-  - Zero-config CLI to deploy static websites: cd my-static-website && npx @agentofuser/ipfs-deploy\n-  - Easy to use encrypted file uploader.\n-  - Mount IPFS as a mapped drive on Windows.\n-  - Paste stdin and clipboard to IPFS.\n-  - A toolkit help upload files to IPFS pinning services.\n-  - Continuous Delivery tool for delivery of static websites from Git providers to IPFS.\n-  - Capture screenshots, publish them to IPFS, and copy the link to the clipboard.\n-  - Cloud-init your own IPFS gateway on a cloud provider and easily pin content through a simple web interface.\n-  - Encrypt and decrypt IPFS files with a secret passphrase.\n-  - :satellite: wget for IPFS: retrieve files over IPFS and save them locally.\n-  - Explore the Merkle Forest from the comfort of your browser.\n-  - A command-line tool to pin stuff via ipns.\n-  - Browser userscript for redirecting IPFS/IPNS addresses to your local gateway. This should work on any browser that hasnt had an extension written for it yet and has support for userscripts.\n-  - IETF RFC downloader which stores RFCs on IPFS and indexes them with RTradeLtd/Lens.\n-  - Mahuta is a plug and play service for your micro-service architecture allowing to collect, store and index data on IPFS and offering search functionalities (full text, query).\n-  - Multiverse is a decentralized version control system that enables peer-to-peer software development.\n-  - OrbitDB is a serverless, distributed, peer-to-peer database that uses IPFS as its data storage and IPFS Pubsub to automatically sync databases with peers.\n-  - Web Extension which creates a WebArchiveZip of a tweet and adds to IPFS network.\n-  - Checks which public gateways are online or not.\n-  - A toolkit makes it easier to archive webpages to IPFS.\n-  - A twitter bot that adds, pins, unpins your tweets to public IPFS network using IPFS Cluster.\n-  - Using Solid to store IPFS Hash privately or publicly.\n-  - Encrypt files before uploading them using a keypair or a passphrase.\n-  - Publish your Vue apps easily to IPFS.\n-  - A command-line tool and Go package interface for wayback webpage to IPFS.\n-  - Download videos from YouTube (and similar video platforms) and add them to IPFS.\n\n## Services & Platforms\n\n-  - Ceramic combines IPFS content addressing with advanced cryptography and blockchain timestamps to guarantee security and verifiability of data.\n-  - Hosting platform with automated deployments from GitHub to IPFS\n-  - Encrypted file sharing based on IPFS. Share any files with or without a wallet\n-  - Open Web development platform for building, hosting, and storing sites and apps on IPFS, Filecoin, and the Internet Computer.\n-  - Fission builds open source protocols and managed solutions that empower developers to construct scalable and secure software applications.\n-  - Your private, but social, space online. Store and edit documents and media. Share files or folders with friends.\n-  - A trustless universal package repository enabling you to digitally sign and distribute software in just a few steps.\n\n## Pinning services\n-  - 4EVERLAND is a pinning service that provides IPFS infrastructure and tooling making it easier and faster to host frontends, store data/NFT/file and fetch data with IPFS.\n-  - Pinning data to IPFS can be hard. Filebase removes that complexity.\n-  - Free decentralized storage and bandwidth for NFTs on IPFS & Filecoin.\n-  - Build and manage your dapp through Pinata\xe2\x80\x99s REST API and IPFS toolkit.\n-  - Scalable and distributed storage infrastructure for your application.\n-  - Pinning service & Web3 Platform for building Web3 apps.\n-  - A multi-region, multi-az redundant IPFS pinning service.\n-  - Spheron offers IPFS pinning service and dedicated gateways.\n-  - Easily upload and pin files to IPFS.\n-  - Simple file storage with IPFS & Filecoin.\n\n## Stale Projects\nWe maintain a list of no longer maintained projects for reference. If you see something on this list thats no longer maintained, please submit a PR moving the entry into  and optionally add the reason why its marked as stale with an indented comment.\n\n\n\n## Contribute\n\nContributions are welcome!\n\nSee the .\n\n## License\n\n\n'"
Deep Hough Voting for 3D Object Detection in Point Clouds,"b'# Deep Hough Voting for 3D Object Detection in Point Clouds\nCreated by Charles R. Qi, Or Litany, Kaiming He and Leonidas Guibas from Facebook AI Research and Stanford University.\n\n\n\n## Introduction\nThis repository is code release for our ICCV 2019 paper (arXiv report ).\n\nCurrent 3D object detection methods are heavily influenced by 2D detectors. In order to leverage architectures in 2D detectors, they often convert 3D point clouds to regular grids (i.e., to voxel grids or to bird\xe2\x80\x99s eye view images), or rely on detection in 2D images to propose 3D boxes. Few works have attempted to directly detect objects in point clouds. In this work, we return to first principles to construct a 3D detection pipeline for point cloud data and as generic as possible. However, due to the sparse nature of the data \xe2\x80\x93 samples from 2D manifolds in 3D space \xe2\x80\x93 we face a major challenge when directly predicting bounding box parameters from scene points: a 3D object centroid can be far from any surface point thus hard to regress accurately in one step. To address the challenge, we propose VoteNet, an end-to-end 3D object detection network based on a synergy of deep point set networks and Hough voting. Our model achieves state-of-the-art 3D detection on two large datasets of real 3D scans, ScanNet and SUN RGB-D with a simple design, compact model size and high efficiency. Remarkably, VoteNet outperforms previous methods by using purely geometric information without relying on color images.\n\nIn this repository, we provide VoteNet model implementation (with Pytorch) as well as data preparation, training and evaluation scripts on SUN RGB-D and ScanNet.\n\n## Citation\n\nIf you find our work useful in your research, please consider citing:\n\n    @inproceedings{qi2019deep,\n        author = {Qi, Charles R and Litany, Or and He, Kaiming and Guibas, Leonidas J},\n        title = {Deep Hough Voting for 3D Object Detection in Point Clouds},\n        booktitle = {Proceedings of the IEEE International Conference on Computer Vision},\n        year = {2019}\n    }\n\n## Installation\n\nInstall  and  (for TensorBoard). It is required that you have access to GPUs. Matlab is required to prepare data for SUN RGB-D. The code is tested with Ubuntu 18.04, Pytorch v1.1, TensorFlow v1.14, CUDA 10.0 and cuDNN v7.4. Note: After a code update on 2/6/2020, the code is now also compatible with Pytorch v1.2+\n\nCompile the CUDA layers for , which we used in the backbone network:\n\n    cd pointnet2\n    python setup.py install\n\nTo see if the compilation is successful, try to run  to see if a forward pass works.\n\nInstall the following Python dependencies (with ):\n\n    matplotlib\n    opencv-python\n    plyfile\n    trimesh>=2.35.39,<2.35.40\n    networkx>=2.2,<2.3\n\n## Run demo\n\nYou can download pre-trained models and sample point clouds .\nUnzip the file under the project root path () and then run:\n\n    python demo.py\n\nThe demo uses a pre-trained model (on SUN RGB-D) to detect objects in a point cloud from an indoor room of a table and a few chairs (from SUN RGB-D val set). You can use 3D visualization software such as the  to open the dumped file under  to see the 3D detection output. Specifically, open  and  to see the input point cloud and predicted 3D bounding boxes.\n\nYou can also run the following command to use another pretrained model on a ScanNet:\n\n    python demo.py --dataset scannet --num_point 40000\n\nDetection results will be dumped to .\n\n## Training and evaluating\n\n### Data preparation\n\nFor SUN RGB-D, follow the  under the  folder.\n\nFor ScanNet, follow the  under the  folder.\n\n### Train and test on SUN RGB-D\n\nTo train a new VoteNet model on SUN RGB-D data (depth images):\n\n    CUDA_VISIBLE_DEVICES=0 python train.py --dataset sunrgbd --log_dir log_sunrgbd\n\nYou can use  to specify which GPU(s) to use. Without specifying CUDA devices, the training will use all the available GPUs and train with data parallel (Note that due to I/O load, training speedup is not linear to the nubmer of GPUs used). Run  to see more training options (e.g. you can also set  to train with the baseline BoxNet model).\nWhile training you can check the  file on its progress, or use the TensorBoard to see loss curves.\n\nTo test the trained model with its checkpoint:\n\n    python eval.py --dataset sunrgbd --checkpoint_path log_sunrgbd/checkpoint.tar --dump_dir eval_sunrgbd --cluster_sampling seed_fps --use_3d_nms --use_cls_nms --per_class_proposal\n\nExample results will be dumped in the  folder (or any other folder you specify). You can run  to see the full options for evaluation. After the evaluation, you can use MeshLab to visualize the predicted votes and 3D bounding boxes (select wireframe mode to view the boxes).\nFinal evaluation results will be printed on screen and also written in the  file under the dump directory. In default we evaluate with both AP@0.25 and AP@0.5 with 3D IoU on oriented boxes. A properly trained VoteNet should have around 57 mAP@0.25 and 32 mAP@0.5.\n\n### Train and test on ScanNet\n\nTo train a VoteNet model on Scannet data (fused scan):\n\n    CUDA_VISIBLE_DEVICES=0 python train.py --dataset scannet --log_dir log_scannet --num_point 40000\n\nTo test the trained model with its checkpoint:\n\n    python eval.py --dataset scannet --checkpoint_path log_scannet/checkpoint.tar --dump_dir eval_scannet --num_point 40000 --cluster_sampling seed_fps --use_3d_nms --use_cls_nms --per_class_proposal\n\nExample results will be dumped in the  folder (or any other folder you specify). In default we evaluate with both AP@0.25 and AP@0.5 with 3D IoU on axis aligned boxes. A properly trained VoteNet should have around 58 mAP@0.25 and 35 mAP@0.5.\n\n### Train on your own data\n\n[For Pro Users] If you have your own dataset with point clouds and annotated 3D bounding boxes, you can create a new dataset class and train VoteNet on your own data. To ease the proces, some tips are provided in this .\n\n## Acknowledgements\nWe want to thank Erik Wijmans for his PointNet++ implementation in Pytorch ().\n\n## License\nvotenet is relased under the MIT License. See the  for more details.\n\n## Change log\n10/20/2019: Fixed a bug of the 3D interpolation customized ops (corrected gradient computation). Re-training the model after the fix slightly improves mAP (less than 1 point).\n'"
Composable Docker Management,"b'# Shipyard Project\nAfter a long time I have decided to retire this project.  It formed the foundation for\nwhat became Docker Universal Control Plane and I no longer have time to manage this.\nI asked for new maintainers but there\nseemed to be no interest.\n\nWARNING: as the project retired I no longer maintained the domain.  Someone else has setup a duplicate site that is not official and is carrying an invalid SSL certificate.  PLEASE DO NOT GO TO THE DOMAIN shipyard-project.com.  I cannot endorse it nor vouch for the security or content of the site.\n\nI want to thank all of the \nfor all of your help.  Thank you.\n\nI will keep this repository open for a while to keep the source accessible for anyone that\nwants it.\n\nIf you are looking for alternatives, here are a few open source Docker management\napplications available:\n\n- \n- \n- \n\nThank you.\n'"
"Helping you select an MV* framework - Todo apps for React.js, Ember.js, Angular, and many more","b'# \n\n> Helping you select an MV* framework\n\n### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\n\n\n\nDevelopers these days are spoiled with choice when it comes to selecting an MV* framework for structuring and organizing JavaScript web apps.\n\nBackbone, Ember, AngularJS... the list of new and stable solutions goes on and on, but just how do you decide on which to use in a sea of so many options?\n\nTo help solve this problem, we created TodoMVC - a project which offers the same Todo application implemented using MV* concepts in most of the popular JavaScript MV* frameworks of today.\n\n\n## Team\n\nTodoMVC would not be possible without a strong team of  helping push the project forward each day. Additionally, we have a core project team composed of:\n\n####  - Founder/Lead\n\n\n  Addy is a Software Engineer at Google who originally created TodoMVC. He oversees the project direction, maintenance and organizes the planning and development efforts of the team.\n\n####  - Lead Developer\n\n\nSindre is a Web Developer who leads core development, quality control and application design for the project. His engineering contributions have helped us ensure consistency and best practices are enforced wherever possible. Sindre also leads up development of the TodoMVC application spec.\n\n####  - Developer\n\n\nPascal is a Software Engineer at Twitter with a deep passion for consistency. He watches pull requests and helps developers getting their contributions integrated with TodoMVC.\n\n####  - Developer\n\n\nStephen is a Front-end Engineer at Quicken Loans that cares about improving the maintainability and developer experience of open-source projects. His recent contributions include helping us move all apps over to using Bower and implementing the new information bar.\n\n####  - Developer\n\n\nColin is a software consultant at Scott Logic who is passionate about all software - from JavaScript to Java, and C# to Objective-C. His recent contribution to the project has been a fully automated test suite.\n\n####  - Developer\n\n\nSam is a Software Engineer at Google who is driven by an endless desire to create, solve problems, and improve developers lives.\n\n####  - Developer\n\n\nArthur is an open-source fanboy from Belgium. He is passionate about developer tooling and all things JavaScript.\n\n####  - Developer\n\n\nFady is a front-end developer who loves all things JavaScript and enjoys solving real world problems using the web platform and helping other developers do the same. He currently leads maintenance of the project and ensures that the project is friendly for new contributors and upcoming developers.\n\n####  - Logo designer\n\n\nGianni is a programmer and designer currently working as the Chief Rigger at MetaLab.\n\n## Disclaimer\n\n\n\nTodoMVC has been called many things including the Speed-dating and Rosetta Stone of MV* frameworks. Whilst we hope that this project can offer assistance in deciding what frameworks are worth spending more time looking at, remember that the Todo application offers a limited view of a frameworks potential capability.\n\nIt is meant to be used as a gateway to reviewing how a basic application using a framework may be structured, and we heavily recommend investing time researching a solution in more depth before opting to use it.\n\nAlso, please keep in mind that TodoMVC is not the perfect way to compare the size of different frameworks. We intentionally use the unminified versions to make reading the source code easier.\n\n\n## Getting Involved\n\nWhilst we enjoy implementing and improving existing Todo apps, were always interested in speaking to framework authors (and users) wishing to share Todo app implementations in their framework/solution of choice.\n\nCheck out our  for more info.\n\n\n## License\n\nEverything in this repo is MIT License unless otherwise specified.\n\n \xc2\xa9 Addy Osmani, Sindre Sorhus, Pascal Hartig, Stephen Sawchuk.\n'"
Synopse mORMot 1 ORM/SOA/MVC framework - Please upgrade to mORMot 2 !,"b'\r\n  Synopse mORMot 1 Framework\r\n\r\nAn Open Source Client-Server ORM/SOA framework\r\n (c) 2008-2023 Synopse Informatique\r\n  https://synopse.info\r\n  http://mormot.net\r\n\r\n=========  \r\n WARNING\r\n=========\r\n This repository is now in ""frozen/maintenance"" mode. \r\n Only SQLite3 static binaries and important bug fixes will be included in the future.\r\n-----------------------------------------------------------------------------------------------\r\n Please consider using https://github.com/synopse/mORMot2 for any new or maintainable project.\r\n-----------------------------------------------------------------------------------------------\r\n\r\n\r\nContributors\r\n  Alan Chate\r\n  Alexander (sha)\r\n  Alexander (volax)\r\n  AlexPirate\r\n  Alfred Glaenzer (alf)\r\n  Andre Heider (dhewg)\r\n  Antoine Simard (AntoineGS)\r\n  Arnaud Bouchez\r\n  ASiwon\r\n  Aweste\r\n  Bas Schouten\r\n  BigStar\r\n  BugsDigger\r\n  Cheemeng\r\n  CoMPi\r\n  Damien (ddemars)\r\n  Darian Miller\r\n  Daniel Kuettner\r\n  David Mead (MDW)\r\n  Delphinium (louisyeow)\r\n  DigDiver\r\n  Dominikcz\r\n  EgorovAlex\r\n  Emanuele (lele9)\r\n  Eric Grange\r\n  Esmond\r\n  Esteban Martin (EMartin)\r\n  Eugene Ilyin\r\n  Eva Freimann (EVaF)\r\n  FeelAirSlow\r\n  F-Vicente\r\n  Goran Despalatovic (gigo)\r\n  Jean-Baptiste Roussia (jbroussia)\r\n  Joe (jokusoft)\r\n  Johan Bontes\r\n  Jordi Tudela\r\n  Kevin Chen\r\n  Lagodny\r\n  Leon Oosthuizen\r\n  Macc2010\r\n  Maciej Izak (hnb)\r\n  Marcos Douglas B. Santos (mdbs99)\r\n  Mario Moretti\r\n  Marius Maximus (mariuszekpl)\r\n  Martin Eckes\r\n  Martin Suer\r\n  Mapes\r\n  Matkov\r\n  Maxim Masiutin\r\n  Mazinsw\r\n  MChaos\r\n  Miab3\r\n  Michael (EgonHugeist)\r\n  Michalis Kamburelis \r\n  MilesYou\r\n  Mingda\r\n  Mr Yang (ysair)\r\n  Nicolas Marchand (MC)\r\n  Nortg\r\n  Nzsolt\r\n  Oleg Tretyakov\r\n  Ondrej (reddwarf)\r\n  Pavel Mashlyakovskii (mpv)\r\n  Pierre le Riche\r\n  RalfS\r\n  Richard6688\r\n  Rik (rvk)\r\n  Sabbiolina\r\n  Sanyin\r\n  Sinisa (sinisav)\r\n  Sllimr7139\r\n  SSoftPro\r\n  Stefan (itSDS)\r\n  Svetozar Belic (transmogrifix)\r\n  Transmogrifix\r\n  Uian2000\r\n  Vaclav\r\n  Vadim Orel\r\n  Willo vd Merwe\r\n  Win2014\r\n  Wloochacz\r\n  Wolfgang Ehrhardt\r\n  Yoanq\r\n  Ysair\r\n  Zed\r\n\r\n[See below if you upgrade from 1.17 revision]\r\n\r\n  \r\nSynopse mORMot is an Open Source Client-Server ORM SOA MVC framework\r\nfor Delphi 6 up to the latest Delphi and FPC revisions, targeting Windows/Linux\r\nfor servers, and any platform for clients (including mobile or AJAX).\r\n\r\nThe main features of mORMot are therefore:\r\n\r\n - ORM/ODM: objects persistence on almost any database (SQL or NoSQL);\r\n - SOA: organize your business logic into REST services;\r\n - Clients: consume your data or services from any platform, via ORM/SOA APIs;\r\n - Web MVC: publish your ORM/SOA process as responsive Web Applications.\r\n\r\nWith local or remote access, via an auto-configuring Client-Server REST design.\r\n\r\nDue to its modular design, switch from a Client-Server architecture over\r\nHTTP, named pipes or GDI messages into a stand-alone application is just\r\na matter of mORMot classes initialization.\r\nFor instance, the very same executable can even be running stand-alone,\r\nas a server, as a service, or a client, depending on some run-time parameters!\r\n\r\nEmphasizing simplicity, speed and versatility, mORMot is a incredibly well\r\ndocumented Open Source project easy enough to add basic ORM or Client-Server\r\nfeatures to simple applications for hobbyists, or let experienced users\r\ndevelop scaling and strong service-based projects for their customers, with\r\nthe advantages of native code and easy-to-deploy solutions, reducing\r\ndeployment cost and increasing ROI.\r\n\r\nIt provides an Open Source self-sufficient set of units (even Delphi starter\r\nedition is enough) for creating any application, from a stand-alone solution\r\nup to the most complex Domain-Driven Design (DDD):\r\n\r\n - Presentation layer featuring MVC UI generation with i18n and reporting\r\n (with pdf export) for rich Delphi clients, MVC web clients (with logic-less\r\n Mustache templates) or rich AJAX clients (via native JSON/REST access);\r\n\r\n - Application layer implementing Service Oriented Architecture via\r\n interface-based services (like WCF) and Client-Server ORM (including \r\n method-based services) - following a RESTful model using JSON over several\r\n communication protocols (e.g. HTTP/1.1);\r\n\r\n - Domain Model layer handling all the needed business logic in plain Delphi\r\n objects, including high-level managed types like dynamic arrays or records\r\n for Value Objects, dedicated classes for Entities or Aggregates, and variant\r\n storage with late-binding for dynamic documents;\r\n\r\n - Data persistence infrastructure layer with ORM operations on direct\r\n Oracle, MS SQL, OleDB, ODBC, ZEOS/ZDBC access or any TDataSet provider (e.g.\r\n FireDAC/AnyDAC, UniDAC, NexusDB, BDE...), with a powerful SQLite3 kernel,\r\n and optional SQL access if needed, with amazing performance and advanced\r\n features like Array DML, auto-generating SQL for SQLite3, Oracle, \r\n Jet/MSAccess, MS SQL, Firebird, DB2, PostgreSQL, MySQL and NexusDB - and\r\n alternative high-speed MongoDB NoSQL database access for ODM persistence;\r\n\r\n - Cross-Cutting infrastructure layers for handling data filtering and\r\n validation, security (e.g. Windows authentication or any custom model),\r\n caching, logging and testing (framework uses test-driven approach and\r\n features interface stubbing and mocking).\r\n\r\nWith mORMot, ORM/ODM is not used only for data persistence of objects (like\r\nin other implementations), but as part of a global n-Tier, Service Oriented\r\nArchitecture (SOA), ready to implement Domain-Driven solutions. This\r\nframework is not an ORM on which a transmission layer has been added, like\r\nalmost everything existing in Delphi, C# or Java: this is a full Client-Server \r\nORM/SOA from the ground up.\r\nThis really makes the difference.\r\n\r\nThe business logic of your applications will be easily exposed as Services,\r\nand will be accessible from light clients (written in Delphi or any other\r\nmean, including AJAX).\r\nThe SpiderMonkey JavaScript engine has been integrated on the server side\r\nand can be used to define business rules or any process (including MVC web\r\nrendering) - just like node.js, but with a multi-threaded core, and the\r\nfull power of our optimized Delphi libraries at hand.\r\n\r\nThe framework Core is non-visual: you will get everything you need in a\r\nconsistent set of classes to be used from code. In order to let you focus\r\non your business, using mORMots KISS/DRY/SOC/YAGNI/TDD and Convention Over\r\nConfiguration patterns. But you have also some UI units available (including\r\nscreen auto-generation, reporting and ribbon GUI), and you can use it from\r\nany RAD, web, or AJAX clients (via JavaScript or Smart Mobile Studio).\r\n\r\nNo dependency is needed on the client side (no DB driver, or third-party\r\nruntime): it is able to connect via standard HTTP, even through a corporate\r\nproxy or a VPN. Rich Delphi clients can be deployed just by copying and running\r\na stand-alone small executable, with no installation process. Stream can be\r\nencrypted via HTTS or with proven SHA/AES-256. Endpoints are configured\r\nautomatically for each published interface on both server and client sides,\r\nand creating a load-balancing proxy is a matter of one method call.\r\nSpeed and scalability has been implemented from the ground up: a genuine\r\noptimized multi-threaded core let a single server handle more than 50,000\r\nconcurrent clients, faster than DataSnap, WCF or node.js, and our rich SOA\r\ndesign is able to implement both vertical and horizontal scalable hosting,\r\nusing recognized enterprise-level SQL or NoSQL databases for storage.\r\n\r\nEven if mORMot will be more easily used in a project designed from scratch,\r\nit fits very well the purpose of evolving any existing Delphi project, or\r\ncreating the server side part of an AJAX application.\r\n\r\nLicensed under a disjunctive tri-license giving you the choice of one of\r\nthe three following sets of free software/open source licensing terms:\r\n - Mozilla Public License, version 1.1 or later;\r\n - GNU General Public License, version 2.0 or later;\r\n - GNU Lesser General Public License, version 2.1 or later.\r\nThis allows the use of our code in as wide a variety of software projects\r\nas possible, while still maintaining copy-left on code we wrote.\r\n\r\nMain project page:\r\nhttp://mORMot.net\r\n\r\nDocumentation:\r\nhttps://synopse.info/files/html/Synopse%20mORMot%20Framework%20SAD%201.18.html\r\n\r\nInstallation:\r\nhttps://synopse.info/files/html/Synopse%20mORMot%20Framework%20SAD%201.18.html#TITL_113\r\n\r\nFAQ:\r\nhttps://synopse.info/files/html/Synopse%20mORMot%20Framework%20SAD%201.18.html#TITL_123\r\n\r\nHow to get the source:\r\nhttps://synopse.info/fossil/wiki?name=Get+the+source\r\n\r\nA forum is dedicated to support:\r\nhttps://synopse.info\r\n\r\nA blog is available:\r\nhttp://blog.synopse.info\r\n\r\nIssues and feature requests can be posted (take a look at the forums\r\nand latest unstable version first!):\r\nhttps://synopse.info/fossil/reportlist\r\n\r\nYou can also monitor/fork our projects on GitHub:\r\nhttps://github.com/synopse/mORMot\r\n\r\nYou may also install it as a Delphinus package: Delphinus-Support\r\n\r\nDont forget to download the documentation (available online or as pdf files,\r\ncreated by our SynProject tool).\r\nIn particular, you should take a look at all general introduction chapters\r\nof the SAD document. It will cover all key-concepts and code modelling\r\nused by the framework.\r\nA developer guide is included in this SAD document, in its 2nd part. Youll\r\nget good practice guidance, presentation of the ORM/SOA approach and other\r\nunderlying concepts.\r\n\r\nFeel free to contribute by posting enhancements and patches to this\r\nquickly evolving project.\r\n  \r\nEnjoy!\r\n\r\n\r\nSome units (e.g. SynPdf, SynGdiPlus, SynBigTable, SynCommons, SynCrypto, \r\nSynDB*, SynSQLite3, SynMongoDB, SynMustache, SynSM, mORMotReport) are used \r\nby mORMot, but do not require the whole framework to be linked.\r\nThat is, you can use e.g. only  PDF generation, SynDB fast database\r\naccess, a static-linked SQLite3 engine, direct MongoDB access, Mustache\r\ntemplates, SpiderMonkey JavaSCript engine, code-generated reports, or \r\nthe TDocVariant, TDynArray, TSynLog classes of SynCommons, without using\r\nthe main mORMot units and features (ORM, Client-Server, services, UI).\r\n\r\nSome of those units can even be compiled with Delphi 5 (e.g. SynPdf, SynDB).\r\n\r\n\r\nQuick Steps when upgrading from a previous 1.17 revision:\r\n\r\n1) Note that some units where renamed, and some breaking changes introduced\r\n   by some enhanced features, therefore a direct update is not possible\r\n\r\n2) Erase or rename your whole previous #Lib directory\r\n\r\n3) Download latest 1.18 revision files as stated just above\r\n  \r\n4) Change your references to mORMot units:\r\n - Add in your uses clause SynLog.pas and/or SynTests.pas if needed;\r\n - Rename in your uses clause any SQLite3Commons reference into mORmot;\r\n - Rename in your uses clause any SQLite3 reference into mORMotSQLite3;\r\n - Rename in your uses clause any other SQlite3* reference into mORMot*;\r\n - Add in one uses clause a link to SynSQLite3Static (for Win32).\r\n \r\n5) Consult the units headers about 1.18 for breaking changes, mainly:\r\n - TSQLRecord.ID: TID primary key, TIDDynArray, and TRecordReference are now Int64;\r\n - Renamed Iso8601 low-level structure as TTimeLogBits;\r\n - TJSONSerializerCustomReader/Writer callbacks changed;\r\n - TSQLRestServerCallBackParams replaced by TSQLRestServerURIContext class;\r\n - TSQLRestServerStatic* classes renamed as TSQLRestStorage*;\r\n - rmJSON* enums replaced by TSQLRestRoutingREST/JSON_RPC classes;\r\n - Changed \xc2\xa4 into ~ character for mORMoti18n language files.\r\n'"
Udacity Machine Learning Nanodegree Capstone Project,"b'# Machine Learning Engineer Nanodegree\n## Specializations\n## Project: Capstone Proposal and Capstone Project\n\nNote\n\nWelcome to my Capstone Project.\nIn order to correctly review the material, this README provides a few instructions about the documentation and code.\n\nThe proposal I submitted is available in the proposal.pdf file.\nI have provided both reviews I had, named: Proposal Udacity Review First.pdf and Proposal Udacity Review Final.pdf.\nThe url for the last proposal is https://review.udacity.com/#!/reviews/398679\n\nThe capstone project report is available as capstone_report.pdf. The report does NOT contain any code and has been written to provide a complete guide to the steps I followed in order to complete my project. The report follows the suggested capstone project structure as of the provided template.\nCompanion of the report is a jupyter notebook capstone_report.ipynb that contains all python code inside a version of the content in the report in order to be able to understand the context the code has been written in. The jupyter notebook is sufficient to have access to all results. So just run all the cells and the data will be loaded (from the data directory) and all code executed. The jupyter notebook is also available in exported html format for reader convenience.\n\nI used only standard libraries (I used the Anaconda installation with python 2.7), in particular: numpy, pandas, matplotlib, scipy.stats (for norm).\n\nThe reference folder contains additional papers I read in order to document myself about possibile solutions. They are referenced inside the report.\n\nThe data folder contains both JSON and CSV versions of the data samples I used for the report.\n\nI proofreaded only the capstone PDF report. Please forgive me for any typos you may encounter in the ipython notebook.\n\n'"
"Structured, contextual, extensible, composable logging for Rust","b'\n\n  \n  \n  \n  \n\n  \n      \n  \n\n  \n      \n  \n\n  \n      \n  \n\n  \n      \n  \n  \n  \n      \n  \n  \n    Getting started\n  Introduction\n  FAQ\n  \n  Crate list\n\n\n# slog-rs - The Logging for [Rust][rust]\n\n### You might consider using  instead\n\nIts been a while since  was created and it served\nRust community well all this time. It remains a stable, featureful\nand battle-tested library, used in many important projects.\n\nIn last few years,\nanother ecosystem for Rust was\ncreated with similar features and a very good support for debugging  code\nand already larger dev team and community.\n\nPlease check  and see\nif it is more suitable for your use-case. It seems that it is already\na go-to logging/tracing solution for Rust.\n\nReasons you might want to stick with  anyway:\n\n*  support doesnt benefit you\n* you consider mature, stable code & API a plus\n* it has some features that  is missing\n* great performance (I have NOT done any comparison, but s performance\n  is very good).\n\n### Introduction (please read)\n\n is an ecosystem of reusable components for structured, extensible,\ncomposable and contextual logging for [Rust][rust].\n\nThe ambition is to be The Logging Library for Rust.  should accommodate a\nvariety of logging features and requirements. If there is a feature that you\nneed and standard  crate is missing,  should have it.\n\nThis power comes with a little steeper learning curve, so if you experience any\nproblems, please join [slog-rs gitter] channel to get up to speed. If youd\nlike to take a quick, convenient route, consider using\n wrapper library.\n\nWhile the code is reliable, the documentation sometimes could use an improvement.\nPlease report all issues and ideas.\n\n### Features & technical documentation\n\nMost of the interesting documentation is auto-generated and hosted on .\n\nGo to  to read about features and APIs\n(examples included).\n\nNote:  is just a core, and the actual functionality is inside\nmany feature crates. To name a few:\n\n*  for terminal output\n*  for asynchronous logging\n*  for logging JSON\n*  for logging to syslog\n*  for convenience methods (note: )\n\nThere are many more slog feature crates. Search for . It is easy to write and publish\nnew ones. Look through all the  for examples and ideas.\n\n### Terminal output example\n\n is only one of many  features - useful showcase,\nmulti-platform, and featuring eg. automatic TTY detection and colors.\n\nSee following screenshot: same output in both compact and full output mode.\n\n\n\n## Using & help\n\nPlease use [slog-rs gitter] channel to ask for help or discuss\nslog features.\n\nSee\n\nfor full quick code example overview.\n\nRead  for details and features.\n\nTo report a bug or ask for features use [github issues][issues].\n\n[faq]: https://github.com/slog-rs/slog/wiki/FAQ\n[wiki]: https://github.com/slog-rs/slog/wiki/\n[rust]: http://rust-lang.org\n[slog-rs gitter]: https://gitter.im/slog-rs/slog\n[issues]: //github.com/slog-rs/slog/issues\n\n## Slog community\n\nSlog related crates are hosted under .\n\nDawid Ci\xc4\x99\xc5\xbcarkiewicz is the original author and current maintainer of  and\ntherefore self-appointed benevolent dictator over the project. When working on\nslog Dawid follows and expects everyone to follow his .\n\nAny particular repositories under slog ecosystem might be created, controlled,\nmaintained by other entities with various levels of autonomy. Lets work together\ntoward a common goal in a respectful and welcoming atmosphere!\n\n## Verification Recommendation\n\nTo help with the maintained, the ownership of this crate is potentially shared between multiple developers.\nIt is recommended to always use \nto verify the trustworthiness of each of your dependencies, including this one.\n'"
